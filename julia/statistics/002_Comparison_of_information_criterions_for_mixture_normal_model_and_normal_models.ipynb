{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#混合正規分布モデルと正規分布モデルの各種情報量規準の比較\" data-toc-modified-id=\"混合正規分布モデルと正規分布モデルの各種情報量規準の比較-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>混合正規分布モデルと正規分布モデルの各種情報量規準の比較</a></span><ul class=\"toc-item\"><li><span><a href=\"#パッケージの読み込みと諸定義\" data-toc-modified-id=\"パッケージの読み込みと諸定義-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>パッケージの読み込みと諸定義</a></span><ul class=\"toc-item\"><li><span><a href=\"#MambaパッケージでMCMCを実行するための函数\" data-toc-modified-id=\"MambaパッケージでMCMCを実行するための函数-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>MambaパッケージでMCMCを実行するための函数</a></span></li><li><span><a href=\"#Mambaによるシミュレーション結果のまとめの表示\" data-toc-modified-id=\"Mambaによるシミュレーション結果のまとめの表示-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Mambaによるシミュレーション結果のまとめの表示</a></span></li><li><span><a href=\"#WAICなどを計算するための函数\" data-toc-modified-id=\"WAICなどを計算するための函数-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>WAICなどを計算するための函数</a></span></li><li><span><a href=\"#情報をまとめて表示するための函数\" data-toc-modified-id=\"情報をまとめて表示するための函数-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>情報をまとめて表示するための函数</a></span></li><li><span><a href=\"#単純な正規分布モデルを最尤法で解くための函数\" data-toc-modified-id=\"単純な正規分布モデルを最尤法で解くための函数-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>単純な正規分布モデルを最尤法で解くための函数</a></span></li></ul></li><li><span><a href=\"#一回だけの比較\" data-toc-modified-id=\"一回だけの比較-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>一回だけの比較</a></span></li><li><span><a href=\"#複数回の比較\" data-toc-modified-id=\"複数回の比較-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>複数回の比較</a></span><ul class=\"toc-item\"><li><span><a href=\"#サイズ-n=-8,-32,-128-のサンプルをそれぞれ1000個生成して推定\" data-toc-modified-id=\"サイズ-n=-8,-32,-128-のサンプルをそれぞれ1000個生成して推定-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>サイズ n= 8, 32, 128 のサンプルをそれぞれ1000個生成して推定</a></span></li><li><span><a href=\"#シミュレーション結果のプロット\" data-toc-modified-id=\"シミュレーション結果のプロット-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>シミュレーション結果のプロット</a></span><ul class=\"toc-item\"><li><span><a href=\"#n-=-8\" data-toc-modified-id=\"n-=-8-1.3.2.1\"><span class=\"toc-item-num\">1.3.2.1&nbsp;&nbsp;</span>n = 8</a></span></li><li><span><a href=\"#n-=-32\" data-toc-modified-id=\"n-=-32-1.3.2.2\"><span class=\"toc-item-num\">1.3.2.2&nbsp;&nbsp;</span>n = 32</a></span></li><li><span><a href=\"#n-=-128\" data-toc-modified-id=\"n-=-128-1.3.2.3\"><span class=\"toc-item-num\">1.3.2.3&nbsp;&nbsp;</span>n = 128</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混合正規分布モデルと正規分布モデルの各種情報量規準の比較\n",
    "\n",
    "黒木玄\n",
    "\n",
    "2017-11-16～2018-01-13\n",
    "\n",
    "正規分布の確率密度函数を次のように書くことにする:\n",
    "\n",
    "$$\\displaystyle\n",
    "N(\\mu,\\sigma) = \\frac{\\exp(-(x-\\mu)^2/(2\\sigma^2))}{\\sqrt{2\\pi\\sigma^2}}.\n",
    "$$\n",
    "\n",
    "標準正規分布 $N(0,1)$ で生成したサンプルについて, 分散を1に固定した山が2つの混合正規分布モデル mixnormal\n",
    "\n",
    "$$\\displaystyle\n",
    "y \\sim (1-a)N(b,1) + a N(c,1)\n",
    "$$\n",
    "\n",
    "と分散を1に固定した正規分布モデル normal1\n",
    "\n",
    "$$\\displaystyle\n",
    "y \\sim N(\\mu,1)\n",
    "$$\n",
    "\n",
    "と分散も動かすパラメーター数2の正規分布モデル normal\n",
    "\n",
    "$$\\displaystyle\n",
    "y \\sim N(\\mu,\\sigma)\n",
    "$$\n",
    "\n",
    "による推定を比較する.\n",
    "\n",
    "このノートで作成したデータファイルは\n",
    "\n",
    "https://genkuroki.github.io/documents/Jupyter/#2017-11-16\n",
    "\n",
    "からダウンロードできる. 分析結果は以下の場所で閲覧できる:\n",
    "\n",
    "* n=8 http://nbviewer.jupyter.org/gist/genkuroki/cee2962916ec9269c194468a3e5cf288\n",
    "\n",
    "* n=32 http://nbviewer.jupyter.org/gist/genkuroki/41dd5005f143bda6cc678a243bca41c0\n",
    "\n",
    "* n=128 http://nbviewer.jupyter.org/gist/genkuroki/d2978887f61287d54e58baa700d2c002\n",
    "\n",
    "**警告・注意 (2018-01-13)** このノートブックにおけるWBICの数値計算法は適切ではない. なぜならば, このノートブックではWBICを逆温度β=1の場合に純粋数学的には成立しているWBICの公式を利用しているからである. 実際にやってみてわかったことだが(よくよく考えると当たり前のことだが), 逆温度β=1/log(n)における事後分布平均で定義されるWBICを逆温度β=1での事後分布のサンプルを使って近似計算すると誤差が大きくなる. \n",
    "\n",
    "Julia言語のMamba.jlパッケージで逆温度βでのベイズ推定を行う方法については\n",
    "\n",
    "http://nbviewer.jupyter.org/gist/genkuroki/8e97ef72ec01857564bd1a68e6e63d64\n",
    "\n",
    "を参照せよ.  単純な逆温度βの正規分布モデルの場合にWBICのexact formulaを使った実験については\n",
    "\n",
    "http://nbviewer.jupyter.org/gist/genkuroki/8a342d0b7b249e279dd8ad6ae283c5db\n",
    "\n",
    "を参照せよ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.5.2\n",
      "Commit 539f3ce943 (2020-09-23 23:17 UTC)\n",
      "Platform Info:\n",
      "  OS: Windows (x86_64-w64-mingw32)\n",
      "  CPU: AMD Ryzen 5 3500U with Radeon Vega Mobile Gfx  \n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-9.0.1 (ORCJIT, znver1)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "using Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パッケージの読み込みと諸定義\n",
    "- [LocationScale](https://matsueushi.github.io/posts/shift-scale-distribution/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Mamba [5424a776-8be3-5c5b-a13f-3551f69ba0e6]\n",
      "└ @ Base loading.jl:1278\n",
      "┌ Info: Precompiling PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "└ @ Base loading.jl:1278\n",
      "┌ Info: Precompiling JLD2 [033835bb-8acc-5ee8-8aae-3f567f8a3819]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214.750608 seconds (55.31 M allocations: 2.773 GiB, 0.75% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time begin\n",
    "    using Mamba\n",
    "    \n",
    "    using KernelDensity\n",
    "    function makefunc_pdfkde(X)\n",
    "        ik = InterpKDE(kde(X))\n",
    "        pdfkde(x) = pdf(ik, x)\n",
    "        return pdfkde\n",
    "    end\n",
    "    function makefunc_pdfkde(X,Y)\n",
    "        ik = InterpKDE(kde((X,Y)))\n",
    "        pdfkde(x, y) = pdf(ik, x, y)\n",
    "        return pdfkde\n",
    "    end\n",
    "\n",
    "    using Optim\n",
    "    optim_options = Optim.Options(\n",
    "        store_trace = true,\n",
    "        extended_trace = true\n",
    "    )\n",
    "    \n",
    "    using QuadGK\n",
    "\n",
    "    import PyPlot\n",
    "    plt = PyPlot\n",
    "\n",
    "    using Distributions\n",
    "    @everywhere GTDist(μ, ρ, ν) = LocationScale(Float64(μ), Float64(ρ), TDist(Float64(ν)))\n",
    "    @everywhere GTDist(ρ, ν) = GTDist(zero(ρ), ρ, ν)\n",
    "\n",
    "    using JLD2\n",
    "    using FileIO\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### マクロ`sum`の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@sum (macro with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro sum(f_k, k, itr)\n",
    "    quote\n",
    "        begin\n",
    "            s = zero(($(esc(k))->$(esc(f_k)))($(esc(itr))[1]))\n",
    "            for $(esc(k)) in $(esc(itr))\n",
    "                s += $(esc(f_k))\n",
    "            end\n",
    "            s\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MambaパッケージでMCMCを実行するための函数\n",
    "> Mamba: Markov chain Monte Carlo (MCMC) for Bayesian analysis in julia\n",
    "\n",
    "`@everywhere`をつけると子プロセスに持っていける。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample2model_mixnormal (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@everywhere mixnormal(a,b,c) = MixtureModel(Normal[Normal(b, 1.0), Normal(c, 1.0)], [1.0-a, a])\n",
    "\n",
    "mixnormal(w::AbstractVector) = mixnormal(w[1], w[2], w[3])\n",
    "unlink_mixnormal(w) = [logit(w[1]), w[2], w[3]]     # unlink_mixnormal : (0,1)×R^2 -> R^3\n",
    "link_mixnormal(z)   = [invlogit(z[1]), z[2], z[3]]  #   link_mixnormal : R^3 → (0,1)×R^2\n",
    "\n",
    "function sample2model_mixnormal(Y;\n",
    "        dist_model = mixnormal,\n",
    "        a0 = 0.5,\n",
    "        b0 = 0.0,\n",
    "        c0 = 0.0,\n",
    "        prior_a = Uniform(0.0, 1.0),\n",
    "        prior_b = Normal(0.0, 1.0),\n",
    "        prior_c = Normal(0.0, 1.0),\n",
    "        chains = 2\n",
    "    )\n",
    "    data = Dict{Symbol, Any}(\n",
    "        :Y => Y,\n",
    "        :n => length(Y),\n",
    "        :a0 => a0,\n",
    "        :b0 => b0,\n",
    "        :c0 => c0,\n",
    "    )\n",
    "    \n",
    "    model = Model(\n",
    "        y = Stochastic(1, (a, b, c) -> dist_model(a, b, c), false),\n",
    "        a = Stochastic(() -> prior_a, true),\n",
    "        b = Stochastic(() -> prior_b, true),\n",
    "        c = Stochastic(() -> prior_b, true),\n",
    "    )\n",
    "    scheme = [\n",
    "        NUTS([:a, :b, :c])\n",
    "    ]\n",
    "    setsamplers!(model, scheme)\n",
    "    \n",
    "    inits = [\n",
    "        Dict{Symbol, Any}(\n",
    "            :y => data[:Y],\n",
    "            :a => data[:a0],\n",
    "            :b => data[:b0],\n",
    "            :c => data[:c0],\n",
    "        )\n",
    "        for k in 1:chains\n",
    "    ]\n",
    "    return model, data, inits\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一般の正規分布とそれによるsample2model_normalの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample2model_normal (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@everywhere normal(mu, sigma) = Normal(mu, sigma)\n",
    "\n",
    "normal(w::AbstractVector) = normal(w[1], w[2])\n",
    "unlink_normal(w) = [w[1], log(w[2])]  # unlink_normal : R×(0,∞) -> R^2\n",
    "link_normal(z)   = [z[2], exp(z[2])]  #   link_normal : R^2 → R×(0,∞)\n",
    "\n",
    "function sample2model_normal(Y;\n",
    "        dist_model = normal,\n",
    "        mu0    = 0.0,\n",
    "        sigma0 = 1.0,\n",
    "        prior_mu = Normal(0.0, 1.0),\n",
    "        prior_sigma = Truncated(Normal(1.0, 1.0), 0, Inf),\n",
    "        chains = 2\n",
    "    )\n",
    "    data = Dict{Symbol, Any}(\n",
    "        :Y => Y,\n",
    "        :n => length(Y),\n",
    "        :mu0 => mu0,\n",
    "        :sigma0 => sigma0,\n",
    "    )\n",
    "    \n",
    "    model = Model(\n",
    "        y = Stochastic(1, (mu, sigma) -> dist_model(mu, sigma), false),\n",
    "        mu = Stochastic(() -> prior_mu, true),\n",
    "        sigma = Stochastic(() -> prior_sigma, true),\n",
    "    )\n",
    "    scheme = [\n",
    "        NUTS([:mu, :sigma])\n",
    "    ]\n",
    "    setsamplers!(model, scheme)\n",
    "    \n",
    "    inits = [\n",
    "        Dict{Symbol, Any}(\n",
    "            :y => data[:Y],\n",
    "            :mu => data[:mu0],\n",
    "            :sigma => data[:sigma0],\n",
    "        )\n",
    "        for k in 1:chains\n",
    "    ]\n",
    "    return model, data, inits\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 偏差が1の正規分布の定義とそれによるsample2model_normal1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample2model_normal1 (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@everywhere normal1(mu::Real) = Normal(mu, 1.0)\n",
    "\n",
    "normal1(w::AbstractVector) = normal1(w[1])\n",
    "unlink_normal1(w) = w\n",
    "link_normal1(z)   = z\n",
    "\n",
    "function sample2model_normal1(Y;\n",
    "        dist_model = normal1,\n",
    "        mu0    = 0.0,\n",
    "        prior_mu = Normal(0.0, 1.0),\n",
    "        chains = 2\n",
    "    )\n",
    "    data = Dict{Symbol, Any}(\n",
    "        :Y => Y,\n",
    "        :n => length(Y),\n",
    "        :mu0 => mu0,\n",
    "    )\n",
    "    \n",
    "    model = Model(\n",
    "        y = Stochastic(1, mu -> dist_model(mu), false),\n",
    "        mu = Stochastic(() -> prior_mu, true),\n",
    "    )\n",
    "    scheme = [\n",
    "        NUTS([:mu])\n",
    "    ]\n",
    "    setsamplers!(model, scheme)\n",
    "    \n",
    "    inits = [\n",
    "        Dict{Symbol, Any}(\n",
    "            :y => data[:Y],\n",
    "            :mu => data[:mu0],\n",
    "        )\n",
    "        for k in 1:chains\n",
    "    ]\n",
    "    return model, data, inits\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## showsummary: Mambaによるシミュレーション結果のまとめの表示用関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "showsummary (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function showsummary(sim;\n",
    "        sortkeys=true, figsize_t=(8, 3), figsize_c=(8, 3.5),\n",
    "        show_describe=true, show_gelman=true, plot_trace=true, plot_contour=true)\n",
    "    ## Summary of MCMC\n",
    "    if show_describe\n",
    "        println(\"\\n========== Summary:\\n\")\n",
    "        display(describe(sim))\n",
    "    end\n",
    "\n",
    "    # Convergence Diagnostics\n",
    "    if show_gelman && length(sim.chains) ≥ 2 \n",
    "       println(\"========== Gelman Diagnostic:\")\n",
    "       show(gelmandiag(sim))\n",
    "    end\n",
    "\n",
    "    ## Plot\n",
    "    sleep(0.1)\n",
    "    if plot_trace\n",
    "        #draw(plot(sim), fmt=:png, width=10inch, height=3.5inch, nrow=1, ncol=2, ask=false)\n",
    "        pyplot_trace(sim, sortkeys=sortkeys, figsize=figsize_t)\n",
    "    end\n",
    "    if plot_contour\n",
    "        #draw(plot(sim, :contour), fmt=:png, width=10inch, height=4.5inch, nrow=1, ncol=2, ask=false)\n",
    "        pyplot_contour(sim, sortkeys=sortkeys, figsize=figsize_c)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyplot_traceの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyplot_trace (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function pyplot_trace(sim; sortkeys = false, figsize = (8, 3))\n",
    "    if sortkeys\n",
    "        keys_sim = sort(keys(sim))\n",
    "    else\n",
    "        keys_sim = keys(sim)\n",
    "    end\n",
    "    for var in keys_sim\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        plt.subplot(1,2,1)\n",
    "        for k in sim.chains\n",
    "            plt.plot(sim.range, sim[:,var,:].value[:,1,k], label=\"$k\", lw=0.4, alpha=0.8)\n",
    "        end\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.grid(ls=\":\")\n",
    "        plt.title(\"trace of $var\", fontsize=10)\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        xmin = quantile(vec(sim[:,var,:].value), 0.005)\n",
    "        xmax = quantile(vec(sim[:,var,:].value), 0.995)\n",
    "        for k in sim.chains\n",
    "            chain = sim[:,var,:].value[:,1,k]\n",
    "            pdfkde = makefunc_pdfkde(chain)\n",
    "            x = range(xmin, xmax, length=201)\n",
    "            plt.plot(x, pdfkde.(x), label=\"$k\", lw=0.8, alpha=0.8)\n",
    "        end\n",
    "        plt.xlabel(\"$var\")\n",
    "        plt.grid(ls=\":\")\n",
    "        plt.title(\"empirical posterior pdf of $var\", fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyplot_contourの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyplot_contour (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function pyplot_contour(sim; sortkeys = true, figsize = (8, 3.5))\n",
    "    if sortkeys\n",
    "        keys_sim = sort(keys(sim))\n",
    "    else\n",
    "        keys_sim = keys(sim)\n",
    "    end\n",
    "    m = 0\n",
    "    K = length(keys_sim)\n",
    "    for i in 1:K\n",
    "        for j in i+1:K\n",
    "            m += 1\n",
    "            mod1(m,2) == 1 && plt.figure(figsize=figsize)\n",
    "            plt.subplot(1,2, mod1(m,2))\n",
    "\n",
    "            u = keys_sim[i]\n",
    "            v = keys_sim[j]\n",
    "            X = vec(sim[:,u,:].value)\n",
    "            Y = vec(sim[:,v,:].value)\n",
    "            pdfkde = makefunc_pdfkde(X,Y)\n",
    "            xmin = quantile(X, 0.005)\n",
    "            xmax = quantile(X, 0.995)\n",
    "            ymin = quantile(Y, 0.005)\n",
    "            ymax = quantile(Y, 0.995)\n",
    "            x = range(xmin, xmax, length=200)\n",
    "            y = range(ymin, ymax, length=200)\n",
    "            \n",
    "            plt.pcolormesh(x', y, pdfkde.(x',y), cmap=\"CMRmap\")\n",
    "            plt.colorbar()\n",
    "            plt.grid(ls=\":\")\n",
    "            plt.xlabel(u)\n",
    "            plt.ylabel(v)\n",
    "            plt.title(\"posterior of ($u, $v)\", fontsize=10)\n",
    "\n",
    "            mod1(m,2) == 2 && plt.tight_layout()\n",
    "\n",
    "            if 2*m == K*(K-1) && mod1(m,2) == 1\n",
    "                plt.subplot(1,2,2)\n",
    "                \n",
    "                plt.pcolormesh(y', x, pdfkde.(x,y'), cmap=\"CMRmap\")\n",
    "                plt.colorbar()\n",
    "                plt.grid(ls=\":\")\n",
    "                plt.xlabel(v)\n",
    "                plt.ylabel(u)\n",
    "                plt.title(\"posterior of ($v, $u)\", fontsize=10)\n",
    "\n",
    "                plt.tight_layout()\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WAICなどを計算するための函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下において, 各種情報量規準の定義と計算の仕方を説明する.\n",
    "\n",
    "情報量規準の表示のスケールには, Kullback-Leibler情報量のスケールと対数尤度比によるカイ二乗検定のスケールの2種類があるが, 以下では伝統的な後者のスケールに合わせて説明する. 対数尤度比によるカイ二乗検定のスケールからKL情報量のスケールに移るためには, サンプルサイズの2倍で割ればよい.\n",
    "\n",
    "$X_1,\\ldots,X_n$ はサイズ $n$ のサンプルであり, $d$ は確率モデル $p(x|w)$ のパラメーターの数であり($w=(w_1,\\ldots,w_d$)), $\\hat{w}$ は最大尤度を与えるパラメーターであるとする:\n",
    "\n",
    "$$\\displaystyle\n",
    "\\min_w \\left(-\\sum_{i=1}^n \\log p(X_k|w)\\right) = -\\sum_{i=1}^n \\log p(X_k|\\hat{w}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最尤法の予測分布\n",
    "$$\\displaystyle\n",
    "p^*_\\mathrm{MLE}(x) = p(x|\\hat{w}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AICの計算の仕方\n",
    "$$\\displaystyle\n",
    "\\mathrm{AIC} := 2\\left(-\\sum_{k=1}^n\\log p(X_k|\\hat{w})\\right) + 2d.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BICの計算の仕方\n",
    "$$\\displaystyle\n",
    "\\mathrm{BIC} := 2\\left(-\\sum_{k=1}^n\\log p(X_k|\\hat{w})\\right) + d\\log n.\n",
    "$$\n",
    "\n",
    "MCMCの結果得られる事後分布のサンプルを $w_1,w_2,\\ldots,w_L$ と書く.\n",
    "\n",
    "事後予測分布とWAICとLOOCV(一個抜き交差検証)とWBICは対数尤度の配列 \n",
    "\n",
    "$$\n",
    "\\{\\,\\log p(X_k|w_l)\\mid k=1,2,\\ldots,n,\\; l=1,2,\\ldots,L\\,\\}\n",
    "$$\n",
    "\n",
    "のみから近似計算可能である. 事後予測分布, WAIC, LOOCV, WBIC を計算するための最初の作業はこの配列をMCMCの結果から抽出することである. その配列を抽出できてさえしまえば, それらは以下の公式によって機械的に計算される."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes推定の事後予測分布\n",
    "$$\\displaystyle\n",
    "p^*_\\mathrm{Bayesian}(x) := (\\mathrm{posterior\\ mean\\ of}\\ p(x|w))\n",
    "\\approx \\left(\\mathrm{mean\\ of}\\ \\{p(x|w_l)\\}_{l=1}^L\\right) = \n",
    "\\left(\\mathrm{mean\\ of}\\ \\{\\exp(\\log p(x|w_l))\\}_{l=1}^L\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAICの計算の仕方\n",
    "$$\\displaystyle\n",
    "\\mathrm{WAIC} := T_{\\mathrm{WAIC}} + V_{\\mathrm{WAIC}}.\n",
    "$$\n",
    "\n",
    "ここで\n",
    "$$\\begin{aligned}\n",
    "&\n",
    "T_{\\mathrm{WAIC}} :=\n",
    "-2\\sum_{k=1}^n \\log p^*(X_k)\n",
    "\\approx -2\\sum_{k=1}^n\\log\\left(\\mathrm{mean\\ of}\\ \\{\\exp(\\log p(X_k|w_l))\\}_{l=1}^L\\right),\n",
    "\\\\ &\n",
    "V_{\\mathrm{WAIC}} :=\n",
    "2\\sum_{k=1}^n \\left(\\mathrm{posterior\\ variance\\ of}\\ \\log p(X_k|w)\\right)\n",
    "\\approx 2\\sum_{k=1}^n \\left(\\mathrm{variance\\ of}\\ \\{\\log p(X_k|w_l)\\}_{l=1}^L\\right).\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOCV(一個抜き交差検証)の素朴な計算の仕方\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathrm{LOOCV} &:= -2\\sum_{k=1}^n \\log E^{(k)}_w[p(X_k|w)] =\n",
    "2\\sum_{k=1}^n \\log E_w\\left[\\frac{1}{p(X_k|w)}\\right]\n",
    "\\\\ & \n",
    "\\approx 2\\sum_{k=1}^n \\log\\left(\\mathrm{mean\\ of}\\ \\{\\exp(-\\log p(X_k|w_l))\\}_{l=1}^L\\right).\n",
    "\\end{aligned}$$\n",
    "\n",
    "ここで\n",
    "\n",
    "$$\\begin{aligned}\n",
    "&\n",
    "Z_n := \\int \\prod_{j=1}^n p(X_j|w)\\;\\varphi(w)\\,dw,\n",
    "\\\\ &\n",
    "E_w[f(w)] := \\frac{1}{Z_n}\\int f(w)\\prod_{j=1}^n p(X_j|w)\\;\\varphi(w)\\,dw\n",
    "\\approx \\left(\\mathrm{mean\\ of}\\ \\{f(w_l)\\}_{l=1}^L\\right),\n",
    "\\\\ &\n",
    "Z^{(k)}_n := \\int \\frac{\\prod_{j=1}^n p(X_j|w)}{p(X_k|w)}\\varphi(w)\\,dw =\n",
    "Z_n E_w\\left[\\frac{1}{p(X_k|w)}\\right],\n",
    "\\\\ &\n",
    "E^{(k)}_w[f(w)] := \\frac{1}{Z^{(k)}_n}\\int f(w)\\frac{\\prod_{j=1}^n p(X_j|w)}{p(X_k|w)}\\varphi(w)\\,dw =\n",
    "\\frac{Z_n}{Z^{(k)}_n}E_w\\left[\\frac{f(w)}{p(X_k|w)}\\right] =\n",
    "\\frac{E_w[f(w)/p(X_k|w)]}{E_w[1/p(X_k|w)]},\n",
    "\\\\ &\n",
    "\\log E^{(k)}_w[p(X_k|w)] = \\log\\frac{E_w[1]}{E_w[1/p(X_k|w)]} = -\\log E_w\\left[\\frac{1}{p(X_k|w)}\\right]\n",
    "\\\\ & \\qquad\n",
    "\\approx -\\log\\left(\\mathrm{mean\\ of}\\ \\left\\{\\frac{1}{p(X_k|w_l)}\\right\\}_{l=1}^L\\right)\n",
    "= -\\log\\left(\\mathrm{mean\\ of}\\ \\{\\exp(-\\log p(X_k|w_l))\\}_{l=1}^L\\right).\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WBICの計算の仕方\n",
    "$\\beta=1/\\log n$ とおき, \n",
    "\n",
    "$$\\displaystyle\n",
    "\\mathrm{WBIC} := 2E^{\\beta}_w\\left[nL_n(w)\\right] = 2\\frac{N_{\\mathrm{WBIC}}}{D_{\\mathrm{WBIC}}}.\n",
    "$$\n",
    "\n",
    "ここで, \n",
    "\n",
    "$$\\begin{aligned}\n",
    "nL_n(w) &:= -\\sum_{k=1}^n \\log p(X_k|w), \\quad\n",
    "nL_n(w_l) = -\\sum_{k=1}^n \\log p(X_k|w_l),\n",
    "\\\\\n",
    "Z_n(\\beta) &:= \\int \\left(\\prod_{k=1}^n p(X_k|w)\\right)^\\beta\\;\\varphi(w)\\,dw, \\quad\n",
    "Z_n(\\beta)E^{\\beta}_w\\left[f(w)\\right] := \\int f(w)\\left(\\prod_{k=1}^n p(X_k|w)\\right)^\\beta\\;\\varphi(w)\\,dw\n",
    "\\\\\n",
    "N_{\\mathrm{WBIC}} &:= \\frac{Z_n(\\beta)E^{\\beta}_w\\left[nL_n(w)\\right]}{Z_n(1)} =\n",
    "\\frac{1}{Z_n(1)}\n",
    "\\int nL_n(w)\\left(\\prod_{k=1}^n p(X_k|w)\\right)^{\\beta-1} \\prod_{k=1}^n p(X_k|w)\\;\\varphi(w)\\,dw\n",
    "\\\\ &\n",
    "\\approx \\left(\\mathrm{mean\\ of}\\ \\left\\{nL_n(w_l) \\exp(-(\\beta-1)nL_n(w_l))\\right\\}_{l=1}^L\\right),\n",
    "\\\\\n",
    "D_{\\mathrm{WBIC}} &:= \\frac{Z_n(\\beta)}{Z_n(1)} = \n",
    "\\frac{1}{Z_n(1)}\\int \\left(\\prod_{k=1}^n p(X_k|w)\\right)^{\\beta-1} \\prod_{k=1}^n p(X_k|w)\\;\\varphi(w)\\,dw\n",
    "\\\\ &\n",
    "\\approx \\left(\\mathrm{mean\\ of}\\ \\left\\{\\exp(-(\\beta-1)nL_n(w_l))\\right\\}_{l=1}^L\\right).\n",
    "\\end{aligned}$$\n",
    "\n",
    "WBICは逆温度 $1$ の事後分布のサンプル上での対数尤度函数の $-1$ 倍の値達 $nL_n(w_l)$ のみから近似計算可能である. \n",
    "\n",
    "WBICの近似計算のためには**逆温度 $\\beta$ の事後分布のサンプルを構成する必要がない**ことに注意せよ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文献\n",
    "以上のWBICの計算法では, \n",
    "\n",
    "http://www.jmlr.org/papers/volume14/watanabe13a/watanabe13a.pdf p.877 (p.11 in file)\n",
    "\n",
    "の式(20)を $\\beta_1=1$, $\\beta_2=\\beta$ の場合に適用した結果を使った."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017-11-10 メモ\n",
    "このノートブックにおけるWBICの計算はMCMCの結果に大きく依存し、分散が大きい。もしかしたら、何か間違ったことをしているかもしれない."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017-11-12 追記 (自由エネルギーのより正確な計算法)\n",
    "WBIC導出の第一段階は, 自由エネルギー $F_n(\\beta)$ の逆温度 $\\beta$ による微分が $nL_n(w)$ の逆温度 $\\beta$ の事後分布に関する平均になり, $F_n(0)=0$ なので\n",
    "\n",
    "$$\\displaystyle\n",
    "F_n(1) = \\int_0^1 E^\\beta_w[nL_n(w)] \\,d\\beta\n",
    "\\tag{$*$}\n",
    "$$\n",
    "\n",
    "となることを示すことである(これはとても易しい). WBIC導出の第二段階は右辺の積分が $\\beta=1/\\log n$ のときの $E^\\beta[nL_n(w)]$ で近似できることを示すことである(こちらは少々非自明である)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ($*$)の導出\n",
    "$$\n",
    "\\begin{aligned}\n",
    "nL_n(w) &:= -\\sum_{k=1}^n \\log p(X_k|w),\n",
    "\\\\\n",
    "Z_n(\\beta) &:= \\int \\left(\\prod_{k=1}^n p(X_k|w)\\right)^\\beta \\varphi(w)\\,dw =\n",
    "\\int\\exp\\left(-\\beta nL_n(w)\\right)\\varphi(w)\\,dw,\n",
    "\\\\\n",
    "Z_n'(\\beta) &= -\\int nL_n(w)\\exp\\left(-\\beta nL_n(w)\\right)\\varphi(w)\\,dw,\n",
    "\\\\\n",
    "E^\\beta_w[f(w)] &:= \\frac{1}{Z_n(\\beta)}\\int f(w)\\left(\\prod_{k=1}^n p(X_k|w)\\right)^\\beta \\varphi(w)\\,dw =\n",
    "\\frac{\\int\\exp\\left(-\\beta nL_n(w)\\right)\\varphi(w)\\,dw}{Z_n(\\beta)},\n",
    "\\\\ \n",
    "F_n(\\beta) &:= -\\log Z_n(\\beta),\n",
    "\\\\\n",
    "F_n(0) &= -\\log Z_n(0) = -\\log\\int\\varphi(w)\\,dw = -\\log 1 = 0,\n",
    "\\\\\n",
    "F_n'(\\beta) &= \\frac{-Z_n'(\\beta)}{Z_n(\\beta)} = \n",
    "\\frac{\\int nL_n(w)\\exp\\left(-\\beta nL_n(w)\\right)\\varphi(w)\\,dw}{Z_n(\\beta)} = E^\\beta_w[nL_n(w)].\n",
    "\\\\\n",
    "\\therefore \\quad\n",
    "F_n(1) &= \\int_0^1 E^\\beta_w[nL_n(w)]\\,d\\beta.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$E^\\beta_w[nL_n(w)]$ を $\\beta$ で数値積分すれば自由エネルギー $F_n(1)$ を数値計算できる. 数値積分の分だけ必要な計算量は増えるが, 被積分函数は $\\beta$ の1変数函数なので, モデルのパラメーターに関する多変数函数の積分をするよりも必要な計算量は圧倒的に少なくてすむ.\n",
    "\n",
    "$E^\\beta_w[nL_n(w)]$ は次のように表せる:\n",
    "\n",
    "$$\\displaystyle\n",
    "E^{\\beta}_w\\left[nL_n(w)\\right] = \\frac{N(\\beta)}{D(\\beta)}.\n",
    "$$\n",
    "\n",
    "ここで, \n",
    "\n",
    "$$\\begin{aligned}\n",
    "N(\\beta) &= \\frac{Z_n(\\beta)E^{\\beta}_w\\left[nL_n(w)\\right]}{Z_n(1)} =\n",
    "\\frac{1}{Z_n(1)}\n",
    "\\int nL_n(w)\\left(\\prod_{k=1}^n p(X_k|w)\\right)^{\\beta-1} \\prod_{k=1}^n p(X_k|w)\\;\\varphi(w)\\,dw\n",
    "\\\\ &\n",
    "\\approx \\left(\\mathrm{mean\\ of}\\ \\left\\{nL_n(w_l) \\exp(-(\\beta-1)nL_n(w_l))\\right\\}_{l=1}^L\\right),\n",
    "\\\\\n",
    "D(\\beta) &= \\frac{Z_n(\\beta)}{Z_n(1)} = \n",
    "\\frac{1}{Z_n(1)}\n",
    "\\int \\left(\\prod_{k=1}^n p(X_k|w)\\right)^{\\beta-1} \\prod_{k=1}^n p(X_k|w)\\;\\varphi(w)\\,dw\n",
    "\\\\ &\n",
    "\\approx \\left(\\mathrm{mean\\ of}\\ \\left\\{\\exp(-(\\beta-1)nL_n(w_l))\\right\\}_{l=1}^L\\right).\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意\n",
    "伝統的なAICのスケールに合わせるためには\n",
    "\n",
    "$$\\displaystyle\n",
    "2F_n(1) = 2\\int_0^1 E^{\\beta}_w\\left[nL_n(w)\\right]\\,d\\beta = 2\\int_0^1\\frac{N(\\beta)}{D(\\beta)}\\,d\\beta\n",
    "$$\n",
    "\n",
    "を計算すればよい. 以下のセルでは以上の方法でこのスケールで自由エネルギーを計算する函数を定義している."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `loglik[l,i] = lpdf(w_l, Y_i)` と `chain[l,:] = w_l` を取り出す函数を作る函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 3×3 Array{Float64,2} at index [0, 0]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 3×3 Array{Float64,2} at index [0, 0]",
      "",
      "Stacktrace:",
      " [1] setindex!(::Array{Float64,2}, ::Float64, ::Int64, ::Int64) at .\\array.jl:849",
      " [2] top-level scope at In[11]:2",
      " [3] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "a = Array{Float64,2}(undef, 3, 3)\n",
    "#a[0,0] = 3.0\n",
    "a[1,1] = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "makefunc_loglikchainof (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function makefunc_loglikchainof(lpdf, symbols, Y)\n",
    "    #\n",
    "    # loglikchainof(sim) で loglik[l,i] と chain[l,:] が抽出される\n",
    "    #\n",
    "    function loglikchainof(sim)\n",
    "        val = sim[:, symbols, :].value\n",
    "        chain = vcat((val[:,:,k] for k in 1:size(val,3))...)\n",
    "        L = size(chain,1)\n",
    "        n = length(Y)\n",
    "        loglik = Array{Float64, 2}(undef, L, n)\n",
    "        for i in 1:n\n",
    "            for l in 1:L\n",
    "                loglik[l,i] = lpdf(chain[l,:], Y[i])\n",
    "            end\n",
    "        end\n",
    "        return loglik, chain\n",
    "    end\n",
    "    return loglikchainof\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測分布函数 $p^*(x,y)$ = mean of $\\{\\mathrm{lpdf}(w_l, y)\\}_{l=1}^L$ を作る函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "makefunc_pdfpred (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function makefunc_pdfpred(lpdf, chain)\n",
    "    L = size(chain,1)\n",
    "    pred_Bayes(y) = @sum(exp(lpdf((@view chain[l,:]), y)), l, 1:L)/L\n",
    "    return pred_Bayes\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `loglik[l,i]` からWAICを計算する函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WAICof (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function WAICof(loglik)\n",
    "    L, n = size(loglik)\n",
    "    T_n = -mean(log(mean(exp(loglik[l,i]) for l in 1:L)) for i in 1:n)\n",
    "    V_n  = sum(var(loglik[:,i], corrected=false) for i in 1:n)\n",
    "    WAIC = 2*n*T_n + 2*V_n\n",
    "    WAIC, 2*n*T_n, 2*V_n\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `loglik[l,i]` からLOOCVを素朴に計算する函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOOCVof (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function LOOCVof(loglik)\n",
    "    L, n = size(loglik)\n",
    "    LOOCV = 2*sum(log(mean(exp(-loglik[l,i]) for l in 1:L)) for i in 1:n)\n",
    "    return LOOCV\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自由エネルギー(の2倍)を計算するための函数\n",
    "自由エネルギーの2の逆温度微分は `E^β_w[2n L_n]` に等しいので、\n",
    "それを β=0.0 から 1.0 まで数値積分すれば自由エネルギーの2倍を計算できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "makefunc_E2nLn (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function FreeEnergyof(loglik)\n",
    "    E2nLn = makefunc_E2nLn(loglik)\n",
    "    F = quadgk(E2nLn, 0.0, 1.0)[1]\n",
    "    return F, E2nLn\n",
    "end\n",
    "\n",
    "function makefunc_E2nLn(loglik)\n",
    "    L = size(loglik)[1]\n",
    "    negloglik = -sum(loglik, 2)\n",
    "    negloglik_n = negloglik .- maximum(negloglik)\n",
    "    function E2nLn(beta)\n",
    "        Edenominator = @sum(             exp((1-beta)*negloglik_n[l]), l, 1:L)/L\n",
    "        if Edenominator == zero(Edenominator) || !isfinite(Edenominator)\n",
    "            return zero(Edenominator)\n",
    "        end\n",
    "        Enumerator   = @sum(negloglik[l]*exp((1-beta)*negloglik_n[l]), l, 1:L)/L\n",
    "        return 2*Enumerator/Edenominator\n",
    "    end\n",
    "    return E2nLn\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `loglik[l,i]` からWBICを計算する函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WBICof (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function WBICof(loglik)\n",
    "    E2nLn = makefunc_E2nLn(loglik)\n",
    "    n = size(loglik, 2)\n",
    "    WBIC = E2nLn(1/log(n))\n",
    "    return WBIC\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 汎化損失を計算する函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneralizationLossof (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function GeneralizationLossof(pdftrue, pdfpred; xmin=-10.0, xmax=10.0)\n",
    "    f(x) = -pdftrue(x)*log(pdfpred(x))\n",
    "    return quadgk(f, xmin, xmax)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最尤法を実行して AIC と BIC を計算する函数\n",
    "- lpdf(w,y) = log p(y|w)\n",
    "- w = link_model(z)   ←実ベクトル z 全体をパラメーター w の空間内に移す函数\n",
    "- z = unlinkmodel(w) ←link_model(z)の逆函数\n",
    "- これらは -imize() 函数の適用時にパラメーター w が定義域から外れることを防ぐための函数達\n",
    "- (X[i], Y[i] はサンプル\n",
    "- chain は loglik, chain = loglikchainof(sim) で作った chain\n",
    "- optimize函数は1変数函数の場合には初期条件を与えて解を求める函数ではなくなるので、その場合には2変数函数に拡張してから使用している."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AICandBICof (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function AICandBICof(lpdf, link_model, unlink_model, Y, chain)\n",
    "    n = length(Y)\n",
    "    L = size(chain,1)\n",
    "    nparams = size(chain,2)\n",
    "    negloglik(z) = -@sum(lpdf(link_model(z), Y[i]), i, 1:n)\n",
    "    minnegloglik_chain, l\n",
    "    minnegloglik_chain, l = findmin(negloglik(unlink_model(chain[l,:])) for l in 1:L)\n",
    "    if size(chain,2) == 1\n",
    "        f(z) = negloglik([z[1]]) + z[2]^2/eps()\n",
    "        o = optimize(f, [unlink_model(chain[l,:])[1], 0.0])\n",
    "        minnegloglik = o.minimum\n",
    "        param_AIC = link_model([o.minimizer[1]])\n",
    "    else\n",
    "        o = optimize(negloglik, unlink_model(chain[l,:]))\n",
    "        minnegloglik = o.minimum\n",
    "        param_AIC = link_model(o.minimizer)\n",
    "    end\n",
    "    T_AIC = 2.0*minnegloglik\n",
    "    V_AIC = 2.0*nparams\n",
    "    T_BIC = T_AIC\n",
    "    V_BIC = nparams*log(n)\n",
    "    AIC = T_AIC + V_AIC\n",
    "    BIC = T_BIC + V_BIC\n",
    "    return AIC, T_AIC, V_AIC, \n",
    "        BIC, T_BIC, V_BIC, \n",
    "        param_AIC\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情報をまとめて表示するための函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statsof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statsof (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function statsof(sim, Y; \n",
    "        dist_true=mixnormal(0.0, 0.0, 0.0), \n",
    "        dist_model=mixnormal, link_model=link_mixnormal, unlink_model=unlink_mixnormal)\n",
    "    \n",
    "    n = length(Y)\n",
    "    \n",
    "    lpdf(w, y) = logpdf(dist_model(w), y)\n",
    "    \n",
    "    loglikchainof = makefunc_loglikchainof(lpdf, sort(keys(sim)), Y)\n",
    "    loglik, chain = loglikchainof(sim)\n",
    "    \n",
    "    WAIC, T_WAIC, V_WAIC = WAICof(loglik)\n",
    "    LOOCV = LOOCVof(loglik)\n",
    "    \n",
    "    WBIC = WBICof(loglik)\n",
    "    FreeEnergy = FreeEnergyof(loglik)[1]\n",
    "    \n",
    "    param_Bayes = vec(mean(chain, 1))\n",
    "    pred_Bayes = makefunc_pdfpred(lpdf, chain)\n",
    "    \n",
    "    GeneralizationLoss = 2*n*GeneralizationLossof(x->pdf(dist_true,x), pred_Bayes)[1]\n",
    "    \n",
    "    AIC, T_AIC, V_AIC, BIC, T_BIC, V_BIC, param_MLE = AICandBICof(lpdf, link_model, unlink_model, Y, chain)\n",
    "    \n",
    "    pred_MLE(y) = exp(lpdf(param_MLE, y))\n",
    "    \n",
    "    return WAIC, T_WAIC, V_WAIC, LOOCV, GeneralizationLoss,\n",
    "        WBIC, FreeEnergy,\n",
    "        param_Bayes, pred_Bayes, \n",
    "        AIC, T_AIC, V_AIC, \n",
    "        BIC, T_BIC, V_BIC,\n",
    "        param_MLE, pred_MLE\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show_all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_all_results (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function show_all_results(dist_true, Y, sim; statsfunc=statsof, \n",
    "        dist_model=mixnormal, link_model=link_mixnormal, unlink_model=link_mixnormal,\n",
    "        figsize=(6,4.2), xmin=-4.0, xmax=6.0)\n",
    "    WAIC, T_WAIC, V_WAIC, LOOCV, GeneralizationLoss,\n",
    "    WBIC, FreeEnergy,\n",
    "    param_Bayes, pred_Bayes, \n",
    "    AIC, T_AIC, V_AIC, \n",
    "    BIC, T_BIC, V_BIC,\n",
    "    param_MLE, pred_MLE = statsfunc(sim, Y, dist_true=dist_true, \n",
    "        dist_model=dist_model, link_model=link_model, unlink_model=unlink_model)\n",
    "    \n",
    "    n = length(Y)\n",
    "    println(\"\\n=== Estimates by $dist_model  (n = $n) ===\")\n",
    "    @show param_Bayes\n",
    "    @show param_MLE\n",
    "    \n",
    "    println(\"--- Information Criterions\")\n",
    "    println(\"* AIC     = $AIC = $T_AIC + $V_AIC\")\n",
    "    println(\"* GenLoss = $GeneralizationLoss\")\n",
    "    println(\"* WAIC    = $WAIC = $T_WAIC + $V_WAIC\")\n",
    "    println(\"* LOOCV   = $LOOCV\")\n",
    "    println(\"---\")\n",
    "    println(\"* BIC        = $BIC = $T_BIC + $V_BIC\")\n",
    "    println(\"* FreeEnergy = $FreeEnergy\")\n",
    "    println(\"* WBIC       = $WBIC\")\n",
    "\n",
    "    println(\"=\"^78 * \"\\n\")\n",
    "    \n",
    "    sleep(0.1)\n",
    "    plt.figure(figsize=figsize)\n",
    "    kde_sample = makefunc_pdfkde(Y)\n",
    "    x = range(xmin, xmax, length=201)\n",
    "    plt.plot(x, pdf.(dist_true, x), label=\"true distribution\")\n",
    "    plt.scatter(Y, kde_sample.(Y), label=\"sample\", s=10, color=\"k\", alpha=0.5)\n",
    "    plt.plot(x, kde_sample.(x), label=\"KDE of sample\",   color=\"k\", alpha=0.5)\n",
    "    plt.plot(x, pred_Bayes.(x), label=\"Baysian predictive\", ls=\"--\")\n",
    "    plt.plot(x, pred_MLE.(x),   label=\"MLE predictive\",     ls=\"-.\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"probability density\")\n",
    "    plt.grid(ls=\":\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.title(\"Estimates by $dist_model: n = $(length(Y))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plotsample (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plotsample(dist_true, Y; figsize=(6,4.2), xmin=-4.0, xmax=6.0)\n",
    "    sleep(0.1)\n",
    "    plt.figure(figsize=figsize)\n",
    "    kde_sample = makefunc_pdfkde(Y)\n",
    "    x = range(xmin, xmax, length=201)\n",
    "    plt.plot(x, pdf.(dist_true, x), label=\"true dist.\")\n",
    "    plt.scatter(Y, kde_sample.(Y), label=\"sample\", s=10, color=\"k\", alpha=0.5)\n",
    "    plt.plot(x, kde_sample.(x), label=\"KDE of sample\",   color=\"k\", alpha=0.5)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"probability density\")\n",
    "    plt.grid(ls=\":\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.title(\"Sample size n = $(length(Y))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単純な正規分布モデルを最尤法で解くための函数\n",
    "次のセルの定義はこのノートでは使用しない."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_fit_Normal (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dist_true 分布に従う乱数で生成したサンプルの配列 Y を与えると\n",
    "# 正規分布モデルの最尤法で推定して、AICなどを返す函数\n",
    "#\n",
    "function fit_Normal(dist_true, Y)\n",
    "    n = length(Y)\n",
    "    d = fit(Normal,Y)\n",
    "    mu = d.μ\n",
    "    sigma = d.σ\n",
    "    pred_Normal(y) = pdf(d,y)\n",
    "    T_Normal = -2*sum(logpdf.(d,Y))\n",
    "    V_Normal = 4.0\n",
    "    AIC_Normal = T_Normal + V_Normal\n",
    "    TB_Normal = T_Normal\n",
    "    VB_Normal = 2.0*log(n)\n",
    "    BIC_Normal = TB_Normal + VB_Normal\n",
    "    f(y) = -pdf(dist_true, y)*logpdf(d, y)\n",
    "    GL_Normal = 2*n*quadgk(f, -10, 10)[1]\n",
    "    return mu, sigma, pred_Normal, \n",
    "        AIC_Normal, T_Normal, V_Normal, \n",
    "        BIC_Normal, TB_Normal, VB_Normal, \n",
    "        GL_Normal\n",
    "end\n",
    "\n",
    "# グラフをプロットする範囲が xmin から xmax まで\n",
    "#\n",
    "function show_fit_Normal(dist_true, Y; figsize=(6,4.2), xmin=-4.0, xmax=6.0)\n",
    "    mu, sigma, pred_Normal, \n",
    "    AIC_Normal, T_Normal, V_Normal, \n",
    "    BIC_Normal, TB_Normal, VB_Normal, \n",
    "    GL_Normal = fit_Normal(dist_true, Y)\n",
    "    println(\"--- Normal Fitting\")\n",
    "    println(\"* μ = $mu\")\n",
    "    println(\"* σ = $sigma\")\n",
    "    println(\"* GenLoss = $GL_Normal\")\n",
    "    println(\"* AIC     = $AIC_Normal = $T_Normal + $V_Normal\")\n",
    "    println(\"* BIC     = $BIC_Normal = $TB_Normal + $VB_Normal\")\n",
    "    \n",
    "    sleep(0.1)\n",
    "    plt.figure(figsize=figsize)\n",
    "    kde_sample = makefunc_pdfkde(Y)\n",
    "    x = range(xmin, xmax, length=201)\n",
    "    plt.plot(x, pdf.(dist_true, x), label=\"true distribution\")\n",
    "    plt.scatter(Y, kde_sample.(Y), label=\"sample\", s=10, color=\"k\", alpha=0.5)\n",
    "    plt.plot(x, kde_sample.(x), label=\"KDE of sample\",   color=\"k\", alpha=0.5)\n",
    "    plt.plot(x, pred_Normal.(x), label=\"Normal predictive\", ls=\"--\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"probability density\")\n",
    "    plt.grid(ls=\":\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.title(\"Sample size n = $(length(Y))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一回だけの比較: `simonce`マクロの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_sample = false\n",
    "\n",
    "macro simonce(seed, n, dist_true) quote begin\n",
    "\n",
    "Random.seed!($(esc(seed)))\n",
    "\n",
    "dist_true = $(esc(dist_true))\n",
    "n = $(esc(n))\n",
    "Y = rand(dist_true, n)\n",
    "\n",
    "println(\"dist_true = $dist_true\")\n",
    "println(\"n = $n\")\n",
    "show_sample && println(\"Y = $Y\")\n",
    "println()\n",
    "\n",
    "iterations = 500\n",
    "burnin = 100\n",
    "thin = 1\n",
    "chains = 4\n",
    "model, data, inits = sample2model_mixnormal(Y, chains=chains)\n",
    "@time sim_mix = mcmc(model, data, inits, iterations, burnin=burnin, thin=thin, chains=chains, verbose=false)\n",
    "showsummary(sim_mix, show_describe=false, show_gelman=false)\n",
    "show_all_results(dist_true, Y, sim_mix, xmax=4.5,\n",
    "    dist_model=mixnormal, link_model=link_mixnormal, unlink_model=unlink_mixnormal)\n",
    "\n",
    "iterations = 500\n",
    "burnin = 100\n",
    "thin = 1\n",
    "chains = 4\n",
    "model, data, inits = sample2model_normal1(Y, chains=chains)\n",
    "@time sim_normal1 = mcmc(model, data, inits, iterations, burnin=burnin, thin=thin, chains=chains, verbose=false)\n",
    "showsummary(sim_normal1, show_describe=false, show_gelman=false)\n",
    "show_all_results(dist_true, Y, sim_normal1, xmax=4.5, \n",
    "    dist_model=normal1, link_model=link_normal1, unlink_model=unlink_normal1)\n",
    "\n",
    "iterations = 500\n",
    "burnin = 100\n",
    "thin = 1\n",
    "chains = 4\n",
    "model, data, inits = sample2model_normal(Y, chains=chains)\n",
    "@time sim_normal = mcmc(model, data, inits, iterations, burnin=burnin, thin=thin, chains=chains, verbose=false)\n",
    "showsummary(sim_normal, show_describe=false, show_gelman=false)\n",
    "show_all_results(dist_true, Y, sim_normal, xmax=4.5, \n",
    "    dist_model=normal, link_model=link_normal, unlink_model=unlink_normal)\n",
    "\n",
    "end end end; # macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シミュレーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_true = Normal{Float64}(μ=0.0, σ=1.0)\n",
      "n = 32\n",
      "\n",
      " 25.618951 seconds (104.85 M allocations: 2.901 GiB, 3.45% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\r\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: objects of type Array{Float64,2} are not callable\nUse square brackets [] for indexing an Array.",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type Array{Float64,2} are not callable\nUse square brackets [] for indexing an Array.",
      "",
      "Stacktrace:",
      " [1] mapreduce_first(::Array{Float64,2}, ::Function, ::Int64) at .\\reduce.jl:392",
      " [2] mapreduce(::Array{Float64,2}, ::Function, ::Int64) at .\\reduce.jl:419",
      " [3] sum(::Array{Float64,2}, ::Int64) at .\\reduce.jl:494",
      " [4] makefunc_E2nLn(::Array{Float64,2}) at .\\In[16]:9",
      " [5] WBICof(::Array{Float64,2}) at .\\In[17]:2",
      " [6] statsof(::ModelChains, ::Array{Float64,1}; dist_true::Normal{Float64}, dist_model::typeof(mixnormal), link_model::Function, unlink_model::Function) at .\\In[20]:15",
      " [7] show_all_results(::Normal{Float64}, ::Array{Float64,1}, ::ModelChains; statsfunc::Function, dist_model::Function, link_model::Function, unlink_model::Function, figsize::Tuple{Int64,Float64}, xmin::Float64, xmax::Float64) at .\\In[21]:4",
      " [8] top-level scope at .\\In[24]:23 [inlined]",
      " [9] top-level scope at .\\In[25]:0",
      " [10] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "@simonce(4649, 2^5, Normal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "汎化損失だけは mixnormal モデルが最も小さいが, 他は normal1 モデルが最も小さくなっている. 汎化損失は真の分布をカンニングしないと計算できないので, サンプルだけから計算できる情報量規準でモデル選択すると normal1 モデルが選択されることになる. mixnormal, normal1, normal モデルはどれも真の分布である標準正規分布を含むが, その中で最も単純なモデルが normal1 なので, もしもnormal1が選択されたのであれば最も望ましい結果になったと言える.\n",
    "\n",
    "**汎化損失の比較:**\n",
    "\n",
    "* GenLoss_mixnormal = 94.93636379655361\n",
    "* GenLoss_normal1   = 95.42506541805591\n",
    "* GenLoss_normal    = 95.47037034565636\n",
    "\n",
    "**WAICの比較:**\n",
    "\n",
    "* WAIC_mixnormal = 95.3158398699402 = 93.04112941153926 + 2.2747104584009405\n",
    "* WAIC_normal1   = 95.04348739824401 = 93.0925423020421 + 1.9509450962019106\n",
    "* WAIC_normal    = 97.3731984764354 = 93.33549023479857 + 4.037708241636829\n",
    "\n",
    "**LOOCVの比較:**\n",
    "\n",
    "* LOOCV_mixnormal = 95.320310712043\n",
    "* LOOCV_normal1   = 95.04532852881752\n",
    "* LOOCV_normal    = 97.36293296471752\n",
    "\n",
    "**FreeEnergyの比較:**\n",
    "\n",
    "* FreeEnergy_mixnormal = 96.3665833145624\n",
    "* FreeEnergy_normal1   = 95.05669751909502\n",
    "* FreeEnergy_normal    = 95.05669751909502\n",
    "\n",
    "**WBICの比較:**\n",
    "\n",
    "* WBIC_mixnormal = 97.37210472588768\n",
    "* WBIC_normal1   = 95.48354480264267\n",
    "* WBIC_normal    = 98.03605673034451\n",
    "\n",
    "しかし, 以下の例を見ると, 常に normal1 が選択されるわけではないし, 情報量規準によって選択されるモデルが変化することがあることもわかる. このようなシミュレーションを大量に行って, どれだけの確率で何が選択されるかを確認する必要がありそうだ. サンプルサイズの違いの影響も見る必要があるだろう."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_true = Normal{Float64}(μ=0.0, σ=1.0)\n",
      "n = 32\n",
      "\n",
      " 15.844535 seconds (89.35 M allocations: 2.209 GiB, 2.56% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\r\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: objects of type Array{Float64,2} are not callable\nUse square brackets [] for indexing an Array.",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type Array{Float64,2} are not callable\nUse square brackets [] for indexing an Array.",
      "",
      "Stacktrace:",
      " [1] mapreduce_first(::Array{Float64,2}, ::Function, ::Int64) at .\\reduce.jl:392",
      " [2] mapreduce(::Array{Float64,2}, ::Function, ::Int64) at .\\reduce.jl:419",
      " [3] sum(::Array{Float64,2}, ::Int64) at .\\reduce.jl:494",
      " [4] makefunc_E2nLn(::Array{Float64,2}) at .\\In[16]:9",
      " [5] WBICof(::Array{Float64,2}) at .\\In[17]:2",
      " [6] statsof(::ModelChains, ::Array{Float64,1}; dist_true::Normal{Float64}, dist_model::typeof(mixnormal), link_model::Function, unlink_model::Function) at .\\In[20]:15",
      " [7] show_all_results(::Normal{Float64}, ::Array{Float64,1}, ::ModelChains; statsfunc::Function, dist_model::Function, link_model::Function, unlink_model::Function, figsize::Tuple{Int64,Float64}, xmin::Float64, xmax::Float64) at .\\In[21]:4",
      " [8] top-level scope at .\\In[24]:23 [inlined]",
      " [9] top-level scope at .\\In[26]:0",
      " [10] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "@simonce(12345, 2^5, Normal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_true = Normal{Float64}(μ=0.0, σ=1.0)\n",
      "n = 32\n",
      "\n",
      " 17.206398 seconds (89.78 M allocations: 2.220 GiB, 2.45% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\r\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: objects of type Array{Float64,2} are not callable\nUse square brackets [] for indexing an Array.",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type Array{Float64,2} are not callable\nUse square brackets [] for indexing an Array.",
      "",
      "Stacktrace:",
      " [1] mapreduce_first(::Array{Float64,2}, ::Function, ::Int64) at .\\reduce.jl:392",
      " [2] mapreduce(::Array{Float64,2}, ::Function, ::Int64) at .\\reduce.jl:419",
      " [3] sum(::Array{Float64,2}, ::Int64) at .\\reduce.jl:494",
      " [4] makefunc_E2nLn(::Array{Float64,2}) at .\\In[16]:9",
      " [5] WBICof(::Array{Float64,2}) at .\\In[17]:2",
      " [6] statsof(::ModelChains, ::Array{Float64,1}; dist_true::Normal{Float64}, dist_model::typeof(mixnormal), link_model::Function, unlink_model::Function) at .\\In[20]:15",
      " [7] show_all_results(::Normal{Float64}, ::Array{Float64,1}, ::ModelChains; statsfunc::Function, dist_model::Function, link_model::Function, unlink_model::Function, figsize::Tuple{Int64,Float64}, xmin::Float64, xmax::Float64) at .\\In[21]:4",
      " [8] top-level scope at .\\In[24]:23 [inlined]",
      " [9] top-level scope at .\\In[27]:0",
      " [10] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "@simonce(2017, 2^5, Normal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サンプルサイズを512にしてみる。\n",
    "FreeEnergyof 函数で使用している E2nLn 函数にバグがあったので修正した。\n",
    "以前のバージョンでは n=2^9 で Domain Error が出ていた。\n",
    "C:/JuliaPkg/v0.6/QuadGK/src/QuadGK.jl の第86行を見よ。\n",
    "以下は修正がうまく行っているかどうかのテスト。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_true = Normal{Float64}(μ=0.0, σ=1.0)\n",
      "n = 512\n",
      "\n",
      "591.038274 seconds (3.34 G allocations: 78.466 GiB, 2.36% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\r\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: objects of type Array{Float64,2} are not callable\nUse square brackets [] for indexing an Array.",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type Array{Float64,2} are not callable\nUse square brackets [] for indexing an Array.",
      "",
      "Stacktrace:",
      " [1] mapreduce_first(::Array{Float64,2}, ::Function, ::Int64) at .\\reduce.jl:392",
      " [2] mapreduce(::Array{Float64,2}, ::Function, ::Int64) at .\\reduce.jl:419",
      " [3] sum(::Array{Float64,2}, ::Int64) at .\\reduce.jl:494",
      " [4] makefunc_E2nLn(::Array{Float64,2}) at .\\In[16]:9",
      " [5] WBICof(::Array{Float64,2}) at .\\In[17]:2",
      " [6] statsof(::ModelChains, ::Array{Float64,1}; dist_true::Normal{Float64}, dist_model::typeof(mixnormal), link_model::Function, unlink_model::Function) at .\\In[20]:15",
      " [7] show_all_results(::Normal{Float64}, ::Array{Float64,1}, ::ModelChains; statsfunc::Function, dist_model::Function, link_model::Function, unlink_model::Function, figsize::Tuple{Int64,Float64}, xmin::Float64, xmax::Float64) at .\\In[21]:4",
      " [8] top-level scope at .\\In[24]:23 [inlined]",
      " [9] top-level scope at .\\In[28]:0",
      " [10] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "@simonce(4649, 2^9, Normal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 複数回の比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InformationCriterions (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function InformationCriterions(dist_true, Y, sim; dist_model=mixnormal)\n",
    "    n = length(Y)\n",
    "    lpdf(w, y) = logpdf(dist_model(w), y)\n",
    "\n",
    "    loglikchainof = makefunc_loglikchainof(lpdf, sort(keys(sim)), Y)\n",
    "    loglik, chain = loglikchainof(sim)\n",
    "\n",
    "    WAIC, T_WAIC, V_WAIC = WAICof(loglik)\n",
    "    LOOCV = LOOCVof(loglik)\n",
    "    \n",
    "    pred_Bayes = makefunc_pdfpred(lpdf, chain)\n",
    "    GL = 2*n*GeneralizationLossof(x->pdf(dist_true,x), pred_Bayes)[1]\n",
    "    \n",
    "    WBIC = WBICof(loglik)\n",
    "    FreeEnergy = FreeEnergyof(loglik)[1]\n",
    "\n",
    "    return chain, WAIC, T_WAIC, V_WAIC, LOOCV, GL, WBIC, FreeEnergy\n",
    " end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サイズ n = 8, 32, 128 のサンプルをそれぞれ1000個生成して推定\n",
    "\n",
    "計算結果はファイルに保存される.\n",
    "\n",
    "以下の場所からデータファイルをダウンロードしてこのノートブックと同じ場所に置いておけば, この節のセルを実行する必要はない.\n",
    "\n",
    "https://genkuroki.github.io/documents/Jupyter/#2017-11-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching Array{Array{Float64,N} where N,N} where N(::Int64)\nClosest candidates are:\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64) where T at boot.jl:420\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64) where T at boot.jl:421\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64, !Matched::Int64) where T at boot.jl:422\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Array{Array{Float64,N} where N,N} where N(::Int64)\nClosest candidates are:\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64) where T at boot.jl:420\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64) where T at boot.jl:421\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64, !Matched::Int64) where T at boot.jl:422\n  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[30]:27",
      " [2] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "dataname = \"DataStandardNormalSample8Case4649\"\n",
    "seed = 4649\n",
    "Nsims = 1000\n",
    "dist_true = Normal()\n",
    "n = 2^3\n",
    "\n",
    "##########\n",
    "\n",
    "Shannon = 2*n*entropy(dist_true)\n",
    "\n",
    "iterations_mixnormal = 500\n",
    "burnin_mixnormal = 100\n",
    "thin_mixnormal = 1\n",
    "chains_mixnormal = 4\n",
    "\n",
    "iterations_normal1 = 500\n",
    "burnin_normal1 = 100\n",
    "thin_normal1 = 1\n",
    "chains_normal1 = 4\n",
    "\n",
    "iterations_normal = 500\n",
    "burnin_normal = 100\n",
    "thin_normal = 1\n",
    "chains_normal = 4\n",
    "\n",
    "N = Nsims\n",
    "Sample = Array{Array{Float64}}(N)\n",
    "T_true = Array{Float64}(N)\n",
    "\n",
    "Chain_mixnormal = Array{Array{Float64,2}}(N)\n",
    "WAIC_mixnormal = Array{Float64}(N)\n",
    "T_mixnormal = Array{Float64}(N)\n",
    "V_mixnormal = Array{Float64}(N)\n",
    "LOOCV_mixnormal = Array{Float64}(N)\n",
    "GL_mixnormal = Array{Float64}(N)\n",
    "WBIC_mixnormal = Array{Float64}(N)\n",
    "FreeEnergy_mixnormal = Array{Float64}(N)\n",
    "\n",
    "Chain_normal1 = Array{Array{Float64,2}}(N)\n",
    "WAIC_normal1 = Array{Float64}(N)\n",
    "T_normal1 = Array{Float64}(N)\n",
    "V_normal1 = Array{Float64}(N)\n",
    "LOOCV_normal1 = Array{Float64}(N)\n",
    "GL_normal1 = Array{Float64}(N)\n",
    "WBIC_normal1 = Array{Float64}(N)\n",
    "FreeEnergy_normal1 = Array{Float64}(N)\n",
    "\n",
    "Chain_normal = Array{Array{Float64,2}}(N)\n",
    "WAIC_normal = Array{Float64}(N)\n",
    "T_normal = Array{Float64}(N)\n",
    "V_normal = Array{Float64}(N)\n",
    "LOOCV_normal = Array{Float64}(N)\n",
    "GL_normal = Array{Float64}(N)\n",
    "WBIC_normal = Array{Float64}(N)\n",
    "FreeEnergy_normal = Array{Float64}(N)\n",
    "\n",
    "@time for i in 1:N\n",
    "    Y = rand(dist_true, n)\n",
    "    Sample[i] = Y\n",
    "    T_true[i] = -2*@sum(logpdf(dist_true, Y[k]), k, 1:n)\n",
    "\n",
    "    # mixnormal\n",
    "    #\n",
    "    model_mixnormal, data_mixnormal, inits_mixnormal = sample2model_mixnormal(Y, chains=chains_mixnormal)\n",
    "    sim_mixnormal = mcmc(model_mixnormal, data_mixnormal, inits_mixnormal,\n",
    "        iterations_mixnormal, burnin=burnin_mixnormal, thin=thin_mixnormal, chains=chains_mixnormal, verbose=false)\n",
    "\n",
    "    Chain_mixnormal[i], WAIC_mixnormal[i], T_mixnormal[i], V_mixnormal[i], \n",
    "    LOOCV_mixnormal[i], GL_mixnormal[i], WBIC_mixnormal[i], FreeEnergy_mixnormal[i] = \n",
    "    InformationCriterions(dist_true, Y, sim_mixnormal, dist_model=mixnormal)\n",
    "    \n",
    "    # normal1\n",
    "    #\n",
    "    model_normal1, data_normal1, inits_normal1 = sample2model_normal1(Y, chains=chains_normal1)\n",
    "    sim_normal1 = mcmc(model_normal1, data_normal1, inits_normal1,\n",
    "        iterations_normal1, burnin=burnin_normal1, thin=thin_normal1, chains=chains_normal1, verbose=false)\n",
    "\n",
    "    Chain_normal1[i], WAIC_normal1[i], T_normal1[i], V_normal1[i], \n",
    "    LOOCV_normal1[i], GL_normal1[i], WBIC_normal1[i], FreeEnergy_normal1[i] = \n",
    "    InformationCriterions(dist_true, Y, sim_normal1, dist_model=normal1)\n",
    "\n",
    "    # normal\n",
    "    #\n",
    "    model_normal, data_normal, inits_normal = sample2model_normal(Y, chains=chains_normal)\n",
    "    sim_normal = mcmc(model_normal, data_normal, inits_normal,\n",
    "        iterations_normal, burnin=burnin_normal, thin=thin_normal, chains=chains_normal, verbose=false)\n",
    "\n",
    "    Chain_normal[i], WAIC_normal[i], T_normal[i], V_normal[i], \n",
    "    LOOCV_normal[i], GL_normal[i], WBIC_normal[i], FreeEnergy_normal[i] = \n",
    "    InformationCriterions(dist_true, Y, sim_normal, dist_model=normal)\n",
    "    \n",
    "    print(\"$i \")\n",
    "    i == N && println()\n",
    "end\n",
    "\n",
    "#########\n",
    "\n",
    "varnames = [\n",
    "    \"seed\", \"dist_true\", \"n\", \"Shannon\",\n",
    "    \"iterations_mixnormal\", \"burnin_mixnormal\", \"thin_mixnormal\", \"chains_mixnormal\",\n",
    "    \"iterations_normal1\",   \"burnin_normal1\",   \"thin_normal1\",   \"chains_normal1\",\n",
    "    \"iterations_normal\",    \"burnin_normal\",    \"thin_normal\",    \"chains_normal\",\n",
    "    \"Nsims\", \"Sample\", \"T_true\", \n",
    "    \"Chain_mixnormal\", \"WAIC_mixnormal\", \"T_mixnormal\",    \"V_mixnormal\", \n",
    "    \"LOOCV_mixnormal\", \"GL_mixnormal\",   \"WBIC_mixnormal\", \"FreeEnergy_mixnormal\", \n",
    "    \"Chain_normal1\",   \"WAIC_normal1\",   \"T_normal1\",      \"V_normal1\", \n",
    "    \"LOOCV_normal1\",   \"GL_normal1\",     \"WBIC_normal1\",   \"FreeEnergy_normal1\", \n",
    "    \"Chain_normal\",    \"WAIC_normal\",    \"T_normal\",       \"V_normal\", \n",
    "    \"LOOCV_normal\",    \"GL_normal\",      \"WBIC_normal\",    \"FreeEnergy_normal\", \n",
    "]\n",
    "eval(parse(\"$dataname = Dict()\"))\n",
    "for v in sort(varnames)\n",
    "    eval(parse(\"$dataname[\\\"$v\\\"] = $v\"))\n",
    "end\n",
    "\n",
    "@show jld2file = \"$dataname.jld2\"\n",
    "eval(parse(\"save(jld2file, $dataname)\"))\n",
    "data = load(\"$dataname.jld2\")\n",
    "@show keys(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching Array{Array{Float64,N} where N,N} where N(::Int64)\nClosest candidates are:\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64) where T at boot.jl:420\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64) where T at boot.jl:421\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64, !Matched::Int64) where T at boot.jl:422\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Array{Array{Float64,N} where N,N} where N(::Int64)\nClosest candidates are:\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64) where T at boot.jl:420\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64) where T at boot.jl:421\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64, !Matched::Int64) where T at boot.jl:422\n  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[31]:27",
      " [2] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "dataname = \"DataStandardNormalSample32Case4649\"\n",
    "seed = 4649\n",
    "Nsims = 1000\n",
    "dist_true = Normal()\n",
    "n = 2^5\n",
    "\n",
    "##########\n",
    "\n",
    "Shannon = 2*n*entropy(dist_true)\n",
    "\n",
    "iterations_mixnormal = 500\n",
    "burnin_mixnormal = 100\n",
    "thin_mixnormal = 1\n",
    "chains_mixnormal = 4\n",
    "\n",
    "iterations_normal1 = 500\n",
    "burnin_normal1 = 100\n",
    "thin_normal1 = 1\n",
    "chains_normal1 = 4\n",
    "\n",
    "iterations_normal = 500\n",
    "burnin_normal = 100\n",
    "thin_normal = 1\n",
    "chains_normal = 4\n",
    "\n",
    "N = Nsims\n",
    "Sample = Array{Array{Float64}}(N)\n",
    "T_true = Array{Float64}(N)\n",
    "\n",
    "Chain_mixnormal = Array{Array{Float64,2}}(N)\n",
    "WAIC_mixnormal = Array{Float64}(N)\n",
    "T_mixnormal = Array{Float64}(N)\n",
    "V_mixnormal = Array{Float64}(N)\n",
    "LOOCV_mixnormal = Array{Float64}(N)\n",
    "GL_mixnormal = Array{Float64}(N)\n",
    "WBIC_mixnormal = Array{Float64}(N)\n",
    "FreeEnergy_mixnormal = Array{Float64}(N)\n",
    "\n",
    "Chain_normal1 = Array{Array{Float64,2}}(N)\n",
    "WAIC_normal1 = Array{Float64}(N)\n",
    "T_normal1 = Array{Float64}(N)\n",
    "V_normal1 = Array{Float64}(N)\n",
    "LOOCV_normal1 = Array{Float64}(N)\n",
    "GL_normal1 = Array{Float64}(N)\n",
    "WBIC_normal1 = Array{Float64}(N)\n",
    "FreeEnergy_normal1 = Array{Float64}(N)\n",
    "\n",
    "Chain_normal = Array{Array{Float64,2}}(N)\n",
    "WAIC_normal = Array{Float64}(N)\n",
    "T_normal = Array{Float64}(N)\n",
    "V_normal = Array{Float64}(N)\n",
    "LOOCV_normal = Array{Float64}(N)\n",
    "GL_normal = Array{Float64}(N)\n",
    "WBIC_normal = Array{Float64}(N)\n",
    "FreeEnergy_normal = Array{Float64}(N)\n",
    "\n",
    "@time for i in 1:N\n",
    "    Y = rand(dist_true, n)\n",
    "    Sample[i] = Y\n",
    "    T_true[i] = -2*@sum(logpdf(dist_true, Y[k]), k, 1:n)\n",
    "\n",
    "    # mixnormal\n",
    "    #\n",
    "    model_mixnormal, data_mixnormal, inits_mixnormal = sample2model_mixnormal(Y, chains=chains_mixnormal)\n",
    "    sim_mixnormal = mcmc(model_mixnormal, data_mixnormal, inits_mixnormal,\n",
    "        iterations_mixnormal, burnin=burnin_mixnormal, thin=thin_mixnormal, chains=chains_mixnormal, verbose=false)\n",
    "\n",
    "    Chain_mixnormal[i], WAIC_mixnormal[i], T_mixnormal[i], V_mixnormal[i], \n",
    "    LOOCV_mixnormal[i], GL_mixnormal[i], WBIC_mixnormal[i], FreeEnergy_mixnormal[i] = \n",
    "    InformationCriterions(dist_true, Y, sim_mixnormal, dist_model=mixnormal)\n",
    "    \n",
    "    # normal1\n",
    "    #\n",
    "    model_normal1, data_normal1, inits_normal1 = sample2model_normal1(Y, chains=chains_normal1)\n",
    "    sim_normal1 = mcmc(model_normal1, data_normal1, inits_normal1,\n",
    "        iterations_normal1, burnin=burnin_normal1, thin=thin_normal1, chains=chains_normal1, verbose=false)\n",
    "\n",
    "    Chain_normal1[i], WAIC_normal1[i], T_normal1[i], V_normal1[i], \n",
    "    LOOCV_normal1[i], GL_normal1[i], WBIC_normal1[i], FreeEnergy_normal1[i] = \n",
    "    InformationCriterions(dist_true, Y, sim_normal1, dist_model=normal1)\n",
    "\n",
    "    # normal\n",
    "    #\n",
    "    model_normal, data_normal, inits_normal = sample2model_normal(Y, chains=chains_normal)\n",
    "    sim_normal = mcmc(model_normal, data_normal, inits_normal,\n",
    "        iterations_normal, burnin=burnin_normal, thin=thin_normal, chains=chains_normal, verbose=false)\n",
    "\n",
    "    Chain_normal[i], WAIC_normal[i], T_normal[i], V_normal[i], \n",
    "    LOOCV_normal[i], GL_normal[i], WBIC_normal[i], FreeEnergy_normal[i] = \n",
    "    InformationCriterions(dist_true, Y, sim_normal, dist_model=normal)\n",
    "    \n",
    "    print(\"$i \")\n",
    "    i == N && println()\n",
    "end\n",
    "\n",
    "#########\n",
    "\n",
    "varnames = [\n",
    "    \"seed\", \"dist_true\", \"n\", \"Shannon\",\n",
    "    \"iterations_mixnormal\", \"burnin_mixnormal\", \"thin_mixnormal\", \"chains_mixnormal\",\n",
    "    \"iterations_normal1\",   \"burnin_normal1\",   \"thin_normal1\",   \"chains_normal1\",\n",
    "    \"iterations_normal\",    \"burnin_normal\",    \"thin_normal\",    \"chains_normal\",\n",
    "    \"Nsims\", \"Sample\", \"T_true\", \n",
    "    \"Chain_mixnormal\", \"WAIC_mixnormal\", \"T_mixnormal\",    \"V_mixnormal\", \n",
    "    \"LOOCV_mixnormal\", \"GL_mixnormal\",   \"WBIC_mixnormal\", \"FreeEnergy_mixnormal\", \n",
    "    \"Chain_normal1\",   \"WAIC_normal1\",   \"T_normal1\",      \"V_normal1\", \n",
    "    \"LOOCV_normal1\",   \"GL_normal1\",     \"WBIC_normal1\",   \"FreeEnergy_normal1\", \n",
    "    \"Chain_normal\",    \"WAIC_normal\",    \"T_normal\",       \"V_normal\", \n",
    "    \"LOOCV_normal\",    \"GL_normal\",      \"WBIC_normal\",    \"FreeEnergy_normal\", \n",
    "]\n",
    "eval(parse(\"$dataname = Dict()\"))\n",
    "for v in sort(varnames)\n",
    "    eval(parse(\"$dataname[\\\"$v\\\"] = $v\"))\n",
    "end\n",
    "\n",
    "@show jld2file = \"$dataname.jld2\"\n",
    "eval(parse(\"save(jld2file, $dataname)\"))\n",
    "data = load(\"$dataname.jld2\")\n",
    "@show keys(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching Array{Array{Float64,N} where N,N} where N(::Int64)\nClosest candidates are:\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64) where T at boot.jl:420\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64) where T at boot.jl:421\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64, !Matched::Int64) where T at boot.jl:422\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Array{Array{Float64,N} where N,N} where N(::Int64)\nClosest candidates are:\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64) where T at boot.jl:420\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64) where T at boot.jl:421\n  Array{Array{Float64,N} where N,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64, !Matched::Int64) where T at boot.jl:422\n  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[32]:27",
      " [2] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "dataname = \"DataStandardNormalSample128Case4649\"\n",
    "seed = 4649\n",
    "Nsims = 1000\n",
    "dist_true = Normal()\n",
    "n = 2^7\n",
    "\n",
    "##########\n",
    "\n",
    "Shannon = 2*n*entropy(dist_true)\n",
    "\n",
    "iterations_mixnormal = 500\n",
    "burnin_mixnormal = 100\n",
    "thin_mixnormal = 1\n",
    "chains_mixnormal = 4\n",
    "\n",
    "iterations_normal1 = 500\n",
    "burnin_normal1 = 100\n",
    "thin_normal1 = 1\n",
    "chains_normal1 = 4\n",
    "\n",
    "iterations_normal = 500\n",
    "burnin_normal = 100\n",
    "thin_normal = 1\n",
    "chains_normal = 4\n",
    "\n",
    "N = Nsims\n",
    "Sample = Array{Array{Float64}}(N)\n",
    "T_true = Array{Float64}(N)\n",
    "\n",
    "Chain_mixnormal = Array{Array{Float64,2}}(N)\n",
    "WAIC_mixnormal = Array{Float64}(N)\n",
    "T_mixnormal = Array{Float64}(N)\n",
    "V_mixnormal = Array{Float64}(N)\n",
    "LOOCV_mixnormal = Array{Float64}(N)\n",
    "GL_mixnormal = Array{Float64}(N)\n",
    "WBIC_mixnormal = Array{Float64}(N)\n",
    "FreeEnergy_mixnormal = Array{Float64}(N)\n",
    "\n",
    "Chain_normal1 = Array{Array{Float64,2}}(N)\n",
    "WAIC_normal1 = Array{Float64}(N)\n",
    "T_normal1 = Array{Float64}(N)\n",
    "V_normal1 = Array{Float64}(N)\n",
    "LOOCV_normal1 = Array{Float64}(N)\n",
    "GL_normal1 = Array{Float64}(N)\n",
    "WBIC_normal1 = Array{Float64}(N)\n",
    "FreeEnergy_normal1 = Array{Float64}(N)\n",
    "\n",
    "Chain_normal = Array{Array{Float64,2}}(N)\n",
    "WAIC_normal = Array{Float64}(N)\n",
    "T_normal = Array{Float64}(N)\n",
    "V_normal = Array{Float64}(N)\n",
    "LOOCV_normal = Array{Float64}(N)\n",
    "GL_normal = Array{Float64}(N)\n",
    "WBIC_normal = Array{Float64}(N)\n",
    "FreeEnergy_normal = Array{Float64}(N)\n",
    "\n",
    "@time for i in 1:N\n",
    "    Y = rand(dist_true, n)\n",
    "    Sample[i] = Y\n",
    "    T_true[i] = -2*@sum(logpdf(dist_true, Y[k]), k, 1:n)\n",
    "\n",
    "    # mixnormal\n",
    "    #\n",
    "    model_mixnormal, data_mixnormal, inits_mixnormal = sample2model_mixnormal(Y, chains=chains_mixnormal)\n",
    "    sim_mixnormal = mcmc(model_mixnormal, data_mixnormal, inits_mixnormal,\n",
    "        iterations_mixnormal, burnin=burnin_mixnormal, thin=thin_mixnormal, chains=chains_mixnormal, verbose=false)\n",
    "\n",
    "    Chain_mixnormal[i], WAIC_mixnormal[i], T_mixnormal[i], V_mixnormal[i], \n",
    "    LOOCV_mixnormal[i], GL_mixnormal[i], WBIC_mixnormal[i], FreeEnergy_mixnormal[i] = \n",
    "    InformationCriterions(dist_true, Y, sim_mixnormal, dist_model=mixnormal)\n",
    "    \n",
    "    # normal1\n",
    "    #\n",
    "    model_normal1, data_normal1, inits_normal1 = sample2model_normal1(Y, chains=chains_normal1)\n",
    "    sim_normal1 = mcmc(model_normal1, data_normal1, inits_normal1,\n",
    "        iterations_normal1, burnin=burnin_normal1, thin=thin_normal1, chains=chains_normal1, verbose=false)\n",
    "\n",
    "    Chain_normal1[i], WAIC_normal1[i], T_normal1[i], V_normal1[i], \n",
    "    LOOCV_normal1[i], GL_normal1[i], WBIC_normal1[i], FreeEnergy_normal1[i] = \n",
    "    InformationCriterions(dist_true, Y, sim_normal1, dist_model=normal1)\n",
    "\n",
    "    # normal\n",
    "    #\n",
    "    model_normal, data_normal, inits_normal = sample2model_normal(Y, chains=chains_normal)\n",
    "    sim_normal = mcmc(model_normal, data_normal, inits_normal,\n",
    "        iterations_normal, burnin=burnin_normal, thin=thin_normal, chains=chains_normal, verbose=false)\n",
    "\n",
    "    Chain_normal[i], WAIC_normal[i], T_normal[i], V_normal[i], \n",
    "    LOOCV_normal[i], GL_normal[i], WBIC_normal[i], FreeEnergy_normal[i] = \n",
    "    InformationCriterions(dist_true, Y, sim_normal, dist_model=normal)\n",
    "    \n",
    "    print(\"$i \")\n",
    "    i == N && println()\n",
    "end\n",
    "\n",
    "#########\n",
    "\n",
    "varnames = [\n",
    "    \"seed\", \"dist_true\", \"n\", \"Shannon\",\n",
    "    \"iterations_mixnormal\", \"burnin_mixnormal\", \"thin_mixnormal\", \"chains_mixnormal\",\n",
    "    \"iterations_normal1\",   \"burnin_normal1\",   \"thin_normal1\",   \"chains_normal1\",\n",
    "    \"iterations_normal\",    \"burnin_normal\",    \"thin_normal\",    \"chains_normal\",\n",
    "    \"Nsims\", \"Sample\", \"T_true\", \n",
    "    \"Chain_mixnormal\", \"WAIC_mixnormal\", \"T_mixnormal\",    \"V_mixnormal\", \n",
    "    \"LOOCV_mixnormal\", \"GL_mixnormal\",   \"WBIC_mixnormal\", \"FreeEnergy_mixnormal\", \n",
    "    \"Chain_normal1\",   \"WAIC_normal1\",   \"T_normal1\",      \"V_normal1\", \n",
    "    \"LOOCV_normal1\",   \"GL_normal1\",     \"WBIC_normal1\",   \"FreeEnergy_normal1\", \n",
    "    \"Chain_normal\",    \"WAIC_normal\",    \"T_normal\",       \"V_normal\", \n",
    "    \"LOOCV_normal\",    \"GL_normal\",      \"WBIC_normal\",    \"FreeEnergy_normal\", \n",
    "]\n",
    "eval(parse(\"$dataname = Dict()\"))\n",
    "for v in sort(varnames)\n",
    "    eval(parse(\"$dataname[\\\"$v\\\"] = $v\"))\n",
    "end\n",
    "\n",
    "@show jld2file = \"$dataname.jld2\"\n",
    "eval(parse(\"save(jld2file, $dataname)\"))\n",
    "data = load(\"$dataname.jld2\")\n",
    "@show keys(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: No file exists at given path: DataStandardNormalSample128Case4649.jld2",
     "output_type": "error",
     "traceback": [
      "ArgumentError: No file exists at given path: DataStandardNormalSample128Case4649.jld2",
      "",
      "Stacktrace:",
      " [1] load(::Formatted; options::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:192",
      " [2] load at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:187 [inlined]",
      " [3] #load#16 at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:136 [inlined]",
      " [4] load(::String) at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:136",
      " [5] top-level scope at In[33]:3",
      " [6] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "#data = load(\"DataStandardNormalSample8Case4649.jld2\")\n",
    "#data = load(\"DataStandardNormalSample32Case4649.jld2\")\n",
    "data = load(\"DataStandardNormalSample128Case4649.jld2\")\n",
    "for v in sort(collect(keys(data)))\n",
    "    ex = parse(\"$v = data[\\\"$v\\\"]\")\n",
    "    println(ex)\n",
    "    eval(ex)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shannon = 363.2482645003962\n",
      "n * log(2pi) + n = 363.2482645003962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "363.2482645003962"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show Shannon\n",
    "@show n*log(2pi) + n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### シミュレーション結果のプロット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率分布 $q(x)$ で独立生成したサンプルを $X_1,\\ldots,X_n$ と書き, 推定用の確率モデルを $p(x|w)$ と書き, 予測分布を $p^*(x)$ と書く. 以下で採用したスケールはすべて伝統的なAICのスケール(対数尤度比のカイ二乗検定のスケール)に合わせてある. \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\n",
    "\\mathrm{S} = \\mathrm{Shannon} = -2n\\int q(x)\\log q(x)\\,dx,\n",
    "\\\\ &\n",
    "\\mathrm{GL} = \\text{Generalization Loss} = -2n\\int q(x)\\log p^*(x)\\,dx,\n",
    "\\\\ &\n",
    "\\mathrm{KL} = \\text{Kullback-Leibler} = \\mathrm{GL} - \\mathrm{S} = 2n\\int q(x)\\log\\frac{q(x)}{p^*(x)}\\,dx,\n",
    "\\\\ &\n",
    "\\mathrm{T}_\\mathrm{true} = -2\\sum_{k=1}^n \\log q(X_k),\n",
    "\\\\ &\n",
    "\\mathrm{T} = -2\\sum_{k=1}^n \\log p^*(X_k),\n",
    "\\\\ &\n",
    "\\mathrm{TT} = \\mathrm{T} - \\mathrm{T}_\\mathrm{true} = 2\\sum_{k=1}^n\\log\\frac{q(X_k)}{p^*(X_k)},\n",
    "\\\\ &\n",
    "\\mathrm{V} = 2\\sum_{k=1}^n (\\text{posterior variance of}\\ \\log p(X_k|w))\n",
    "\\\\ &\n",
    "\\mathrm{WAIC} = T + V,\n",
    "\\\\ &\n",
    "\\mathrm{WT} = \\mathrm{WAIC} - \\mathrm{T}_\\mathrm{true} = \\mathrm{TT} + \\mathrm{V},\n",
    "\\\\ &\n",
    "\\mathrm{KW} = \\mathrm{KL} + \\mathrm{WT} = (\\mathrm{GL} - \\mathrm{S}) + (\\mathrm{WAIC} - \\mathrm{T}).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "最後の $\\mathrm{KW}$ の定義が差ではなく和になっていることに注意せよ.\n",
    "\n",
    "渡辺澄夫著『ベイズ統計の理論と方法』の第4章の定理12(p.114)の $\\beta=1$ の場合は, 以上で採用した記号とスケールのもとで以下のように書き直される:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\n",
    "\\mathrm{GL} = \\mathrm{S} + 2\\lambda + \\langle\\sqrt{t}\\;\\xi_n(u)\\rangle - V(\\xi_n) + o_p(1),\n",
    "\\\\ &\n",
    "\\mathrm{T}  = \\mathrm{S} + 2\\lambda - \\langle\\sqrt{t}\\;\\xi_n(u)\\rangle - V(\\xi_n) + o_p(1).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "ゆえに\n",
    "\n",
    "$$\n",
    "\\mathrm{GL} = \\mathrm{T} + 2\\langle\\sqrt{t}\\;\\xi_n(u)\\rangle + o_p(1).\n",
    "$$\n",
    "\n",
    "同書同章補題23(p.115)より\n",
    "\n",
    "$$\n",
    "E_\\xi\\left[\\langle\\sqrt{t}\\;\\xi(u)\\rangle\\right] = E_\\xi[V(\\xi)]\n",
    "$$\n",
    "\n",
    "であり, 我々の $\\mathrm{V}$ は $2V(\\xi_n)$ と漸近等価である(同書同章の定義22(p.117)の $V_n$ の定義は我々の $\\mathrm{V}/2$ に一致する). サンプルの取り方の変化に関する期待値を $E[\\;\\;]$ と書くと, \n",
    "\n",
    "$$\n",
    "E\\left[\\langle\\sqrt{t}\\;\\xi_n(u)\\rangle - V(\\xi_n)\\right] = o(1), \\quad\n",
    "E\\left[\\langle\\sqrt{t}\\;\\xi_n(u)\\rangle + V(\\xi_n)\\right] = E[\\mathrm{V}] + o(1), \\quad\n",
    "E[\\mathrm{GL}] = E[\\mathrm{T} + \\mathrm{V}] + o(1).\n",
    "$$\n",
    "\n",
    "さらに同書同章補題24(p.118)より\n",
    "\n",
    "$$\n",
    "E[\\mathrm{V}] =  4\\nu + o(1)\n",
    "$$\n",
    "\n",
    "であることに注意せよ. 同書同章定理15(p.119)の $\\beta=1$ の場合は次のように書き直される:\n",
    "\n",
    "$$\n",
    "\\mathrm{KW} = \\mathrm{KL} + \\mathrm{WT} = \n",
    "(\\mathrm{GL} - \\mathrm{S}) + (\\mathrm{WAIC} - \\mathrm{T})= 4\\lambda + o_p(1).\n",
    "$$\n",
    "\n",
    "この公式は期待値を取る前に成立していることに注意せよ. この公式より $\\mathrm{KL}+\\mathrm{WT}$ のゆらぎが $n\\to\\infty$ で0に近付くことがわかる.\n",
    "\n",
    "以上で登場した $\\lambda$, $\\nu$ はそれぞれ**実対数閾値**, **特異ゆらぎ**と呼ばれている. それぞれ同書の p.108, p.117 で定義されている.\n",
    "\n",
    "このノートにおける $\\mathrm{LOOCV}$, $\\mathrm{WBIC}$, $\\mathrm{FreeEnergy}$ の定義は以下の通り:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{LOOCV} &= \n",
    "-2\\sum_{k=1}^n \\log\\left( \\text{posterior mean of}\\ p(X_k|w)\\ \\text{for the sample}\\ X_1,\\ldots,\\widehat X_k,\\ldots,X_n\\right)\n",
    "\\\\ & =\n",
    "2\\sum_{k=1}^n \\log\\left( \\text{posterior mean of}\\ \\frac{1}{p(X_k|w)} \\right),\n",
    "\\\\\n",
    "\\mathrm{WBIC} &= \n",
    "2\\left(\\text{posterior mean of}\\ -\\sum_{k=1}^n \\log p(X_k|w) \\ \\text{at the inverse temperature}\\ \\beta=\\frac{1}{\\log n}\\right),\n",
    "\\\\\n",
    "\\mathrm{FreeEnergy} &= -2\\log Z_n = \n",
    "2\\int_0^1 \\left( \\text{posterior mean of}\\ -\\sum_{k=1}^n \\log p(X_k|w) \\ \\text{at the inverse temperature}\\ \\beta \\right)\\,d\\beta.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "ここで $\\widehat X_k$ は $X_k$ を取り除くことを意味する.\n",
    "\n",
    "逆温度 $\\beta$ での事後分布に関する平均は逆温度 $\\beta=1$ における通常の事後分布に関する平均で計算可能であることに注意せよ.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\n",
    "\\left( \\text{posterior mean of}\\ f(w) \\ \\text{at the inverse temperature}\\ \\beta \\right) = \\frac{N(\\beta)}{D(\\beta)},\n",
    "\\\\&\n",
    "N(\\beta) = \\left(\\text{posterior mean of}\\ f(w)\\left(\\prod_{k=1}^n p(X_k|w)\\right)^{\\beta-1}\\right),\n",
    "\\\\ &\n",
    "D(\\beta) = \\left(\\text{posterior mean of}\\ \\left(\\prod_{k=1}^n p(X_k|w)\\right)^{\\beta-1}\\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**警告・注意 (2018-01-13)**  このノートブックの始めの方に追加した警告・注意でも述べていることだが, 逆温度β=1での事後分布のサンプルを用いてWBICを計算すると誤差が大きくなるので止めた方がよい.  よくよく考えると当たり前のことなのだが, 私は実際にやってみるまで気付かなかった."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plotAllModelSelections (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(symbol, suffix) = eval(Symbol(symbol, :_, suffix))\n",
    "\n",
    "function plotTh12(modelname::String; bins=25)\n",
    "    \n",
    "    GL = s(:GL, modelname)\n",
    "    T  = s(:T, modelname)\n",
    "    V  = s(:V, modelname)\n",
    "    WAIC = s(:WAIC, modelname)\n",
    "    LOOCV = s(:LOOCV, modelname)\n",
    "    WBIC = s(:WBIC, modelname)\n",
    "    FreeEnergy = s(:FreeEnergy, modelname)\n",
    "    \n",
    "    WG = WAIC - GL\n",
    "    LG = LOOCV - GL\n",
    "    LW = LOOCV - WAIC\n",
    "    \n",
    "    KL = GL - Shannon\n",
    "    TT = T - T_true\n",
    "    WT = WAIC - T_true\n",
    "    KW = KL + WT\n",
    "\n",
    "    println(\"\\n========== $modelname model (n = $n)\")\n",
    "    println(\"2λ (std) = $(mean(KW)/2) ($(std(KW)/2))\")\n",
    "    println(\"2ν (std) = $(mean(V)/2) ($(std(V)/2))\")\n",
    "    println(\"=\"^70)\n",
    "    println(\"Name                | mean (std)\")\n",
    "    println(\"-\"^70)\n",
    "    println(\"T                   | $(mean(T)) ($(std(T)))\")\n",
    "    println(\"V                   | $(mean(V)) ($(std(V)))\")\n",
    "    println(\"WAIC = T + V        | $(mean(WAIC)) ($(std(WAIC)))\")\n",
    "    println(\"LOOCV               | $(mean(LOOCV)) ($(std(LOOCV)))\")\n",
    "    println(\"GL                  | $(mean(GL)) ($(std(GL)))\")\n",
    "    println(\"-\"^70)\n",
    "    println(\"WAIC - GL           | $(mean(WG)) ($(std(WG)))\")\n",
    "    println(\"LOOCV - GL          | $(mean(LG)) ($(std(LG)))\")\n",
    "    println(\"LOOCV - WAIC        | $(mean(LW)) ($(std(LW)))\")\n",
    "    println(\"-\"^70)\n",
    "    println(\"KL = GL - S         | $(mean(KL)) ($(std(KL)))\")\n",
    "    println(\"TT = T    - T_true  | $(mean(TT)) ($(std(TT)))\")\n",
    "    println(\"WT = WAIC - T_true  | $(mean(WT)) ($(std(WT)))\")\n",
    "    println(\"KW = KL + WT        | $(mean(KW)) ($(std(KW)))\")\n",
    "    println(\"-\"^70)\n",
    "    println(\"WBIC                | $(mean(WBIC)) ($(std(WBIC)))\")\n",
    "    println(\"FreeEnergy          | $(mean(FreeEnergy)) ($(std(FreeEnergy)))\")\n",
    "    println(\"-\"^70)\n",
    "    println(\"WBIC - FreeEnergy   | $(mean(WBIC-FreeEnergy)) ($(std(WBIC-FreeEnergy)))\")\n",
    "    println(\"WBIC - T_true       | $(mean(WBIC-T_true)) ($(std(WBIC-T_true)))\")\n",
    "    println(\"FreeEnergy - T_true | $(mean(FreeEnergy-T_true)) ($(std(FreeEnergy-T_true)))\")\n",
    "    println(\"=\"^70)\n",
    "    println(\"correlation of TT and KL = $(cor(TT, KL))\")\n",
    "    println(\"correlation of WT and WT = $(cor(WT, KL))\")\n",
    "    println(\"=\"^70)\n",
    "    println()\n",
    "    \n",
    "    sleep(0.1)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    plt.subplot(321)\n",
    "\n",
    "    x = linspace(minimum(WAIC), maximum(WAIC), 200)\n",
    "    plt.plt[:hist](WAIC, normed=true, bins=bins, alpha=0.5, label=\"WAIC\")\n",
    "    plt.plot(x, pdf.(Chisq(n), x-(Shannon-n+mean(KW))), label=\"χ²($n) + const\")\n",
    "    plt.grid(ls=\":\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.title(\"WAIC of $modelname, n=$n, Nsims=$Nsims\", fontsize=10)\n",
    "\n",
    "    plt.subplot(322)\n",
    "\n",
    "    x = linspace(minimum(T_true), maximum(T_true), 200)\n",
    "    plt.plt[:hist](T_true, normed=true, bins=bins, alpha=0.5, label=\"T_true\")\n",
    "    plt.plot(x, pdf.(Chisq(n), x - (Shannon-n)), label=\"χ²($n) + const\")\n",
    "    plt.grid(ls=\":\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.title(\"T_true of the true dist, n=$n, Nsims=$Nsims\", fontsize=10)\n",
    "\n",
    "    plt.subplot(323)\n",
    "    plt.plt[:hist](KL, normed=true, bins=bins, alpha=0.5, label=\"KL = GL \\$-\\$ S\")\n",
    "    plt.grid(ls=\":\")\n",
    "    plt.legend()\n",
    "    plt.title(\"KL = GL \\$-\\$ Shannon for $modelname, n=$n\", fontsize=10)\n",
    "\n",
    "    plt.subplot(324)\n",
    "    plt.plt[:hist](TT, normed=true, bins=bins, alpha=0.5, label=\"TT = T \\$-\\$ T_true\")\n",
    "    plt.grid(ls=\":\")\n",
    "    plt.legend()\n",
    "    plt.title(\"TT = T \\$-\\$ T_true for $modelname, n=$n\", fontsize=10)\n",
    "\n",
    "    plt.subplot(325)\n",
    "    plt.plt[:hist](WT, normed=true, bins=bins, alpha=0.5, label=\"WT = WAIC \\$-\\$ T_true\")\n",
    "    plt.grid(ls=\":\")\n",
    "    plt.legend()\n",
    "    plt.title(\"WT = WAIC \\$-\\$ T_true for $modelname, n=$n\", fontsize=10)\n",
    "\n",
    "    plt.subplot(326)\n",
    "    plt.plt[:hist](KW, normed=true, bins=bins, alpha=0.5, label=\"KW = KL + WT\")\n",
    "    plt.axvline(mean(KW), color=\"k\", ls=\":\", label=\"mean\")\n",
    "    plt.grid(ls=\":\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.title(\"KW = KL + WT for $modelname, n=$n\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "end\n",
    "\n",
    "function plotModelSelection(criterion::String, leftmodel::String, rightmodel::String;\n",
    "        title=\"Model Selection by $criterion (n=$n)\",\n",
    "        xlabel=\"$leftmodel ←―――――――――――――――――→ $rightmodel\")\n",
    "    IC_left  = s(criterion, leftmodel)\n",
    "    IC_right = s(criterion, rightmodel)\n",
    "    Diff  = IC_left - IC_right\n",
    "    \n",
    "    Percent_left  = 100*count(x -> x < 0.0, Diff)/length(Diff)\n",
    "    Percent_right = 100*count(x -> x ≥ 0.0, Diff)/length(Diff)\n",
    "\n",
    "    rmin = minDiff = minimum(Diff)\n",
    "    rmax = maxDiff = maximum(Diff)\n",
    "    (rmin > -0.3*rmax) && (rmin = -0.3*rmax)\n",
    "    (rmax < -0.3*rmin) && (rmax = -0.3*rmin)\n",
    "    \n",
    "    h = plt.plt[:hist](Diff, normed=true, bins=50, alpha=0.5, range=(rmin,rmax), label=\"diff of $criterion\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"probability density\")\n",
    "    plt.axvline(0, color=\"red\", ls=\"--\")\n",
    "    \n",
    "    xann1 = rmin\n",
    "    yann1 = 0.9*maximum(h[1])\n",
    "    plt.annotate(\"$Percent_left%\", \n",
    "        xytext=(0.9*xann1, 0.6*yann1), \n",
    "        xy=(0.4*minDiff, 0.2*yann1),\n",
    "        arrowprops=Dict(\"arrowstyle\" => \"->\", \"color\" => \"red\"),\n",
    "        color=\"red\")\n",
    "    \n",
    "    xann2 = 0.7*rmax\n",
    "    yann2 = 0.9*maximum(h[1])\n",
    "    plt.annotate(\"$Percent_right%\", \n",
    "        xytext=(0.9*xann2, 0.6*yann2), \n",
    "        xy=(0.4*maxDiff, 0.2*yann2), \n",
    "        arrowprops=Dict(\"arrowstyle\" => \"->\", \"color\" => \"red\"),\n",
    "        color=\"red\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(ls=\":\")\n",
    "    plt.title(title, fontsize=10)\n",
    "    \n",
    "end\n",
    "\n",
    "function plotAllModelSelections(criterion::String)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.subplot(221); plotModelSelection(criterion, \"normal1\", \"mixnormal\")\n",
    "    plt.subplot(222); plotModelSelection(criterion, \"normal\", \"mixnormal\")\n",
    "    plt.subplot(223); plotModelSelection(criterion, \"normal\", \"normal1\")\n",
    "    plt.tight_layout()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: No file exists at given path: DataStandardNormalSample8Case4649.jld2",
     "output_type": "error",
     "traceback": [
      "ArgumentError: No file exists at given path: DataStandardNormalSample8Case4649.jld2",
      "",
      "Stacktrace:",
      " [1] load(::Formatted; options::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:192",
      " [2] load at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:187 [inlined]",
      " [3] #load#16 at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:136 [inlined]",
      " [4] load(::String) at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:136",
      " [5] top-level scope at In[36]:1",
      " [6] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "data = load(\"DataStandardNormalSample8Case4649.jld2\")\n",
    "#data = load(\"DataStandardNormalSample32Case4649.jld2\")\n",
    "#data = load(\"DataStandardNormalSample128Case4649.jld2\")\n",
    "for v in sort(collect(keys(data)))\n",
    "    ex = parse(\"$v = data[\\\"$v\\\"]\")\n",
    "    #println(ex)\n",
    "    eval(ex)\n",
    "end\n",
    "\n",
    "plotTh12(\"mixnormal\")\n",
    "plotTh12(\"normal1\")\n",
    "plotTh12(\"normal\")\n",
    "\n",
    "plotAllModelSelections(\"T\")\n",
    "plotAllModelSelections(\"GL\")\n",
    "plotAllModelSelections(\"WAIC\")\n",
    "plotAllModelSelections(\"LOOCV\")\n",
    "plotAllModelSelections(\"WBIC\")\n",
    "plotAllModelSelections(\"FreeEnergy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: No file exists at given path: DataStandardNormalSample32Case4649.jld2",
     "output_type": "error",
     "traceback": [
      "ArgumentError: No file exists at given path: DataStandardNormalSample32Case4649.jld2",
      "",
      "Stacktrace:",
      " [1] load(::Formatted; options::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:192",
      " [2] load at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:187 [inlined]",
      " [3] #load#16 at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:136 [inlined]",
      " [4] load(::String) at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:136",
      " [5] top-level scope at In[37]:2",
      " [6] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "#data = load(\"DataStandardNormalSample8Case4649.jld2\")\n",
    "data = load(\"DataStandardNormalSample32Case4649.jld2\")\n",
    "#data = load(\"DataStandardNormalSample128Case4649.jld2\")\n",
    "for v in sort(collect(keys(data)))\n",
    "    ex = parse(\"$v = data[\\\"$v\\\"]\")\n",
    "    #println(ex)\n",
    "    eval(ex)\n",
    "end\n",
    "\n",
    "plotTh12(\"mixnormal\")\n",
    "plotTh12(\"normal1\")\n",
    "plotTh12(\"normal\")\n",
    "\n",
    "plotAllModelSelections(\"T\")\n",
    "plotAllModelSelections(\"GL\")\n",
    "plotAllModelSelections(\"WAIC\")\n",
    "plotAllModelSelections(\"LOOCV\")\n",
    "plotAllModelSelections(\"WBIC\")\n",
    "plotAllModelSelections(\"FreeEnergy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: No file exists at given path: DataStandardNormalSample128Case4649.jld2",
     "output_type": "error",
     "traceback": [
      "ArgumentError: No file exists at given path: DataStandardNormalSample128Case4649.jld2",
      "",
      "Stacktrace:",
      " [1] load(::Formatted; options::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:192",
      " [2] load at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:187 [inlined]",
      " [3] #load#16 at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:136 [inlined]",
      " [4] load(::String) at C:\\Users\\4429s\\.julia\\packages\\FileIO\\TyKdX\\src\\loadsave.jl:136",
      " [5] top-level scope at In[38]:3",
      " [6] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "#data = load(\"DataStandardNormalSample8Case4649.jld2\")\n",
    "#data = load(\"DataStandardNormalSample32Case4649.jld2\")\n",
    "data = load(\"DataStandardNormalSample128Case4649.jld2\")\n",
    "for v in sort(collect(keys(data)))\n",
    "    ex = parse(\"$v = data[\\\"$v\\\"]\")\n",
    "    #println(ex)\n",
    "    eval(ex)\n",
    "end\n",
    "\n",
    "plotTh12(\"mixnormal\")\n",
    "plotTh12(\"normal1\")\n",
    "plotTh12(\"normal\")\n",
    "\n",
    "plotAllModelSelections(\"T\")\n",
    "plotAllModelSelections(\"GL\")\n",
    "plotAllModelSelections(\"WAIC\")\n",
    "plotAllModelSelections(\"LOOCV\")\n",
    "plotAllModelSelections(\"WBIC\")\n",
    "plotAllModelSelections(\"FreeEnergy\");"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/d688c6e5e8c427dba9856d37a12bbee1"
  },
  "gist": {
   "data": {
    "description": "混合正規分布モデルと正規分布モデルの各種情報量規準の比較",
    "public": true
   },
   "id": "d688c6e5e8c427dba9856d37a12bbee1"
  },
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
