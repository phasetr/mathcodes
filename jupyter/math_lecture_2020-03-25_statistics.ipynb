{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第 4 章 モデルの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 モデルとは何か"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1 モデルとは何か?\n",
    "- モデルの定義: 入力データを特徴量とし, 出力を予測値とする変換器.\n",
    "    - 例: ランダムフォレスト, ニューラルネット.\n",
    "- 復習\n",
    "    - 目的変数: 予測したいラベルや値. 例: 1 ヶ月以内の有料機能利用状況.\n",
    "    - 特徴量: 目的変数の予測に使える量. 例: 有料機能を使う様々なユーザー属性.\n",
    "- 分析コンペでは「教師あり学習」が基本: 教師あり学習に関して, 必要なら以下の補足を参考にする.\n",
    "- ハイパーパラメータ: モデルが持つ, 学習前に指定するパラメータ.\n",
    "    - 学習の方法, 速度, どれだけ複雑なモデルにするかが決まる.\n",
    "    - モデルの精度に影響する.\n",
    "    - ハイパーパラメータの例: 正則化 (後述) の強さを調整する.\n",
    "    - チューニングについては 6 章で議論する.\n",
    "- 自分用のメモ: パラメータとハイパーパラメータの違い\n",
    "    - パラメータ: 正規分布の平均や分散. これ自体が推測の対象\n",
    "    - ハイパーパラメータ: 上で書いたように正則化の強さなどの調整弁."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補足: 教師あり学習\n",
    "- 教師あり学習: 目的変数があるデータからモデルを学習させ, 目的変数がないデータに対して予測する.\n",
    "- 半教師あり学習\n",
    "    - 目的変数があるデータだけではなく目的変数がないデータについてもモデルの学習に活用する.\n",
    "    - 少量のラベルありデータを使って大量のラベルなしデータを学習に活かす.\n",
    "    - 人間の学習と似ている\n",
    "        - 様々なもののラベル (例えば「これはネコ」「これはイヌ」) を他人から与えられる.\n",
    "        - 後は自分でたくさんのネコやイヌを見てどんどん学習して認識できるようになっていく.\n",
    "- 教師なし学習\n",
    "    - 目的変数がないデータからデータ内のパターンを推測する.\n",
    "    - データから共通する特徴を持つグループを見つけたり, データを特徴づける情報を抽出したりする.\n",
    "    - 例\n",
    "        - 類似データのグルーピング (クラスタリング)\n",
    "        - 本質的なデータを抽出する (次元削減)\n",
    "            - 参考: https://aizine.ai/glossary-unsupervised-learning/\n",
    "            - A さんに対するイメージのアンケートから「美人」を導出する."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2 モデル作成の流れ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習と予測\n",
    "- (ハイパーパラメータは適切な値がわかっているとする)\n",
    "- モデルの種類とハイパーパラメータを指定する\n",
    "- 学習データと目的変数を与えて学習させる\n",
    "- テストデータを与えて予測させる\n",
    "- 参考コードは以下の通り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('~/codes/kagglebook/input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('~/codes/kagglebook/input/sample-data/test_preprocessed.csv')\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, params=None):\n",
    "        self.model = None\n",
    "        if params is None:\n",
    "            self.params = {}\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "    def fit(self, tr_x, tr_y):\n",
    "        params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71}\n",
    "        params.update(self.params)\n",
    "        num_round = 10\n",
    "        dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "        self.model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "    def predict(self, x):\n",
    "        data = xgb.DMatrix(x)\n",
    "        pred = self.model.predict(data)\n",
    "        return pred\n",
    "\n",
    "params = {'param1': 10, 'param2': 100}\n",
    "model = Model(params)\n",
    "model.fit(train_x, train_y)\n",
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 出てくる行列の次数\n",
    "- 学習データのレコード数を $n_{tr}$, テストデータのレコード数を $n_{te}$, 特徴量の列数を $n_f$ とする.\n",
    "- 学習データは $(n_{tr}, n_{f})$ 次の行列\n",
    "- 目的変数は $n_{tr}$ 個のベクトル (配列)\n",
    "- テストデータは $(n_{te}, n_f)$ 次の行列\n",
    "- 予測値は $n_{te}$ 個のベクトル (配列)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの評価 (バリデーション)\n",
    "- モデルの良し悪しを評価する: 詳しくは 第 5 章.\n",
    "- 学習に使ったデータに関してモデルは「正解を知っている」.\n",
    "- 一方, 知りたいのはあくまで未知のデータに対する予測能力.\n",
    "- モデル評価用に一部のデータをバリデーション (検証用) データとして分けて評価に使う.\n",
    "- モデルによっては学習時に学習データとともにバリデーションデータを与えられる.\n",
    "    - 学習進度をモニタリングできる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('~/codes/kagglebook/input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('~/codes/kagglebook/input/sample-data/test_preprocessed.csv')\n",
    "\n",
    "import xgboost as xgb\n",
    "class Model:\n",
    "    def __init__(self, params=None):\n",
    "        self.model = None\n",
    "        if params is None:\n",
    "            self.params = {}\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "    def fit(self, tr_x, tr_y):\n",
    "        params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71}\n",
    "        params.update(self.params)\n",
    "        num_round = 10\n",
    "        dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "        self.model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "    def predict(self, x):\n",
    "        data = xgb.DMatrix(x)\n",
    "        pred = self.model.predict(data)\n",
    "        return pred\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]\n",
    "\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "model = Model(params)\n",
    "model.fit(tr_x, tr_y)\n",
    "va_pred = model.predict(va_x)\n",
    "score = log_loss(va_y, va_pred)\n",
    "print(f'logloss: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hold-out 法\n",
    "- 一部のデータをバリデーションデータとして取り分ける.\n",
    "- 欠点: モデルの学習・評価に使えるデータが少なくなる.\n",
    "- 克服のために使われるのがクロスバリデーション."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クロスバリデーション\n",
    "- 学習データを分割する: 分割したそれぞれの固まりを fold と呼ぶ.\n",
    "- そのうちの 1 つをバリデーションデータ, 残りを学習データとして学習・評価し,\n",
    "  バリデーションデータでのスコアを求める.\n",
    "- 分割した数だけバリデーションデータを変えて学習・評価する.\n",
    "- それらのスコアの平均でモデルを評価する."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "scores = []\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx in kf.split(train_x):\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "    model = Model(params)\n",
    "    model.fit(tr_x, tr_y)\n",
    "    va_pred = model.predict(va_x)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "print(f'logloss: {np.mean(scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.222 分析コンペでの学習・評価・予測の流れ\n",
    "- モデルを評価するバリデーションの枠組みを作り, 評価のフィードバックを改善に活かす.\n",
    "- モデルの作成・評価の 1 サイクルは次の通り\n",
    "    - モデルの種類とハイパーパラメータを指定してモデルを作る\n",
    "    - 学習データを与えてモデルを学習させ, バリデーションしてモデルを評価する\n",
    "    - 学習したモデルでテストデータに対して予測する\n",
    "- モデル改善\n",
    "    - 特徴量を追加・変更する\n",
    "    - ハイパーパラメータを変える\n",
    "    - モデルを変える\n",
    "- バリデーションはふつうクロスバリデーション.\n",
    "    - スタッキングのようなアンサンブル (7 章参考: 複数のモデルの組み合わせを考える) のときは結局クロスバリデーションが必要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.223 Author's Opinion\n",
    "- 作業配分の参考\n",
    "    - 特徴量作成: 5-8 割\n",
    "    - ハイパーパラメータの調整: 変更時の影響をたまに見つつ, 本格的な調整は終盤\n",
    "    - モデル選択\n",
    "        - まずは GBDT\n",
    "        - タスクの性質によってニューラルネットを検討\n",
    "        - **(どういうこと?)** アンサンブル (複数のモデルの組み合わせ) を考える場合は他のモデルも作成\n",
    "    - 理解が進んでくるたびにバリデーションの枠組みを再検討する\n",
    "- モデルの種類・ハイパーパラメータ・特徴量のセットを入れ替えやすくするコードを書こう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クロスバリデーション後の予測\n",
    "- 2 つの手法\n",
    "    - 各 fold で学習したモデルを保存し, それらのモデルの予測値の平均を取る\n",
    "        - cf. P.225 の左の図\n",
    "    - 学習データ全体に対して改めてモデルを学習させ, そのモデルで予測\n",
    "- P.225 Author's Opinion: 手法のメリット・デメリット\n",
    "    - 前者の手法\n",
    "        - 追加学習が不要でバリデーションでスコアが見えていてわかりやすい\n",
    "        - 各 fold で学習に使ったデータを合わせると学習データ全体なので,\n",
    "          学習データ全体に対して学習させた場合と変わらない精度が出ると**見込める**\n",
    "        - アンサンブルの効果が効く\n",
    "            - ただしハイパーパラメータや特徴量を変えたモデルでの平均を取るとその効果は消える\n",
    "        - 予測を fold 分くり返すからテストデータが大きいときは予測に時間がかかる\n",
    "    - 後者の手法\n",
    "        - 学習データ全体に対して学習させた方が少し精度がいい**という意見がある**\n",
    "        - 学習データ全体に対して再学習させる時間がかかる\n",
    "        - 学習データ数が違うのに同じハイパーパラメータでいいか懸念がある\n",
    "            - ニューラルネットを使うとき, エポック数の設定が難しい\n",
    "            - 各 fold と全体ではデータ数が違い, 同じエポックだけ学習させたときの進度が変わる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 モデルに関連する用語とポイント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 過学習 (オーバーフィッティング)\n",
    "- 本の定義おかしくない?\n",
    "    - 「学習データのランダムなノイズまで学習してしまい, 学習データではスコアがいいがそれ以外ではスコアが悪くなる現象」\n",
    "    - というか, どう定義すると適切か?\n",
    "    - 現象の定義としては単に「学習データではスコアがいいがそれ以外ではスコアが悪くなる現象」でいい?\n",
    "    - これだと, 例えば[「持っている情報の量に比べて過剰に複雑なモデルを作ってしまうこと」](https://aizine.ai/overfitting0206/)が原因で,\n",
    "      学習データの情報を吸い過ぎて学習データにだけ過剰適合してしまうことなども含められる.\n",
    "    - 失敗原因 (の推測) を盛り込まない定義がよさそう.\n",
    "- 逆 (と呼ばれる) 事例: アンダーフィッティング\n",
    "    - これもおかしくない?\n",
    "    - 「十分に学習データの性質が学習できていなくて学習データでもそれ以外でもスコアがよくない」\n",
    "    - 「十分に学習データの性質が学習できていなくて」の前提がよけい.\n",
    "    - 単に「学習データでもそれ以外でもスコアがよくない」でいいのではないか.\n",
    "    - 「そもそもモデル自体が不適切」という事例も含めた定義をしたい.\n",
    "    - 単に学習が足りないこともある.\n",
    "    \n",
    "- (コンペのスコアをもとに) ハイパーパラメータ調整の参考にする.\n",
    "- スコアが違う場合の注意\n",
    "    - バリデーションとテストでデータの分布が違うこともある\n",
    "    - テストデータのレコード数が少ないこともある\n",
    "    - もちろんバリデーションがうまくいっていない可能性もある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正則化 (regularization)\n",
    "- 学習時にモデルの複雑さに対してペナルティを課すこと.\n",
    "    - 過学習を防ぐ目的で導入する.\n",
    "    - 本の過学習の定義の議論と整合性なくない?\n",
    "        - 定義でモデルの複雑さに言及していない.\n",
    "- ペナルティを上回るほど予測に寄与する複雑さだけが評価対象.\n",
    "- 多くのモデルには正則化項がある\n",
    "    - 正則化の強さを指定するハイパーパラメータの調整でモデルの複雑さを制御できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データとバリデーションデータのスコアのモニタリング\n",
    "- GBDT やニューラルネットは逐次的に学習が進んでいくモデル\n",
    "    - 学習データとその目的変数の他,\n",
    "      モニタリングする評価指標・バリデーションデータとその目的変数を与えることで,\n",
    "      学習データとバリデーションデータのスコアの推移を見られる.\n",
    "- モデルの学習でバリデーションデータも与えるのを基本にする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アーリーストッピング\n",
    "- バリデーションデータのスコアを見て一定期間スコアが上がらないとき途中で学習を打ち切る機能\n",
    "    - ライブラリにも機能がある\n",
    "- 学習を進めすぎて過学習になり汎化性能が落ちるのを防ぐ\n",
    "- スコアのイメージについては P.228 図 4.6 を参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バギング\n",
    "- 複数のモデルを組み合わせてモデルを作る方法：アンサンブルの具体例\n",
    "- 同じ種類のモデルを並列に複数作り, その予測値の平均などを使って予測する\n",
    "- それぞれのモデルでデータや特徴量をサンプリングして汎化性能を高める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ブースティング\n",
    "- 複数のモデルを組み合わせてモデルを作る方法: 同じ種類のモデルを直列的に組み合わせる\n",
    "- それまでの学習による予測値を補正しつつ順に 1 つずつモデルを学習させる\n",
    "- GBDT は名前の通りブースティングを使っている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 分析コンペで使われるモデル\n",
    "- 次のモデルを紹介する\n",
    "    - GBDT (勾配ブースティング木)\n",
    "    - ニューラルネット\n",
    "    - 線型モデル\n",
    "    - その他のモデル\n",
    "        - k 近傍法 (k-nearest neighbor algorithm, KNN)\n",
    "        - ランダムフォレスト (Random Forest, RF)\n",
    "        - Extremely Randomized Trees (ERT)\n",
    "        - Regularized Greedy Forest (RGF)\n",
    "        - Field-aware Factorization Machines (FFM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析コンペでモデルを選ぶ観点\n",
    "- 精度, 計算速度, 使いやすさ, 多様性でアンサンブルによる精度向上に寄与するか\n",
    "- 最優先は精度\n",
    "- 試行錯誤のために計算速度や使いやすさも重要\n",
    "- モデル自体の精度は高くなくても, \n",
    "  精度が高い他のモデルと違う観点から予測しアンサンブルでの精度向上に寄与できることもある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT\n",
    "- 精度・計算速度・使いやすさともに優れている\n",
    "- ふつうは最初に試すモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネット\n",
    "- 扱いが難しい\n",
    "- タスクによって役に立つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 線型モデル\n",
    "- 過学習しやすそうな特殊なコンペでは選択肢に上がる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### その他のモデル\n",
    "- 多様性に貢献し, アンサンブルで精度を上げることを狙って使う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決定木ベースのモデル\n",
    "- GBDT, ランダムフォレスト, Extremely Randomized Trees, Regularized Greedy Forest\n",
    "- 1 つの決定木では十分な予測は難しいので複数を組み合わせる\n",
    "- サポートベクターマシンは精度・計算速度の問題からあまり使わない\n",
    "- cf. P.230 Author's Opinion の「モデルの選び方」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 GBDT (勾配ブースティング木)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.1 GBDT の概要\n",
    "- 使いやすくて精度が高く, ふつうコンペの初手で作る\n",
    "- 学習\n",
    "    - 目的変数と予測値から計算される目的関数を改善するように、決定木を作ってモデルに追加\n",
    "    - ハイパーパラメータで定めた決定木の本数の分だけくり返す\n",
    "    - 2 本目以降の木は目的変数とそれまでに作った決定木による予測値の差に対して学習を進める\n",
    "    - 木を作るうちにモデルの予測値が目的変数に合っていく: 作成させる決定木のウェイトは徐々に小さくなる\n",
    "    - 予測値は予測対象のデータがそれぞれの決定木で属する葉のウェイトの和を取る\n",
    "- 決定木の作り方\n",
    "    - ランダムフォレスト: 決定木を並列に作る\n",
    "    - GBDT: 決定木を直列に作る\n",
    "        - それまでに作った決定木の予測値を新しい決定木の予測値を加えて少しずつ修正"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.2 GBDT の特徴\n",
    "- 特徴量は数値: 特徴量の大小で分岐を振り分けるため\n",
    "- 補完なしで欠損値が扱える: 欠損値があっても分岐のどちらかに振り分けられる\n",
    "- 変数間の相互作用が反映される: 分岐のくり返しによる\n",
    "- 著者の経験則\n",
    "    - 精度が高い\n",
    "    - パラメータチューニングしなくても精度が出やすい\n",
    "    - 不要な特徴量を追加しても精度が落ちにくい\n",
    "- 使いやすさの面からの特徴\n",
    "    - 特徴量をスケーリングする必要がない: 決定木ではそれぞれの特徴量について値の大小関係だけが問題\n",
    "    - カテゴリ変数を one-hot encoding しなくていい\n",
    "        - 数値化するために label encoding は必要\n",
    "    - 疎行列へのサポート"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.3 GBDT の主なライブラリ\n",
    "- よく使われるライブラリ: xgboost, lightgbm, catboost\n",
    "- 長く使われていて資料の多い xgboost で説明する\n",
    "- lightgbm: 高速で, 2019/8 時点で xgboost よりも人気\n",
    "- catboost: カテゴリ変数の扱いに工夫がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.4 GBDT の実装\n",
    "- ch04/cho4-02-run_xgb.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.12853\teval-error:0.15160\n",
      "[1]\ttrain-error:0.11533\teval-error:0.14600\n",
      "[2]\ttrain-error:0.10933\teval-error:0.13760\n",
      "[3]\ttrain-error:0.10533\teval-error:0.13640\n",
      "[4]\ttrain-error:0.09693\teval-error:0.13840\n",
      "[5]\ttrain-error:0.09467\teval-error:0.13640\n",
      "[6]\ttrain-error:0.08733\teval-error:0.12960\n",
      "[7]\ttrain-error:0.08493\teval-error:0.12440\n",
      "[8]\ttrain-error:0.07813\teval-error:0.12080\n",
      "[9]\ttrain-error:0.07373\teval-error:0.11720\n",
      "[10]\ttrain-error:0.06867\teval-error:0.11600\n",
      "[11]\ttrain-error:0.06493\teval-error:0.11640\n",
      "[12]\ttrain-error:0.06227\teval-error:0.11120\n",
      "[13]\ttrain-error:0.06053\teval-error:0.11160\n",
      "[14]\ttrain-error:0.05680\teval-error:0.11120\n",
      "[15]\ttrain-error:0.05040\teval-error:0.10480\n",
      "[16]\ttrain-error:0.04920\teval-error:0.10040\n",
      "[17]\ttrain-error:0.04640\teval-error:0.10160\n",
      "[18]\ttrain-error:0.04427\teval-error:0.10280\n",
      "[19]\ttrain-error:0.04347\teval-error:0.10120\n",
      "[20]\ttrain-error:0.03867\teval-error:0.10160\n",
      "[21]\ttrain-error:0.03653\teval-error:0.10040\n",
      "[22]\ttrain-error:0.03493\teval-error:0.09960\n",
      "[23]\ttrain-error:0.03373\teval-error:0.10040\n",
      "[24]\ttrain-error:0.03253\teval-error:0.10400\n",
      "[25]\ttrain-error:0.03120\teval-error:0.10320\n",
      "[26]\ttrain-error:0.02880\teval-error:0.10200\n",
      "[27]\ttrain-error:0.02773\teval-error:0.10160\n",
      "[28]\ttrain-error:0.02573\teval-error:0.10040\n",
      "[29]\ttrain-error:0.02320\teval-error:0.10080\n",
      "[30]\ttrain-error:0.02293\teval-error:0.10240\n",
      "[31]\ttrain-error:0.02067\teval-error:0.09920\n",
      "[32]\ttrain-error:0.01987\teval-error:0.09920\n",
      "[33]\ttrain-error:0.01973\teval-error:0.09840\n",
      "[34]\ttrain-error:0.01693\teval-error:0.10280\n",
      "[35]\ttrain-error:0.01733\teval-error:0.10080\n",
      "[36]\ttrain-error:0.01627\teval-error:0.09880\n",
      "[37]\ttrain-error:0.01520\teval-error:0.09720\n",
      "[38]\ttrain-error:0.01480\teval-error:0.09800\n",
      "[39]\ttrain-error:0.01453\teval-error:0.09720\n",
      "[40]\ttrain-error:0.01333\teval-error:0.09760\n",
      "[41]\ttrain-error:0.01253\teval-error:0.09480\n",
      "[42]\ttrain-error:0.01253\teval-error:0.09560\n",
      "[43]\ttrain-error:0.01147\teval-error:0.09480\n",
      "[44]\ttrain-error:0.01080\teval-error:0.09680\n",
      "[45]\ttrain-error:0.01093\teval-error:0.09600\n",
      "[46]\ttrain-error:0.01000\teval-error:0.09320\n",
      "[47]\ttrain-error:0.01027\teval-error:0.09240\n",
      "[48]\ttrain-error:0.00920\teval-error:0.09120\n",
      "[49]\ttrain-error:0.00947\teval-error:0.09120\n",
      "logloss: 0.2223\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train_xは学習データ、train_yは目的変数、test_xはテストデータ\n",
    "# pandasのDataFrame, Seriesで保持します。（numpyのarrayで保持することもあります）\n",
    "train = pd.read_csv('kagglebook/input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('kagglebook/input/sample-data/test_preprocessed.csv')\n",
    "\n",
    "# 学習データを学習データとバリデーションデータに分ける\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# 特徴量と目的変数をxgboostのデータ構造に変換する\n",
    "dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "dtest = xgb.DMatrix(test_x)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71}\n",
    "num_round = 50\n",
    "\n",
    "# 学習の実行\n",
    "# バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\n",
    "# watchlistには学習データおよびバリデーションデータをセットする\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(params, dtrain, num_round, evals=watchlist)\n",
    "\n",
    "# バリデーションデータでのスコアの確認\n",
    "va_pred = model.predict(dvalid)\n",
    "score = log_loss(va_y, va_pred)\n",
    "print(f'logloss: {score:.4f}')\n",
    "\n",
    "# 予測（二値の予測値ではなく、1である確率を出力するようにしている）\n",
    "pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.5 xgboost の使い方のポイント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ブースター (booster)\n",
    "- GBDT を使う場合はデフォルト値の gbtree でいい.\n",
    "- gblinear: 線型モデル\n",
    "    - 表現力が線型モデルと同じなのであまり使われない\n",
    "- dart: 正則化に DART というアルゴリズムを使った GBDT\n",
    "    - コンペによっては効果がある\n",
    "    - 勾配ブースティングでは序盤に作成される木の影響が強い: 終盤に作成される木は瑣末な部分にフィットする\n",
    "    - これを抑制するためにドロップアウトを GBDT に適用する手法\n",
    "    - 決定木の作成ごとにドロップアウトのように一定の割合の木を存在しないとして学習させる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目的関数\n",
    "- これを最小化するように学習を進める\n",
    "- パラメータ objective を以下のように設定する\n",
    "- 回帰: reg:squarederror を設定すると平均2乗誤差を最小化するように学習\n",
    "- 二値分類: binary:logistic を設定すると logloss を最小化するように学習\n",
    "- 多クラス分類: multi:softprob を設定して multi-class logloss を最小化するように学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータ\n",
    "- 詳細は 6 章"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データとバリデーションデータのスコアのモニタリング\n",
    "- train メソッドの evals パラメータに学習データ・バリデーションデータを渡す\n",
    "- 決定木を追加するごとに学習データ・バリデーションデータへのスコアを出力する\n",
    "- デフォルトでは目的関数に応じて適した評価指標が設定される\n",
    "- パラメータ `eval_metric` を指定するとモニタリングしたい評価指標への変更・複数の評価指標の設定ができる\n",
    "- `train` メソッドの `early_stopping_round` パラメータの指定で, アーリーストッピングができる.\n",
    "    - 注意: 予測時に ntree_limit パラメータを指定しないと最適ではなく学習が止まったところまでの木の本数で計算されてしまう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モニタリングをloglossで行い、アーリーストッピングの観察するroundを20とする\n",
    "params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71,\n",
    "          'eval_metric': 'logloss'}\n",
    "num_round = 500\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(params, dtrain, num_round, evals=watchlist,\n",
    "                  early_stopping_rounds=20)\n",
    "\n",
    "# 最適な決定木の本数で予測を行う\n",
    "pred = model.predict(dtest, ntree_limit=model.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning API と Scikit-Learn API のどちらを使うか\n",
    "- どちらを使うは好み\n",
    "- Scikit-Learn API は Learning API の train メソッドなどをラップしているので, 小回りが利かないこともある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.6 lightgbm\n",
    "- xgboost に比べて高速で, 精度は同程度\n",
    "    - 決定木の分岐はヒストグラムベース\n",
    "    - 深さ単位でなく葉単位での分岐の追加による精度の向上\n",
    "        - estimator を見ると様子が分かる。\n",
    "    - カテゴリ変数の分割の最適化による精度の向上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# 特徴量と目的変数をlightgbmのデータ構造に変換する\n",
    "lgb_train = lgb.Dataset(tr_x, tr_y)\n",
    "lgb_eval = lgb.Dataset(va_x, va_y)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "params = {'objective': 'binary', 'seed': 71, 'verbose': 0, 'metrics': 'binary_logloss'}\n",
    "num_round = 100\n",
    "\n",
    "# 学習の実行\n",
    "# カテゴリ変数をパラメータで指定している\n",
    "# バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\n",
    "categorical_features = ['product', 'medical_info_b2', 'medical_info_b3']\n",
    "model = lgb.train(params, lgb_train, num_boost_round=num_round,\n",
    "                  categorical_feature=categorical_features,\n",
    "                  valid_names=['train', 'valid'], valid_sets=[lgb_train, lgb_eval])\n",
    "\n",
    "# バリデーションデータでのスコアの確認\n",
    "va_pred = model.predict(va_x)\n",
    "score = log_loss(va_y, va_pred)\n",
    "print(f'logloss: {score:.4f}')\n",
    "\n",
    "# 予測\n",
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.7 catboost\n",
    "- カテゴリ変数の扱いに特徴的な工夫をしている\n",
    "    - カテゴリ変数の target encoding: 自動的に数値に変換する\n",
    "    - oblivious decision tree: 各深さの分岐の条件式が全て同じ決定木を使う, cf. P241, 図 4.14\n",
    "    - ordered boosting: データ数が少ないときに使われるアルゴリズム\n",
    "        - 遅いがデータ数が少ないときには精度がいい\n",
    "- Author's Opinion\n",
    "    - 速度が出ないので使われる機会は少ない\n",
    "    - 相互作用が重要なときにいい精度が出る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.243 Column xgboost のアルゴリズムの解説\n",
    "- 目的関数を変えればタスクは分類・回帰のどちらも同じ枠組みで計算できる\n",
    "- 目的関数\n",
    "    - 回帰なら二乗誤差\n",
    "    - 二値分類なら logloss\n",
    "    - マルチクラス分類なら multi-class logloss\n",
    "- 以下の設定\n",
    "    - レコード数: $N$, 添字: $i$\n",
    "    - 決定木: $M$ 個, 添字: $m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. 決定木によるブースティング\n",
    "- モデルは決定木 (回帰木) によるブースティングで作る\n",
    "    - 分類であっても回帰木を使う\n",
    "    - 予測値を予測確率に変換して使う\n",
    "- 決定木を逐次的に学習させる\n",
    "    - $m$ 番目の木を学習させるときは $m-1$ 番目までの予測誤差を補正するように決める\n",
    "    - 学習が進むと補正する必要性が小さくなり, ウェイトも小さくなる\n",
    "- GBDT では各決定木でのレコードが属する葉のウェイトの合計がモデルの予測値\n",
    "    - レコード $i$ の特徴量の組を $x_i$ とし, \n",
    "      ある決定木 $m$ でのレコードが属する葉のウェイトを $w_m(x_i)$ とすると,\n",
    "      予測値は $\\sum_{m=1}^M w_m(x_i)$ と表される.\n",
    "    - 2 値分類では $\\sum_{m=1}^M w_m(x_i)$ にシグモイド関数をあてた値が予測確率\n",
    "- 流れは次の通り\n",
    "    - 決定木を $M$ 本作り, 次のフローをくり返す\n",
    "    - 分岐を何度も作ることで決定木を作る.\n",
    "      分岐を作るためにはどの特徴量のどの値で分岐させるかを選ぶ.\n",
    "    - どの特徴量のどの値で分岐させるかは次の通り.\n",
    "        - 全ての候補を調べ, 分岐させる\n",
    "        - 目的関数が 1 番減る葉のウェイトを選ぶ\n",
    "    - 作った決定木にもとづいて予測値を更新する\n",
    "        - 例: あるレコードが分岐でウェイト $w$ の葉に落ちる場合,\n",
    "          学習率を $\\eta$ として,\n",
    "          レコードの予測値には $w \\eta$ を加える."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. 正則化された目的関数\n",
    "- 目的変数 $y_i$, 予測値 $\\dot{y}_i$ としたときの目的関数を $l(y_i, \\dot{y}_i)$ とする.\n",
    "- それぞれの決定木を $f_m$ として決定木に対して罰則が計算される正則化項を $\\Omega(f_m)$ とする.\n",
    "- $T$ を木の葉の数, $j$ を葉の添字, $w_j$ を葉のウェイトとする.\n",
    "    - 正則化項は $$\\Omega(f_m) = \\gamma T + \\frac{1}{2} \\lambda \\sum_{j} w_j^2 + \\alpha \\sum_{j} |w_j|$$\n",
    "- 目的関数は次の通り: $$L = \\sum_{i=1}^N l(\\hat{y}_j, y_i) + \\sum_{m=1}^M \\Omega(f_m)$$.\n",
    "- 正則化はモデルをできるだけシンプルにするために導入する\n",
    "    - xgboost では正則化項まで含めて計算して葉のウェイトを決める\n",
    "    - 以下では正則化項は省略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. 決定木の作成\n",
    "- それぞれ 1 つの葉から始めて分岐をくり返して作る\n",
    "- 対象とする点での勾配を使って決定木の分岐の仕方を決める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c-1. 葉の最適なウェイトと分岐で得られる目的関数の計算\n",
    "- どの特徴量で分岐させるか, どの値の大小で分岐させるかを決めると分岐先の葉に含まれるデータの集合が得られる\n",
    "- それらの与えるべき最適なウェイトとそのときの目的関数の変化を求めたい\n",
    "- それまでの決定木による予測値が $\\hat{y}_i$,\n",
    "  分岐を決めたときのある葉のレコードの集合を $I_j$,\n",
    "  ウェイトを $w_j$ とする.\n",
    "- レコードの集合の目的関数の和は $$L_j = \\sum_{i \\in I_j} l(y_i, \\hat{y}_i + w_j)$$.\n",
    "- これを 2 次近似する: それぞれのレコードで目的関数を 2 次関数とし, その和を最適化する.\n",
    "- 予測値 $\\hat{y}_j$ まわりの勾配を $g_i = l_{\\hat{y}_i}$,\n",
    "  2 階の微分係数を $h_i = l_{\\hat{y}_i \\hat[y]_i}$ とすると,\n",
    "  目的関数の和は次の通り\n",
    "    - $$\\tilde{L}_j = \\sum_{i \\in I_j} (l(y_i, \\hat{y}_i) + g_i w_j + \\frac{1}{2} h_i w_j^2)$$.\n",
    "    - 定数部分はウェイトの決め方に関与しないので除く\n",
    "    - $$\\tilde{L}'_j = \\sum_{i \\in I_j} (g_i w_j + \\frac{1}{2} h_i w_j^2)$$.\n",
    "- 次のようにウェイトを決めれば目的関数 $\\tilde{L}'_j$ は最小になる\n",
    "\n",
    "\\begin{align}\n",
    " w_j = - \\frac{\\sum_{i \\in I_j} g_i}{\\sum_{i \\in I_j} h_i}, \\quad\n",
    " \\tilde{L}'_j = \\frac{1}{2} \\frac{(\\sum_{i \\in I_j} g_i)}{\\sum_{i \\in I_j} h_i}.\n",
    "\\end{align}\n",
    "\n",
    "- $g_i$, $h_i$ が決まれば目的関数の値が決まり, 分岐したときの目的関数の減り方も決まる\n",
    "- 分岐前の目的関数を $\\tilde{L}'_j$,\n",
    "  分岐後の左右の葉の目的関数を $\\tilde{L}'_{jL}, \\tilde{L}'_{jR}$ とすると,\n",
    "  分岐による目的関数の減少は $\\tilde{L}'_j - (\\tilde{L}'_{jL} - \\tilde{L}'_{jR})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 乗誤差の場合の目的関数の計算\n",
    "- 二乗誤差なら計算しやすくなる\n",
    "- 目的関数は $l(y_i, \\hat{y}_i) = \\frac{1}{2} (\\hat{y}_i - y_i)^2$.\n",
    "    - 勾配: $g_i = l_{\\hat{y}_i} = \\hat{y}_i - y_i$\n",
    "    - 二階の微分係数: $h_i = l_{\\hat{y}_i \\hat{y}_i} = 1$.\n",
    "- これを 2 次近似目的関数の和に代入\n",
    "\n",
    "\\begin{align}\n",
    " \\tilde{L}_j\n",
    " &= \\sum_{i \\in I_j} \\left( \\frac{1}{2} (\\hat{y}_i - y_i)^2 + (\\hat{y}_i - y_i) w_j + \\frac{1}{2} w_j^2 \\right) \\\\\n",
    " &= \\sum_{i \\in I_j} \\left( \\frac{1}{2} ((\\hat{y}_i + w_j) - y_j)^2 \\right)\n",
    "\\end{align}\n",
    "\n",
    "- 括弧内は $l(y_i, \\hat{y}_i + w_j)$ であることに注意.\n",
    "- 目的関数 $\\tilde{L}'_j$ を最小にするウェイトは次の通り.\n",
    "\n",
    "\\begin{align}\n",
    " w_j = - \\frac{\\sum_{i \\in I_j} g_i}{\\sum_{i \\in I_j} h_i}\n",
    " = - \\frac{\\sum_{i \\in I_j} (\\hat{y}_i - y_i)}{\\sum_{i \\in I_j} 1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c-2 分岐の特徴量と基準値の決定\n",
    "- どの特徴量で分岐させるか, どの値の大小で分岐させるか\n",
    "    - 全ての候補を調べて正則化された目的関数が 1 番小さくなるように選ぶ\n",
    "    - データが多い場合は一定の分位点だけを候補として調べる\n",
    "    - 疎なデータに対しては効率的に計算できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. 過学習を防ぐ工夫 (正則化以外の方法)\n",
    "- 学習率\n",
    "    - 上記で求めた最適なウェイトまで一気に予測値を補正してしまうと過学習になる\n",
    "    - (**どういうこと?**) 実際には各決定木で求めたウェイトの一定割合を適用し, 少しずつ補正\n",
    "    - 率はパラメータ `eta` で指定する.\n",
    "- サンプリング\n",
    "    - 決定木を作るときに特徴量の列をサンプリングする\n",
    "    - 割合は `colsample_bytree` で指定する\n",
    "    - それぞれの決定木を作るときに学習データの行もサンプリングする\n",
    "    - 割合はパラメータ `subsample` で指定\n",
    "- データが少なすぎる葉を作らない\n",
    "    - 葉の構成に最低限必要な 2 階微分係数の値を `min_child_weight` で指定\n",
    "- 決定木の深さの制限\n",
    "    - 木の深さの最大値は `max_depth` で制限できる\n",
    "    - 深くすると複雑なモデルになる表現力は上がるが過学習しやすくなる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 ニューラルネット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.1 ニューラルネットの概要\n",
    "- テーブルデータに対してよく使われる構造を考える。\n",
    "    - いわゆる深層学習で使われる 10 層以上あるようなニューラルネットではなく、中間層が 2-4 層程度の全結合層からなる多層パーセプトロン（Multi Layer Perceptron、MLP）\n",
    "    - 中間層が 2 層の多層パーセプトロンは P.247 図 4.15\n",
    "- 多層パーセプトロンの概要\n",
    "    - 入力層：特徴量がインプット\n",
    "    - 中間層：前の層の値をウェイトで重みづけした和を取って結合し、そのあと活性化関数を適用する。\n",
    "      活性化関数には ReLU（Rectified Linear Unit）がよく使われる。\n",
    "    - 出力層：前の層の値をウェイトで重みづけした和を取り結合する。\n",
    "      そのあとタスクに合わせて活性化関数を適用する。\n",
    "      - 出力層の活性化関数の選び方\n",
    "      - 回帰：恒等関数\n",
    "      - 二値分類：シグモイド関数\n",
    "      - マルチクラス分類：ソフトマックス関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ユニット\n",
    "- 層の各要素をユニットという。\n",
    "- 入力層のユニット数は特徴量と同じ数。\n",
    "- 中間層のユニット数はハイパーパラメータで設定。\n",
    "- 出力層のユニット数は回帰・二値分類なら 1 つ、多クラス分類ならクラス数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中間層の計算\n",
    "- ある層のユニット $i$ の出力値 $z_i$ の計算は次の通り。\n",
    "- 前の層からの各ユニットの出力の和を取って結合する：$u_i = \\sum_{j} z'_j w_{i,j}$\n",
    "    - 出力は前の層のユニット $j$ の出力とウェイトの積で定義する：$z'_j w_{i,j}$\n",
    "    - バイアスの記述は省略：「モデルと学習データの平均的なずれ」をバイアスと呼ぶ。\n",
    "- 活性化関数 ReLU を適用し、出力は $z_i = \\max (u_i,0)$。\n",
    "    - $f(x) = \\max(x,0)$ を ReLU という。\n",
    "- 活性化関数を適用して層を重ねると非線型性が表現できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.248 いろいろな活性化関数\n",
    "- 出力層にシグモイド関数・ソフトマックス関数を適用すると、出力値は二値分類・多クラス分類で確率を表す値になる。\n",
    "- シグモイド関数は出力値を $(0,1)$ に制限する：$$f(x) = \\frac{1}{1 + e^{-x}}.$$\n",
    "- ソフトマックス関数も出力値を $(0,1)$ に制限し、各出力の和が 1 になるように変換する：クラス数 $K$ に対して次のように定義する。$$f_i(x_1,\\dots,x_k) = \\frac{e^{x_i}}{\\sum_{k=1}^K e^{x_k}}.$$\n",
    "    - 自分用メモ：指数の肩に負号はつけない模様。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.248 学習\n",
    "- 学習するのは中間層・出力層のウェイト。\n",
    "- 学習には**勾配降下法**を使う：誤差を出力層から入力層に伝播させ、ウェイトを更新する**誤差逆伝播法**（バックプロパゲーション）を使う。\n",
    "- 勾配降下法の最適化アルゴリズム（オプティマイザー）がいくつかあり、ハイパーパラメータとして指定する。\n",
    "- 学習データをミニバッチと呼ばれる少数のサンプルに分け、ミニバッチごとに層のウェイトを更新する。\n",
    "- 1 エポックの定義：学習データの最後まで学習する。\n",
    "- 十分に学習が進むまでエポックくり返す。\n",
    "- 確率的勾配降下法：ミニバッチごとに更新する手法。\n",
    "    - 学習データ全体を計算するごとにウェイトを更新するよりも、計算効率が高くなりやすく、局所解にも陥りにくい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.249 4.4.2 ニューラルネットの特徴\n",
    "- 特徴量は数値\n",
    "- 欠損値は扱えない\n",
    "- 非線型性や変数間の相互作用が反映できる\n",
    "- 特徴量を標準化などでスケーリングしなければならない\n",
    "    - 特徴量の大きさが揃っていないと学習がうまくいかないことがある\n",
    "- ハイパーパラメータの調整が難しい\n",
    "    - きちんと調整しないと精度が出ない\n",
    "    - 過学習も学習が進まないこともある\n",
    "- 多クラス分類に (比較的) 強い\n",
    "    - 構造上, 多クラス分類を自然にモデリングできる\n",
    "    - GBDT と遜色ない精度が出ることもある\n",
    "- GPU での高速化\n",
    "    - GPU はニューラルネットで必要な行列演算に適している\n",
    "- GBDT よりもモデリングやチューニングの手間がかかる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.3 ニューラルネットの主なライブラリ\n",
    "- keras, pytorch, chainer, tensorflow\n",
    "    - chainer は死んでしまった\n",
    "- この本は keras で解説\n",
    "- keras は tensorflow などのライブラリをバックエンドとし, 扱いやすい API を提供するラッパー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.250 4.4.4 ニューラルネットの実装\n",
    "- サンプルデータに対して keras でモデリング\n",
    "- ニューラルネットで学習させるデータはカテゴリ変数を one-hot encoding している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch04/ch04-04-run_nn.py から\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# データのスケーリング\n",
    "scaler = StandardScaler()\n",
    "tr_x = scaler.fit_transform(tr_x)\n",
    "va_x = scaler.transform(va_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "# ニューラルネットモデルの構築\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(train_x.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 学習の実行\n",
    "# バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "history = model.fit(tr_x, tr_y,\n",
    "                    batch_size=batch_size, epochs=epochs,\n",
    "                    verbose=1, validation_data=(va_x, va_y))\n",
    "\n",
    "# バリデーションデータでのスコアの確認\n",
    "va_pred = model.predict(va_x)\n",
    "score = log_loss(va_y, va_pred, eps=1e-7)\n",
    "print(f'logloss: {score:.4f}')\n",
    "\n",
    "# 予測\n",
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.251 keras の使い方のポイント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.251 目的関数\n",
    "- モデルのコンパイル時にパラメータ `loss` に目的関数を設定すると,\n",
    "  それを最小化するように学習が進む.\n",
    "- 回帰の場合: `mean_squared_error` を設定すると平均 2 乗誤差を最小化する\n",
    "- 二値分類: `binary_crossentropy` を設定すると `logloss` を最小化するように学習する.\n",
    "- 多クラス分類: `categorical_crossentropy` を設定すると `multi-classlogloss` を最小化するように学習する.\n",
    "    - この本、多クラス分類とマルチクラス分類が両方出てくるっぽく、編集者が仕事をしていない疑惑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.252 ハイパーパラメータ\n",
    "- ニューラルネットはハイパーパラメータの種類が決まっていない。\n",
    "    - cf. 多くのモデルではハイパーパラメータの種類が決まっている\n",
    "- ニューラルネットは層の構成など自由にできる部分が多い\n",
    "    - ニューラルネットの難しさの一因\n",
    "    - 調整しやすいようにコードを書こう\n",
    "    - まずはパラメータに応じて中間層の数やユニット数が違うネットワークを作るコードを書く\n",
    "    - そのあとパラメータを設定して調整する\n",
    "    - 具体的なハイパーパラメータ\n",
    "        - 詳細は 6 章\n",
    "        - オプティマイザの種類\n",
    "        - 学習率\n",
    "        - 中間層の数\n",
    "        - ユニット数\n",
    "        - ドロップアウトの強さ: 次に説明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ドロップアウト\n",
    "- 階層の深いニューラルネットを精度よく最適化するために Hinton らによって提案された手法\n",
    "- 複数のネットワークの学習結果の平均と同じ効果があるとされていて過学習を防ぐ\n",
    "- 無視する割合をハイパーパラメータとして指定する\n",
    "- [参考](http://sonickun.hatenablog.com/entry/2016/07/18/191656)\n",
    "    - 学習時にネットワークの自由度を強制的に小さくして汎化性能を上げ過学習を避ける\n",
    "    - ニューラルネットワークを学習するとき,\n",
    "      ある更新で層の中のノードのうちのいくつかをランダムに無効にする:\n",
    "      そもそも存在しないかのように扱って学習する.\n",
    "    - 次の更新では別のノードを無効にして学習を行うことを繰り返す.\n",
    "    - 隠れ層では一般的に 50% 程度を無効するといいとされる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データとバリデーションデータのスコアのモニタリング\n",
    "- エポックごとに学習データとバリデーションデータのスコアを出力する\n",
    "- アーリーストッピングは後述のコールバックで"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コールバック\n",
    "- 学習時, ミニバッチの処理ごとやエポックごとに指定した処理を走らせる\n",
    "- 次のようなときに使う\n",
    "    - アーリーストッピング\n",
    "    - モデルの定期的な保存: バリデーションデータでの評価がいいモデルを残す\n",
    "    - 学習率のスケジューリング・調整\n",
    "    - ログ・可視化\n",
    "- 次の例はコールバックでアーリーストッピングしている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch04/ch04-04-run_nn.py\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# アーリーストッピングの観察するroundを20とする\n",
    "# restore_best_weightsを設定することで、最適なエポックでのモデルを使用する\n",
    "epochs = 50\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(tr_x, tr_y,\n",
    "                    batch_size=batch_size, epochs=epochs,\n",
    "                    verbose=1, validation_data=(va_x, va_y), callbacks=[early_stopping])\n",
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding layer\n",
    "- 正の整数を密な数値ベクトルに変換する層\n",
    "    - (**疑問**) 「密な」というのはどういうこと? 整数を 0 が少ない数列・ベクトルに置き換える。\n",
    "    - 参考：https://www.tensorflow.org/tutorials/text/word_embeddings?hl=ja\n",
    "- モデルの最初の層としてしか指定できない\n",
    "    - カテゴリ変数を入力にするときに使える\n",
    "    - 二値ではないカテゴリ変数はもともと one-hot encoding で前処理していた.\n",
    "    - label encoding から embedding layer を使う手法が出てきた\n",
    "- 自然言語対応\n",
    "    - `Word2Vec` や `Glove` などの学習済み embedding (単語を対応する密な数値ベクトルで表現したもの) をウェイトに設定できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch normalization 層 (BN 層)\n",
    "- ミニバッチごとに標準化して各層の出力のばらつきを抑える\n",
    "    - 効果が高く広く使われている\n",
    "    - 学習に効果的な理由は本の P253、注 29 の文献参照\n",
    "- BN 層への入力\n",
    "    - ミニバッチごとに標準化: 平均を 0, 標準偏差を 1 にする\n",
    "    - 標準化された値 $\\hat{x}$ に対して $\\gamma \\hat{x} + \\beta$ に変換されて出力される\n",
    "        - この $\\gamma$ と $\\beta$ は BN 層で学習されるパラメータ\n",
    "    - それぞれの入力ごとに計算され, $\\gamma, \\beta$ も入力の数だけある\n",
    "- - 学習中の BN 層への入力の平均・標準偏差は保持される\n",
    "    - 予測ではこれらで標準化する: ミニバッチの選び方で結果が変わらないようにしている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.6 参考になるソリューション: 多層パーセプトロン\n",
    "- ニューラルネットの難しさ: 選択肢が多くモデル作りの自由度が高い\n",
    "    - 層をどう作るか, オプティマイザーに何を使うか\n",
    "    - Kaggle の過去のソリューションを基礎にするといい\n",
    "- 以下のソリューションには多層パーセプトロンのモデルがある\n",
    "    - [Recruit Retaurant Visitor Forecasting](https://github.com/dkivaranovic/kaggledays-recruit)\n",
    "    - [Corporation Favorita Grocery Sales Forecasting](https://www.kaggle.com/shixw125/1st-place-nn-model-public-0-507-private-0-513)\n",
    "    - [Otto Group Product Classification Challenge](https://github.com/puyokw/kaggle_Otto)\n",
    "    - [Home Depot Product Search Relevance](https://github.com/ChenglongChen/Kaggle_HomeDepot)\n",
    "        - hyperopt で自動的にパラメータをチューニングしてモデルを作っている\n",
    "    - [https://www.kaggle.com/c/mercari-price-suggestion-challenge/discussion/50256]\n",
    "        - 商品タイトルや説明文など自然言語中心のデータからその商品価格を予測する\n",
    "        - 疎なデータをインプットにする多層パーセプトロンのソリューションがメイン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.255 4.4.7 参考になるソリューション: 最近のニューラルネットの発展\n",
    "- テーブルデータ対象の場合, 以前はほぼパーセプトロンだった.\n",
    "- 最近は RNN (リカレントニューラルネット) が使われるようになってきた\n",
    "- 人手での特徴量作成による GBDT と, あまり特徴量を生成しないニューラルネットが遜色ない精度になっているケースもある\n",
    "- 例\n",
    "    - [Instacart Market Basket Analysis](https://github.com/sjvasquez/instacart-basket-prediction)\n",
    "        - 顧客の時系列的な注文データから次のどの商品が購入されるか予測する.\n",
    "        - RNN・CNN (たたみ込みニューラルネット) でモデルを作り, アンサンブルしている\n",
    "    - [Web Traffic Time Series Forecasting](https://github.com/sjvasquez/web-traffic-forecasting)\n",
    "        - Wikipedia の記事の日ごとの閲覧数を予測する\n",
    "        - WaveNet という音声波形生成のためのニューラルネットをベースにしている\n",
    "    - [Mercari Price Suggestion Challenge](https://github.com/ChenglongChen/tensorflow-XNN)\n",
    "        - DeepFM という Factorization Machine というモデルの組み込みをネットワーク構造に組み込んだニューラルネットがベース\n",
    "        - [Guo, Tang, Ye, Li, He, 2017, DeepFM: A Factorization-Machine based Neural Network for CTR Prediction](https://arxiv.org/abs/1703.04247)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.256, 4.5 線型モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.256, 4.5.1 線型モデルの概要\n",
    "- 線型モデル: シンプルなモデル\n",
    "- 単体での精度は高くない\n",
    "- GBDT やニューラルネットに勝つことはまずない\n",
    "- アンサンブルのうちの 1 つやスタッキングの最終層に使う\n",
    "    - スタッキング: 効率的かつ効果的に 2 つ以上のモデルを組み合わせて予測する方法\n",
    "    - cf. P360, 7.3\n",
    "- Author's Opinion\n",
    "    - 過学習しやすいデータで活躍する: データ不足だったりノイズが多かったり.\n",
    "    - Kaggle の Two Sigma Financial Modeling Challenge や Walmart Recruting II: Sales in Stormy Weather で使われている\n",
    "- 回帰タスク\n",
    "    - 次のような線型回帰モデルを使う.\n",
    "    - 後述の $L^1$ 正則化を使う線型回帰モデルを Lasso, $L^2$ 正則化を使う線型回帰モデルを Ridge という.\n",
    "    - 予測値 $y$, 特徴量 $x_i$ に対して $y =  b_0 + \\sum_{k=1}^n b_k x_k$ を考え,\n",
    "      各係数 $b_k$ を学習させる.\n",
    "- 分類タスク\n",
    "    - ロジスティック回帰モデルが使われる\n",
    "    - ロジスティック回帰\n",
    "        - 線型回帰にシグモイド関数を適用\n",
    "        - 予測値の取り得る値を $(0,1)$ に制限, 確率予測ができるようにした\n",
    "        - $y' = b_0 + \\sum_{k=1}^n b_k x_k$, $y = 1 / (1 + e^{-y'})$.\n",
    "- 線型モデルでの正則化: 係数の絶対値が大きいほど罰則を与える\n",
    "    - 大きすぎる係数での学習データへの過剰適合を防ぐ\n",
    "    - 係数の絶対値に比例する罰則を $L^1$ 正則化, 2 乗に比例する罰則を $L^2$ 正則化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.257, 4.5.2 線型モデルの特徴\n",
    "- 特徴量は数値\n",
    "- 欠損値は扱えない\n",
    "- GBDT やニューラルネットと比較して精度は高くない\n",
    "- 非線型性を表現するためには明示的に特徴量を作る必要がある\n",
    "    - 特徴量 $x_f$ が予測値に対して $\\log x_f$ 程度に影響していることを表すには $\\log x_f$ という特徴量を作る必要がある\n",
    "- 相互作用を表現するためには明示的に特徴量を作る必要がある\n",
    "    - フラグ 1 とフラグ 2 の関連性を見たければ, 「フラグ 1 かつフラグ 2」といった特徴量が必要.\n",
    "- 特徴量は標準化すべし\n",
    "    - 正則化の効き方が特徴量によって変わってしまい, 学習がうまくいかないことがある\n",
    "- 特徴量を作るときに丁寧な処理が必要\n",
    "    - 非線型性や相互作用を表す特徴量をわざわざ作る必要あり\n",
    "    - 最大・最小を制限\n",
    "    - binning する\n",
    "    - 上記を組み合わせる\n",
    "    - いろいろな変換・処理が必要\n",
    "- $L^1$ 正則化をするとき, 予測に寄与しない特徴量の係数が 0 になる\n",
    "    - 逆にこの性質を使って線型モデルを特徴選択に使うこともある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.257, 4.5.3 線型モデルの主なライブラリ\n",
    "- scikit-learn の linear_model モジュール\n",
    "- vowpal wabbit\n",
    "- 学習は速い\n",
    "- 以下では scikit-learn の linear_model で説明する\n",
    "- 次のクラスを選ぶといい\n",
    "    - 回帰タスクは Ridge: Ridge では $L^2$-正則化を適用.\n",
    "      $L^1$-正則化を適用する Lasso や $L^1$-正則化・$L^2$-正則化がともに使える ElasticNet を使ってもいい.\n",
    "    - 分類タスクは LogisticRegression: デフォルトでは $L^2$-正則化."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.258, 4.5.4 線型モデルの実装\n",
    "- サンプルデータに対して scikit-learn の LogisticRegression モデルでモデリングする\n",
    "- カテゴリ変数は one-hot encoding しておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# データのスケーリング\n",
    "scaler = StandardScaler()\n",
    "tr_x = scaler.fit_transform(tr_x)\n",
    "va_x = scaler.transform(va_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "# 線形モデルの構築・学習\n",
    "model = LogisticRegression(C=1.0)\n",
    "model.fit(tr_x, tr_y)\n",
    "\n",
    "# バリデーションデータでのスコアの確認\n",
    "# predict_probaを使うことで確率を出力できます。(predictでは二値のクラスの予測値が出力されます。)\n",
    "va_pred = model.predict_proba(va_x)\n",
    "score = log_loss(va_y, va_pred)\n",
    "print(f'logloss: {score:.4f}')\n",
    "\n",
    "# 予測\n",
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.259, 4.5.5 線型モデルの使い方のポイント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.259 目的関数\n",
    "- 基本的にはモデルによって最小化する目的関数が決まっている\n",
    "- 回帰 (Ridge モデルなど): 平均 2 乗誤差を最小化するように学習\n",
    "- 分類 (LogisticRegression モデル)\n",
    "    - 二値分類: logloss を最小化\n",
    "    - マルチクラス分類: one-vs-rest: あるクラスとそれ以外のクラスの二値分類をくり返す\n",
    "        - multi-class logloss を最小化する方法で学習するオプションもある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.259 ハイパーパラメータ\n",
    "- チューニングが必要なパラメータは基本的に正則化の強さを表す係数しかない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.260, 4.6 その他のモデル\n",
    "- アンサンブルのモデルの 1 つとして使われることが多い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.260, 4.6.1 k 近傍法 (k-nearest neighbor algorithm, kNN)\n",
    "- レコード間の距離をそれらの特徴量の差で定義\n",
    "- 距離が最も近い $k$ 個のレコードの目的変数から回帰・分類する\n",
    "- 利用モジュール\n",
    "    - scikit-learn の neighbors モジュールの KNeighborsClassifier, KNeighborsRegressor クラス\n",
    "- デフォルト\n",
    "    - 距離はユークリッド距離\n",
    "    - 回帰では最も近い $k$ 個のレコードの平均が予測値\n",
    "    - 分類では最も近い $k$ 個のレコードで最も多いクラスが予測値\n",
    "- 値のスケールが大きい特徴量が重視されすぎないようにする\n",
    "    - 特徴量に標準化などのスケーリングが必要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.260, 4.6.2 ランダムフォレスト (Random Forest, RF)\n",
    "- 決定木の集合で予測する\n",
    "- GBDT と違い, 並列に決定木を作る: (P.261, 図 4.16)\n",
    "- それぞれの決定木の学習でレコードや特徴量をサンプリングして与えて多様な決定木を作る\n",
    "    - さらにアンサンブルして汎化性能が高い予測をする\n",
    "- モデルの作り方\n",
    "    - 学習データからレコードをサンプリングして抽出\n",
    "    - 抽出レコードから学習して決定木を作る\n",
    "        1. 分岐を作るとき特徴量の一部をサンプリングして抽出して特徴量の候補とする\n",
    "        2. 特徴量の候補からデータを最もよく分割する特徴量と閾値を選んで分岐にする\n",
    "        3. (1) から (2) を作る決定木の本数だけ並列に処理する\n",
    "- scikit-learn の ensemble モジュールの RandomForestClassifier, RandomForestRegressor クラスを使う\n",
    "    - 以下ではこれらのデフォルトパラメータで説明する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.261 決定木作成のポイント\n",
    "- 分岐\n",
    "    - 回帰タスク: 二乗誤差が最も減少するようにする\n",
    "    - 分類タスク: ジニ不純度が最も減少するようにする\n",
    "- 決定木ごとに元の個数と同じだけのレコードを復元抽出するブートストラップサンプリングをする\n",
    "    - ブートストラップサンプリングでは重複して抽出されるレコードがある\n",
    "    - 一方, 平均して 1/3 程度が抽出されないレコードになる\n",
    "- 分岐ごとに特徴量の一部をサンプリングした候補から分岐の特徴量を選ぶ\n",
    "    - 回帰タスク: サンプリングせずに全てを候補にする\n",
    "    - 分類タスク: 特徴量の個数の平方根の個数だけ抽出して候補にする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.261 ランダムフォレストのポイント\n",
    "- 決定木の本数と精度の関係\n",
    "    - 決定木を並列に作るため, GBDT と違い, 決定木の本数が増え過ぎて精度が悪くなることはない\n",
    "    - ある程度増やすと精度が上がらなくなる\n",
    "    - 決定木の本数は計算時間と精度のトレードオフ\n",
    "- out-of-bag\n",
    "    - ブートストラップサンプリングで抽出されないレコードのこと\n",
    "    - out-of-bag のレコードを使うことで, バリデーションデータを用意しなくても汎化性能が見積もれる\n",
    "- 予測確率の妥当性\n",
    "    - 分類タスク\n",
    "        - GBDT ではウェイトに基づいた予測確率の logloss を最小化\n",
    "            - ランダムフォレストではジニ不純度を最小化しようとする各決定木の予測を平均する\n",
    "    - ランダムフォレストの方法では予測確率の妥当性は保証されず, 歪む\n",
    "        - cf. P.95, 2.5.4 予測確率とその調整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.262 4.6.3 Extremely Randomized Trees (ERT)\n",
    "- ランダムフォレストとほぼ同じ方法でモデルを作る\n",
    "- 分岐を作るときに違いがある\n",
    "    - ランダムフォレスト: それぞれの特徴量で最もよくデータを分割できる閾値を使う\n",
    "    - ERT: ランダムに設定した閾値を使う\n",
    "- ランダムフォレストより過学習しづらい**らしい**\n",
    "- scikit-learn の ensemble モジュールの ExtraTreesClassifier, ExtraTreesRegressor クラスを使う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.262 4.6.3 Regularized Greedy Forest (RGF)\n",
    "- 目的関数に正則化項を明示的に含める点で GBDT と同じ\n",
    "- 決定木を作成・成長させる方法が違う\n",
    "- 目的関数が小さくなるように次の操作をくり返して決定木の集合を作る\n",
    "    - 葉を分岐させる\n",
    "    - 新しい木を作る\n",
    "    - いままでに作った決定木全体に対して葉のウェイトを修正する\n",
    "        - 計算コストが高い操作なので, 一定数の葉の分岐や木の作成ごとに定期的に実行\n",
    "- Regularized Greedy Forest ライブラリを使う: pip install rgf_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.263 4.6.5 Field-aware Factorization Machines\n",
    "- Factorization Machines (FM) を発展させたモデル\n",
    "- レコメンドのタスクと相性がいい\n",
    "- ライブラリ libffm を使う: xlearn もある\n",
    "- 説明, P263, Information\n",
    "    - 問題: ユーザー・商品・ジャンルがカテゴリ変数で, 組み合わせへの評価の値が目的変数\n",
    "    - ユーザー・商品・ジャンルを one-hot encoding して表す\n",
    "        - 「ユーザー数・商品数・ジャンル数」が特徴量数で, 疎なデータとして表せる\n",
    "        - cf. P.263, 図 4.17\n",
    "    - FM は特徴量同士の相互作用を特徴量に対応するベクトルの内積で表現する線型モデルの亜種\n",
    "        - それぞれの特徴量はその性質を表す要素数 $k$ のベクトルを持つ\n",
    "        - これらのベクトルが学習対象\n",
    "        - 要素数 $k$ はハイパーパラメータ\n",
    "        - 予測値: $i$ 番目の特徴量のベクトル $v_i$ に対して次のように定義する.\n",
    "          $$y = w_0 + \\sum_{i=1}^{n_f} w_i x_i + \\sum_{i=1}^{n_f} \\sum_{j=i+1}^{n_f} \\langle v_i, v_j \\rangle x_i x_j.$$\n",
    "        - $w_0$ は定数項, $w_i$ はウェイト, $n_f$ は特徴量の数\n",
    "        - 評価した時点からの経過期間などカテゴリ変数だけではなく数値変数を特徴量に持てる\n",
    "    - FFM はこれの拡張\n",
    "        - 組み合わせの相手の種類ごとに異なるベクトルを持たせる\n",
    "        - その種類をフィールドと呼ぶ: いまの例ではユーザー・商品・ジャンル\n",
    "        - 次の式では組み合わせ相手の $j$ 番目の特徴量が属するフィールドが $f_j$ の場合に使われる,\n",
    "          $i$ 番目の特徴量のベクトルを $v_{i, f_j}$ と表す.\n",
    "          $$y = w_0 + \\sum_{i=1}^{n_f} w_i x_i + \\sum_{i=1}^{n_f} \\sum_{j=i+1}^{n_f} \\langle v_{i, f_j}, v_{j, f_i} \\rangle x_i x_j.$$\n",
    "        - FM: 学習対象のベクトルの個数は特徴量数\n",
    "        - FFM: 特徴量数×フィールド数\n",
    "        - 特定のフィールドとの関係性だけ考えればいいので, 必要なベクトルの要素数は少なくなる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.265 4.7 モデルのその他のポイントとテクニック\n",
    "- モデルと扱うときに困る点の対応やその他のテクニックを紹介する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.265 4.7.1 欠損値がある場合\n",
    "- GBDT は問題なく扱える\n",
    "- 逆に欠損値を扱えないモデルでは欠損値を埋める必要がある\n",
    "- 欠損値を扱う方法は「3.3 欠損値の扱い」参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.265 4.7.2 特徴量の数が多い場合\n",
    "- 多過ぎると学習がいつまで経っても終わらない・メモリ不足で学習できないなどの問題が起きる\n",
    "- 余計な特徴量のせいでモデルの精度が上がらないこともある\n",
    "- GBDT の場合\n",
    "    - 学習さえできればそれなりの結果が出ること**も**ある\n",
    "    - 少しずつ特徴量を増やしながらどのくらいまで学習できるか試してみるといい\n",
    "    - 特徴量が数千あっても, データが疎の場合や二値しか持たない場合は分岐の候補が多くない: 学習できて精度が出るかもしれない\n",
    "- よけいな特徴量がないに越したことはない\n",
    "- 精度の寄与が少ない特徴量を落としたい場合は「6.2 特徴選択および特徴量の重要度」を参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P. 265 4.7.3 目的変数に 1対1 で対応するテーブルでない場合\n",
    "- 教師あり学習のためには以下の形になっている必要がある\n",
    "    - $n_{tr}$ はレコード数, $n_f$ は特徴量の数.\n",
    "    - 学習データは $n_{tr} \\times n_f$ の行列\n",
    "    - 目的変数は $n_f$ 個の配列\n",
    "- 最初からこの形ならいい\n",
    "    - コンペによっては目的変数 1 つに複数行のレコードが対応することがある\n",
    "- Kaggle の Walmart Recruiting: Trip Type Classification\n",
    "    - 目的変数に対応するものとして複数行からなる購入した商品の履歴が与えられた\n",
    "    - このままでは予測できない\n",
    "    - 行数・購入量の合計・ある商品の有無など目的変数に 1:1 に対応させた特徴量に変換する必要あり\n",
    "- 特徴量の作り方: 3.8・3.9 節参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.266 4.7.4 pseudo labeling\n",
    "- 目的変数のないデータについても学習に使える半教師あり学習の手法の 1 つ\n",
    "- テストデータに対する予測値を目的変数の値とみなし, 学習データに加えて再度学習するテクニック\n",
    "- 画像系のコンペで活用する例がいくつかある\n",
    "    - テーブルデータで効果がある例もある\n",
    "    - テストデータ数が学習データ数より多い場合にも有効\n",
    "        - 目的変数がなくてもテストデータの情報を使いたい場合などもある\n",
    "- 次のように実行する\n",
    "    1. 学習データで学習し, モデルを作る\n",
    "    2. 上の 1. で作ったモデルによってテストデータを予測する\n",
    "    3. 学習データに 2. の予測値を目的変数としてテストデータを加える\n",
    "         - 使う予測値を pseudo label と呼ぶ\n",
    "    4. テストデータが追加された学習データで再度学習し, モデルを作る\n",
    "    5. 上の 4. で作ったモデルでテストデータを予測し, 最終的な予測値にする\n",
    "- 細かな手法がいろいろあり, 工夫もいろいろある\n",
    "    - 学習データの質を保つため, 例えば分類タスクでは予測確率が十分高いテストデータだけを加える\n",
    "    - 複数のモデルのアンサンブルによる予測値を pseudo label として使う\n",
    "    - テストデータをいくつかのグループにわけ, あるグループの最終的な予測値はそのグループ以外のテストデータを加えて学習したモデルで作る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.267 COLUMN 分析コンペ用のクラスやフォルダの構成\n",
    "- GitHub のサンプルも参照\n",
    "- コンペでは綺麗に書きすぎるのも問題: スピードを重視する\n",
    "    - ファイル名を a01_run_xgb.py, a02_run_nn.py のように連番で書く\n",
    "    - ファイルはあまり分割せず, 修正する場合はファイルをコピーして修正することで, 過去のコードを残して再実行しやすくする\n",
    "- 著者のスタイル: ある程度クラスを整理して進める\n",
    "    - Model クラス\n",
    "        - xgboost や scikit-learn の各モデルをラップしたクラスで, 学習・予測する\n",
    "        - scikit-learn の BaseEstimator を継承すると行儀がいいかもしれない\n",
    "        - 状況に合わせていろいろ工夫する\n",
    "    - Runner クラス\n",
    "        - クロスバリデーションを含めて学習・予測の一連の流れを実行する\n",
    "        - データも読み込む\n",
    "        - Model クラスを保持して学習・予測は Model クラスに実行させる\n",
    "    - Util クラス, Logger クラス\n",
    "        - ユーティリティメソッド: ファイルの入出力など\n",
    "        - ログの出力・表示: ファイルとコンソールへの出力\n",
    "            - 異常終了したときの原因把握, 処理にかかる時間の見積もりなど\n",
    "        - 計算結果の出力・表示: 各モデルのバリデーションのスコアをファイルとコンソールに出力し, 集計する\n",
    "    - フォルダ構成\n",
    "        - 本の P.268 の注 48 に紹介された記事も参考にする\n",
    "        - コードは code, code-analysis ディレクトリにだけ保存する\n",
    "        - input: train.csv, test.csv などの入力ファイルを入れる\n",
    "        - code: 計算用のコード\n",
    "        - code-analysis: 分析用のコードや Jupyter Notebook\n",
    "        - model: モデルや特徴量を保存する\n",
    "        - submission: 提出用ファイルを保存する\n",
    "    - a. Model クラス\n",
    "        - run のクロスバリデーションの各 fold ごとにインスタンスを作る\n",
    "        - クラス生成時には run の名前とどの fold かを組み合わせた名前 (xgb-param1-fold1) を渡す\n",
    "        - 保存先のパスに使ってモデルを保存し, 読み込む"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
