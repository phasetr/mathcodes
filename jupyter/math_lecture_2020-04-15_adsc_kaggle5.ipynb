{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_gGCYHvl-mzF"
   },
   "source": [
    "# 5章　モデルの評価\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfC0GYIMkcyg"
   },
   "source": [
    "## 5.1 モデルの評価とは？\n",
    "モデルの性能→未知のモデルに対する汎化性能\n",
    "\n",
    "どのように汎化性能を評価するか？（validation）\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VylNZLWEkfEn"
   },
   "source": [
    "## 5.2 バリデーションの手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "so2_Hh8JkZD0"
   },
   "source": [
    "### 5.2.1 hold-out法\n",
    "\n",
    "学習データの一部を学習に使わず、バリデーション用に取っておく事で未知のテストデータに対する予測を模擬する方法。\n",
    "学習データとテストデータがランダムに分割されていることを前提としている。\n",
    "ランダムではない（時系列データなど）ときは別の方法を用いる。\n",
    "\n",
    "以下サンプル実行のための事前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2172,
     "status": "ok",
     "timestamp": 1586847196192,
     "user": {
      "displayName": "adsc mogmog",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiVVjAQh221NhImxTQYD760vopRrKw8A2fQPHxn=s64",
      "userId": "12779601883796982034"
     },
     "user_tz": -540
    },
    "id": "gOTKqhLlCFFY",
    "outputId": "4202db58-57ea-4d1c-b1fc-23660cea40cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'kagglebook' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/ghmagazine/kagglebook.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeExYFMGCkHc"
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# データ等の準備\n",
    "# ----------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train_xは学習データ、train_yは目的変数、test_xはテストデータ\n",
    "# pandasのDataFrame, Seriesで保持します。（numpyのarrayで保持することもあります）\n",
    "\n",
    "train = pd.read_csv('/content/kagglebook/input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('/content/kagglebook/input/sample-data/test_preprocessed.csv')\n",
    "\n",
    "# xgboostによる学習・予測を行うクラス\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, params=None):\n",
    "        self.model = None\n",
    "        if params is None:\n",
    "            self.params = {}\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71}\n",
    "        params.update(self.params)\n",
    "        num_round = 10\n",
    "        dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "        dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "        self.model = xgb.train(params, dtrain, num_round, evals=watchlist)\n",
    "\n",
    "    def predict(self, x):\n",
    "        data = xgb.DMatrix(x)\n",
    "        pred = self.model.predict(data)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0y2FA7wLDDcz"
   },
   "source": [
    "以下scikit-learnでのデータの分割例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1077,
     "status": "ok",
     "timestamp": 1586847204700,
     "user": {
      "displayName": "adsc mogmog",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiVVjAQh221NhImxTQYD760vopRrKw8A2fQPHxn=s64",
      "userId": "12779601883796982034"
     },
     "user_tz": -540
    },
    "id": "-_I02Mkjjuhb",
    "outputId": "1cdc3ebf-35c7-4ef1-c891-ce135b60a55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.128533\teval-error:0.1516\n",
      "[1]\ttrain-error:0.115333\teval-error:0.146\n",
      "[2]\ttrain-error:0.109333\teval-error:0.1376\n",
      "[3]\ttrain-error:0.105333\teval-error:0.1364\n",
      "[4]\ttrain-error:0.096933\teval-error:0.1384\n",
      "[5]\ttrain-error:0.094667\teval-error:0.1364\n",
      "[6]\ttrain-error:0.087333\teval-error:0.1296\n",
      "[7]\ttrain-error:0.084933\teval-error:0.1244\n",
      "[8]\ttrain-error:0.078133\teval-error:0.1208\n",
      "[9]\ttrain-error:0.073733\teval-error:0.1172\n",
      "0.30092523058503867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelクラスを定義しているものとする\n",
    "# Modelクラスは、fitで学習し、predictで予測値の確率を出力する\n",
    "\n",
    "# train_test_split関数を用いてhold-out法で分割する\n",
    "tr_x, va_x, tr_y, va_y = train_test_split(train_x, train_y,\n",
    "                                          test_size=0.25, random_state=71, shuffle=True)\n",
    "\n",
    "# 学習の実行、バリデーションデータの予測値の出力、スコアの計算を行う\n",
    "model = Model()\n",
    "model.fit(tr_x, tr_y, va_x, va_y)\n",
    "va_pred = model.predict(va_x)\n",
    "score = log_loss(va_y, va_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5aqyVG2BVcZ"
   },
   "source": [
    "\n",
    "### 5.2.2 クロスバリデーション\n",
    "\n",
    "学習データを分割し、hold-out法の手続きを複数回繰り返す方法。\n",
    "（図５．２）←４分割の例\n",
    "\n",
    "しばしばCVと略される。\n",
    "\n",
    "分割されたデータをfold,分割する数をfold数と呼ぶ。\n",
    "\n",
    "fold数を増やすほど学習データの量を確保できるが、計算時間が増える。（fold数が倍になれば計算する回数は倍になるが、fold数∞の極限で全データなので。。。）\n",
    "なので、むやみにfold数を増やせば良いと言うことではない。\n",
    "\n",
    "クロスバリデーションでの評価は、通常各foldの平均を用いる。（データ全体で評価する場合もある）\n",
    "\n",
    "データ全体でのスコアと、各foldのスコアの平均は評価する指標によって一致したりしなかったりするので注意。\n",
    "MAEやloglossは一致するが、RMSEは一致しない。\n",
    "（各foldの平均の方が小さくなる）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1272,
     "status": "ok",
     "timestamp": 1586847229378,
     "user": {
      "displayName": "adsc mogmog",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiVVjAQh221NhImxTQYD760vopRrKw8A2fQPHxn=s64",
      "userId": "12779601883796982034"
     },
     "user_tz": -540
    },
    "id": "gLxqaBBHLOvN",
    "outputId": "3dd964c0-97d7-49b9-de64-cfa6174abdd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.128533\teval-error:0.1516\n",
      "[1]\ttrain-error:0.115333\teval-error:0.146\n",
      "[2]\ttrain-error:0.109333\teval-error:0.1376\n",
      "[3]\ttrain-error:0.105333\teval-error:0.1364\n",
      "[4]\ttrain-error:0.096933\teval-error:0.1384\n",
      "[5]\ttrain-error:0.094667\teval-error:0.1364\n",
      "[6]\ttrain-error:0.087333\teval-error:0.1296\n",
      "[7]\ttrain-error:0.084933\teval-error:0.1244\n",
      "[8]\ttrain-error:0.078133\teval-error:0.1208\n",
      "[9]\ttrain-error:0.073733\teval-error:0.1172\n",
      "[0]\ttrain-error:0.124\teval-error:0.1512\n",
      "[1]\ttrain-error:0.1156\teval-error:0.1452\n",
      "[2]\ttrain-error:0.110933\teval-error:0.1404\n",
      "[3]\ttrain-error:0.1072\teval-error:0.1396\n",
      "[4]\ttrain-error:0.097067\teval-error:0.1364\n",
      "[5]\ttrain-error:0.092133\teval-error:0.1312\n",
      "[6]\ttrain-error:0.087333\teval-error:0.124\n",
      "[7]\ttrain-error:0.084133\teval-error:0.1236\n",
      "[8]\ttrain-error:0.0804\teval-error:0.12\n",
      "[9]\ttrain-error:0.0768\teval-error:0.1208\n",
      "[0]\ttrain-error:0.130267\teval-error:0.1576\n",
      "[1]\ttrain-error:0.1188\teval-error:0.1384\n",
      "[2]\ttrain-error:0.113067\teval-error:0.1416\n",
      "[3]\ttrain-error:0.1056\teval-error:0.1304\n",
      "[4]\ttrain-error:0.097067\teval-error:0.1372\n",
      "[5]\ttrain-error:0.092133\teval-error:0.1296\n",
      "[6]\ttrain-error:0.089867\teval-error:0.1284\n",
      "[7]\ttrain-error:0.084533\teval-error:0.1256\n",
      "[8]\ttrain-error:0.080533\teval-error:0.1224\n",
      "[9]\ttrain-error:0.074667\teval-error:0.1184\n",
      "[0]\ttrain-error:0.126933\teval-error:0.1492\n",
      "[1]\ttrain-error:0.118133\teval-error:0.1532\n",
      "[2]\ttrain-error:0.111867\teval-error:0.1468\n",
      "[3]\ttrain-error:0.1036\teval-error:0.1368\n",
      "[4]\ttrain-error:0.098133\teval-error:0.1384\n",
      "[5]\ttrain-error:0.091333\teval-error:0.1352\n",
      "[6]\ttrain-error:0.087467\teval-error:0.1304\n",
      "[7]\ttrain-error:0.081467\teval-error:0.1292\n",
      "[8]\ttrain-error:0.0744\teval-error:0.1284\n",
      "[9]\ttrain-error:0.070267\teval-error:0.126\n",
      "0.2966626205723733\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# クロスバリデーション\n",
    "# -----------------------------------\n",
    "# クロスバリデーションでのデータの分割\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# KFoldクラスを用いてクロスバリデーションの分割を行う\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx in kf.split(train_x):\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "# -----------------------------------\n",
    "# クロスバリデーションを行う\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Modelクラスを定義しているものとする\n",
    "# Modelクラスは、fitで学習し、predictで予測値の確率を出力する\n",
    "\n",
    "scores = []\n",
    "\n",
    "# KFoldクラスを用いてクロスバリデーションの分割を行う\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx in kf.split(train_x):\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "    # 学習の実行、バリデーションデータの予測値の出力、スコアの計算を行う\n",
    "    model = Model()\n",
    "    model.fit(tr_x, tr_y, va_x, va_y)\n",
    "    va_pred = model.predict(va_x)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# 各foldのスコアの平均をとる\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "043AGIj8fAUE"
   },
   "source": [
    "### 5.2.3 stratified k-fold（層化処理）\n",
    "\n",
    "分類タスクの場合に、foldごとに含まれるクラスの割合を等しくすること。（stratified sampling)\n",
    "学習データとテストデータに含まれるデータのクラス毎の割合が同程度であると仮定すると、この手法が妥当でバリデーションの評価が安定する。\n",
    "\n",
    "ランダムに分割した場合、各クラスの割合にムラが生じて評価のブレが大きくなる可能性があるので、この処理が重要。特に多クラス分類の場合に必要。\n",
    "\n",
    "クラス数が少ない場合（２クラスなど）は影響が少ないので、行わない場合もある。\n",
    "\n",
    "以下層化抽出を行うコードの例\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtLjr_iXLVAL"
   },
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Stratified K-Fold\n",
    "# -----------------------------------\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# StratifiedKFoldクラスを用いて層化抽出による分割を行う\n",
    "kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx in kf.split(train_x, train_y):\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETiEgeyogJik"
   },
   "source": [
    "### group k-fold\n",
    "\n",
    "何らかのグループ単位で学習データとテストデータが分割されている場合、そのグループを無視してランダムにデータを分割すると性能を過大評価してしまう恐れがある。\n",
    "\n",
    "（例）顧客データごとに複数の行動履歴があるデータ←顧客の情報をむししてごちゃまぜに分割すると、性能が過大になる恐れ。\n",
    "\n",
    "このような場合、バリデーションにおいてもグループごとに分割が必要になる。\n",
    "\n",
    "以下コード例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tEprstQggIGu"
   },
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# GroupKFold\n",
    "# -----------------------------------\n",
    "# 4件ずつ同じユーザーがいるデータであったとする\n",
    "train_x['user_id'] = np.arange(0, len(train_x)) // 4\n",
    "# -----------------------------------\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "# user_id列の顧客IDを単位として分割することにする\n",
    "user_id = train_x['user_id']\n",
    "unique_user_ids = user_id.unique()\n",
    "\n",
    "# KFoldクラスを用いて、顧客ID単位で分割する\n",
    "scores = []\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_group_idx, va_group_idx in kf.split(unique_user_ids):\n",
    "    # 顧客IDをtrain/valid（学習に使うデータ、バリデーションデータ）に分割する\n",
    "    tr_groups, va_groups = unique_user_ids[tr_group_idx], unique_user_ids[va_group_idx]\n",
    "\n",
    "    # 各レコードの顧客IDがtrain/validのどちらに属しているかによって分割する\n",
    "    is_tr = user_id.isin(tr_groups)\n",
    "    is_va = user_id.isin(va_groups)\n",
    "    tr_x, va_x = train_x[is_tr], train_x[is_va]\n",
    "    tr_y, va_y = train_y[is_tr], train_y[is_va]\n",
    "\n",
    "# （参考）GroupKFoldクラスではシャッフルと乱数シードの指定ができないため使いづらい\n",
    "kf = GroupKFold(n_splits=4)\n",
    "for tr_idx, va_idx in kf.split(train_x, train_y, user_id):\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmgXXJJUiw49"
   },
   "source": [
    "### 5.2.5 leave-one-out(LOO)\n",
    "\n",
    "学習データのレコードが極めて少ない場合に、fold数＝学習データ（つまりバリデーションデータが１件）とする手法。\n",
    "\n",
    "n_splitにレコード数を指定すれば良い。（LeaveOneOutクラスもある）\n",
    "\n",
    "以下LeaveOneOutクラスによるサンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fK1DFBHiTrb"
   },
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# leave-one-out\n",
    "# -----------------------------------\n",
    "# データが100件しかないものとする\n",
    "train_x = train_x.iloc[:100, :].copy()\n",
    "# -----------------------------------\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "for tr_idx, va_idx in loo.split(train_x):\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KY8OPvqgjnT-"
   },
   "source": [
    "GBDTやニューラルネットでLOOを使い、アーリーストッピングを用いると、バリデーションデータに最も都合が良いタイミングで学習が止められてしまうのでモデルの精度が過大評価される。\n",
    "(LOOでなくてもfold数が多くバリデーションデータが小さい場合同様の問題が起こることがある）\n",
    "\n",
    "一旦各foldでアーリーストッピングを行った後に、その平均値などで適切なイテレーション数を見積もって再度クロスバリデーションを行うなどして対策する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mD2CJqMWkO1i"
   },
   "source": [
    "## 5.3 時系列データのバリデーション手法\n",
    "\n",
    "時系列データの場合、過去のデータから時間的に新しいデータに対する予測が求められることが多い。\n",
    "このため、学習データとテストデータは時系列に沿って分割されることが多く、学習データにはテストデータと同じ期間は含まれない。\n",
    "\n",
    "単純にランダム分割すると同じ期間のデータが学習できてしまい、時間的に近いデータは似た振る舞いをすることが多いので、モデルの性能を過大評価してしまう危険性が高い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSJgBKcRlK9k"
   },
   "source": [
    "### 5.3.1 時系列データのhold-out法\n",
    "\n",
    "（図５．３参照）\n",
    "学習データのうちテストデータに近い期間をvalidationデータにしてしまう方法。\n",
    "\n",
    "時間的に近いデータほどデータの傾向も近いという仮定に基づく。\n",
    "ただし、この仮定は周期性の高いデータなどには成り立たないので、この場合は周期に基づいたvalidationデータを用意したほうが良いかもしれない。\n",
    "\n",
    "いずれの場合も、テストデータに最も傾向の近いデータを学習に使わないことになるので”もったいない”\n",
    "\n",
    "そこで、最終的にはバリデーションデータを用いて求めた最適な特徴量やパラメータをそのまま使い、バリデーションデータも含めた再学習を行ったモデルを用いる。\n",
    "（このモデルの評価はできない）\n",
    "\n",
    "通常のhold-out法同様バリデーションにデータを有効に使えていないという欠点がある。（バリデーション以外の期間を適切に予測できるモデルになっているかどうかという問題がある）\n",
    "\n",
    "以下コード例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O1Yopb0jjO01"
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# データ等の準備\n",
    "# ----------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train_xは学習データ、train_yは目的変数、test_xはテストデータ\n",
    "# pandasのDataFrame, Seriesで保持します。（numpyのarrayで保持することもあります）\n",
    "\n",
    "train = pd.read_csv('/content/kagglebook/input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('/content/kagglebook/input/sample-data/test_preprocessed.csv')\n",
    "\n",
    "# 時系列データであり、時間に沿って変数periodを設定したとする\n",
    "train_x['period'] = np.arange(0, len(train_x)) // (len(train_x) // 4)\n",
    "train_x['period'] = np.clip(train_x['period'], 0, 3)\n",
    "test_x['period'] = 4\n",
    "\n",
    "# -----------------------------------\n",
    "# 時系列データのhold-out法\n",
    "# -----------------------------------\n",
    "# 変数periodを基準に分割することにする（0から3までが学習データ、4がテストデータとする）\n",
    "# ここでは、学習データのうち、変数periodが3のデータをバリデーションデータとし、0から2までのデータを学習に用いる\n",
    "is_tr = train_x['period'] < 3\n",
    "is_va = train_x['period'] == 3\n",
    "tr_x, va_x = train_x[is_tr], train_x[is_va]\n",
    "tr_y, va_y = train_y[is_tr], train_y[is_va]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkW-WFdemkG0"
   },
   "source": [
    "### 5.3.2 時系列データのクロスバリデーション（時系列に沿って行う方法）\n",
    "\n",
    "（図５．４参照）\n",
    "\n",
    "クロスバリデーションと似ているが、時間的な順序に注意を払って過去データで学習→未来のデータでvalidationという形になるようにして学習させる。\n",
    "\n",
    "テストデータでの予測モデルも過去データで学習して未来のデータを予測するのでその状況を再現するようにして検証する。\n",
    "\n",
    "最も古いデータから学習を行うか、図５．５の右側のように、学習データの期間の長さを揃えることもできる。\n",
    "前者の場合は各foldごとにデータの量が異なるので注意が必要。\n",
    "\n",
    "あまり古いデータは性質が違って参考にならない場合などもあるので、期間やfold数などはデータの性質や計算負荷などによって考えて決めることになる。\n",
    "\n",
    "以下コード例。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttdydn0ZmcMS"
   },
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 時系列データのクロスバリデーション（時系列に沿って行う方法）\n",
    "# -----------------------------------\n",
    "# 変数periodを基準に分割することにする（0から3までが学習データ、4がテストデータとする）\n",
    "# 変数periodが1, 2, 3のデータをそれぞれバリデーションデータとし、それ以前のデータを学習に使う\n",
    "\n",
    "va_period_list = [1, 2, 3]\n",
    "for va_period in va_period_list:\n",
    "    is_tr = train_x['period'] < va_period\n",
    "    is_va = train_x['period'] == va_period\n",
    "    tr_x, va_x = train_x[is_tr], train_x[is_va]\n",
    "    tr_y, va_y = train_y[is_tr], train_y[is_va]\n",
    "\n",
    "# （参考）TimeSeriesSplitの場合、データの並び順しか使えないため使いづらい\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=4)\n",
    "for tr_idx, va_idx in tss.split(train_x):\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K35M53sup_xb"
   },
   "source": [
    "### 5.3.3 時系列データのクロスバリデーション（単純時間分割）\n",
    "\n",
    "データ同士の時間的な前後関係をあまり気にしなくて良い場合もある。そのような場合バリデーションデータより将来のデータを学習に含めても問題ない。\n",
    "\n",
    "→図５．６のように単純に時間分割してクロスバリデーションする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULuHqhSBp-x4"
   },
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 時系列データのクロスバリデーション（単純に時間で分割する方法）\n",
    "# -----------------------------------\n",
    "# 変数periodを基準に分割することにする（0から3までが学習データ、4がテストデータとする）\n",
    "# 変数periodが0, 1, 2, 3のデータをそれぞれバリデーションデータとし、それ以外の学習データを学習に使う\n",
    "\n",
    "va_period_list = [0, 1, 2, 3]\n",
    "for va_period in va_period_list:\n",
    "    is_tr = train_x['period'] != va_period\n",
    "    is_va = train_x['period'] == va_period\n",
    "    tr_x, va_x = train_x[is_tr], train_x[is_va]\n",
    "    tr_y, va_y = train_y[is_tr], train_y[is_va]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QbHMaRsgqhCR"
   },
   "source": [
    "### 5.3.4 時系列データのバリデーションの注意点\n",
    "\n",
    "時系列データでは、タスクの設計やデータの性質や分割のされ方で行うべきバリデーションが変わる。\n",
    "\n",
    "タスクに応じて特殊なバリデーションを行うのが有効な場合もある。\n",
    "\n",
    "特徴量の作成でも注意が必要で、テストデータに対して利用できる情報が何かを意識しないと危険。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7Rg5Vq4uU33"
   },
   "source": [
    "### author's opinion\n",
    "\n",
    "時系列にそって行う方法が安全なのでこちらが基本だが、目的変数が過去の目的変数の情報をそれほど持たない場合や、使えるデータが少なく十分なデータで学習できない場合には、単純に時間で分割する方法が有効な場合もある。\n",
    "\n",
    "#### 大まかな方針\n",
    "\n",
    "データが十分にあるバア愛は、時系列に沿った方法でバリデーションを行う。\n",
    "バリデーションの区切りはデータの時間的な粒度を見て決める。区切る期間が大きすぎると、スコアのブレがデータなのか学習データの機関の違いなのかを考察しづらくなる。\n",
    "\n",
    "予測精度が安定しているかを確認したり、バリデーションスコアとLeaderBoardの相関を見ながら、バリデーション期間と学習データの期間を考える。\n",
    "あえて同じバリデーションデータに対して使う学習データの期間をずらしてみて、どの程度予測スコアが変動するかを見るのも良い。\n",
    "\n",
    "データが十分にないときは、単純に時間で分割する方法のバリデーションとしたり、データについてのドメイン知識から仮設を立ててうまく特徴量を作ることなどが考えられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xrh12umv-Bz"
   },
   "source": [
    "### 5.3.5 Recruit Restaurant Visitor Forecasting\n",
    "\n",
    "飲食店の将来の来客数を予測するタスクの例。\n",
    "\n",
    "筆者は、学習データの末端４週間のうち、予測日の曜日に一致する日のみをバリデーションに用いた。\n",
    "> 曜日を合わせることと、同じ曜日の複数日をバリデーションデータに加えることで、日による評価のばらつきを低減するのが狙い\n",
    "\n",
    "時間的な傾向が大きいデータでは、あまり過去のデータをバリデーション対象に含めると、テストデータに対する汎化性能と乖離する恐れがある。\n",
    "→試行錯誤して決める\n",
    "\n",
    "\n",
    "最終的にバリデーションデータも含めた学習を行いモデルを作成し直す。（モデルのパラメータはバリデーションで最適化されたものを用いているので問題ないと判断）\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4Lig7Krxbpf"
   },
   "source": [
    "### 5.3.6 Santander product Recommendation\n",
    "\n",
    "Santander銀行の顧客ごとの金融商品の購入商品を予測するタスク。\n",
    "\n",
    "学習データが２０１５年２月〜２０１６年５月\n",
    "予測対象が２０１６年６月\n",
    "←前月までのデータを学習に使える\n",
    "\n",
    "このような場合、基本的な戦略は４月までを学習データに５月をバリデーションデータにする。\n",
    "\n",
    "#### 筆者の戦略\n",
    "\n",
    "このコンペは月ごとのデータが大きく、単月データでも十分な性能が出るので、２０１６年の４月、３月と一月分のデータで複数のモデルを作成しそれらのアンサンブルを作成。\n",
    "この際のバリデーションデータに２０１６年５月のデータを用いた。\n",
    "\n",
    "２０１６年の５月のデータを学習に使っていないので、さらに５月のデータでモデルを作成し４月のデータをバリデーションデータとしてアンサンブルに加えた。\n",
    "（リークが発生しないようにちゅうしないといけない）\n",
    "\n",
    "このコンペは商品によって年間の周期性が強く現れるものがあるのが特徴。\n",
    "これを予測するのには学習データやバリデーションデータに直近のデータを用いるのは適切ではない。\n",
    "そこで１年前の２０１５年６月のデータを学習データに用いる事が考えられるが、バリデーションデータがない。\n",
    "そこで、（苦肉の策として）２０１５年６月のデータを学習データとし、２０１５年７月のデータをバリデーションデータとした。\n",
    "テストデータに対する制度を正しく見積もることはできないが、特徴量選択やパラメータチューニングの指針にはできると判断した。（さらにPublic Leaderboardのスコアも参照して確認）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIzrzBj-0gIq"
   },
   "source": [
    "## 5.4 バリデーションのポイントとテクニンク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Due1cW5s0mRj"
   },
   "source": [
    "## 5.4.1 バリデーションを行う目的\n",
    "\n",
    "- モデル改善の指針となるスコアを出す\n",
    "\n",
    "正しくバリデーションできていることは、モデルの性能評価に重要。\n",
    "コンペでの評価指標とあえて異なる（安定した）評価指標を行うという方法もある。\n",
    "\n",
    "- テストデータに対するスコアやそのばらつきを見る\n",
    "\n",
    "バリデーションのスコアから、分析コンペの評価指標でのスコアを見積もる。見積もったスコアとpublic leaderboardのスコアを比較して考察する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cB3IJ_GX31v_"
   },
   "source": [
    "### 5.4.2 学習データとテストデータの分割を真似る\n",
    "\n",
    "どのように分割すればよいか迷ってしまった場合に、学習データとテストデータの分割の仕方を真似してしまう方法がある。\n",
    "\n",
    "テストデータの予測に使えるのと同等の情報をつかって、バリデーションデータの予測をしたことになり、\n",
    "テストデータの予測をするモデルの適切な評価と言える。\n",
    "\n",
    "データの分割が複雑すぎる場合は真似できない場合もあるが、できるだけ分割の方法を近づけるバリデーションを考えることはできる。\n",
    "\n",
    "（例）図５．７／５．８\n",
    "（１）のケース　：　ランダムに抽出された半分のユーザーがテストデータで残り半分が学習データ\n",
    "（２）のケース　：　その時点でのすべてのユーザーがテストデータ。過去の各月松のユーザーと翌月に解約したかどうかの情報が与えられる。\n",
    "\n",
    "（１）通常のクロスバリデーションで良い\n",
    "データがランダムかどうかは留意する必要がある。例えば学習データとテストデータが地域で分割されていると、バリデーションでも地域でgroup K-foldを行うほうが良い。\n",
    "\n",
    "（２）時系列に沿って行うバリデーションを行う\n",
    "この場合は、ランダムにバリデーションを行ってしまうと、時間的な順序が逆転したり同じ月のデータを使ってしまったりしてフェアでない評価になってしまう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mp3O3w8O5-_y"
   },
   "source": [
    "### 5.4.3 学習データとテストデータの分布が違う場合\n",
    "\n",
    "時間や地域などをもとに学習データとテストデータを分割した場合、それぞれなにかのパラメータが違う分布からのサンプルとして与えられたと考えられる場合がある。\n",
    "\n",
    "時系列データで時間に沿って分割した場合などがこれに該当する。\n",
    "\n",
    "このような場合は、学習データと同じ分布のデータを予測するだけでは不十分で、テストデータの分布のデータで良い予測をしなければならない。\n",
    "\n",
    "分布の違いに頑強なモデルを作るのが理想だが、Leaderboardのスコアを参考にテストデータに合わせていくことも必要かもしれない。\n",
    "\n",
    "対応策\n",
    "\n",
    "- 学習データとテストデータの傾向の違いを、データの作成過程や探索的データ分析（EDA)をもとに考察する\n",
    "- adversarial validation の結果や public leaderboardのスコアを参考に、Leaderboardのスコアに相関するバリデーション方法を確立する\n",
    "- モデルを複雑にしすぎない。効く理由が説明できる特徴量を使うことで、分布の違いに頑強なモデルを作る。\n",
    "- さまざまなモデルの平均を取るアンサンブルによって予測を安定させる。\n",
    "- adversarial validationのスコアが低くなるように特徴量を変換し、分布の違いに影響され辛くする。\n",
    "\n",
    "（EDAについてはテキスト１章参照）\n",
    "大雑把に言うと、（色々分析←平均出したりグラフ書いたり。。して）データについて理解すること\n",
    "\n",
    "#### adversarial validation\n",
    "\n",
    "手法\n",
    "- 学習データとテストデータを統合し、テストデータかどうかを目的変数とするモデルを作成する。\n",
    "- モデルに基づいて、それぞれのレコードがテストデータである確率の予測値を出力する\n",
    "- テストデータである確率が高いと予測される学習データを一定数選んでバリデーションデータとする\n",
    "\n",
    "学習データとテストデータを統合し、テストデータかどうかを分類するモデルを作成\n",
    "分類精度が０．５を十分上回る（つまりテストデータと学習データが異なるため予測可能性がある）場合に使う。\n",
    "\n",
    "（AUCは７５ｐ参照。完全予測で１．０、完全ランダムで０．５）\n",
    "\n",
    "#### Author's opinion\n",
    "\n",
    "学習データとテストデータの差異の要因が分かる場合は、それを模倣することでより確実なバリデーションを構築できる。\n",
    "EDAで違いが発見できなくても、adversarial validationで判別に効いている特徴量を確認し、色々仮設を立てて再度EDAを行ってみると良い。\n",
    "\n",
    "リークなどの問題で、学習データとテストデータで異なる性質を持つ特徴量を作ってしまった場合、与えられたデータの違いを考察するという目的にこの特徴量は使わないほうが良い。\n",
    "\n",
    "手元のバリデーションとLeaderboardのスコアの整合が取れないときは、adversarial validationを用いて自身の作成した特徴量のどこに問題があるかを調べるのも有効。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymt_Nj4xdNlv"
   },
   "source": [
    "### 5.4.4 Leaderboardの情報の活用\n",
    "\n",
    "\"trust your CV\" : Leaderboardのスコアに惑わされずに、バリデーションによってモデルを適切に評価することが重要。\n",
    "ただし、Leaderboardのスコアはうまく参考にできることもある。\n",
    "\n",
    "#### バリデーションとの差異を考察する\n",
    "\n",
    "バリデーションとLeaderboardのスコアの水準と動きが整合していない場合、\n",
    "\n",
    "- 偶然\n",
    "- バリデーションデータとテストデータの分布が異なる\n",
    "- バリデーションの設計が不適切\n",
    "\n",
    "> 偶然の場合は、Publicのテストデータと同じデータ数のhold-outのデータ（複数）のスコアのばらつきと比べることで、偶然の範囲かどうかを評価できる。\n",
    "\n",
    "> データの分布が異なる場合は、データの性質や分割の方法について考察する。例えば、時系列データを時間によって分割していると分布が異なる可能性が高い。月ごとにバリデーションを行うことで月ごとのスコアのブレを確認できる。このようなケースではDiscussionでバリデーションのスコアとLeaderboardのスコアの乖離について議論するトピックが立つことが多い。ない場合はバリデーションが不適切な可能性を疑ったほうが良い\n",
    "\n",
    "#### データの分割とLeaderboardスコア\n",
    "\n",
    "図５．９参照\n",
    "\n",
    "1の場合\n",
    "\n",
    "\n",
    "> データがランダムに分割。この場合はpublicリーダーボードは気にせずクロスバリデーションで評価すれば良い。\n",
    "\n",
    "2の場合\n",
    "\n",
    "> 訓練データが少ない場合。public Leaderboardのスコアも利用することでより安定した評価が期待できる\n",
    "\n",
    "3の場合\n",
    "\n",
    "> publicのデータのほうがprivateのテストデータに近いのでpublicLBのスコアが良ければPrivateのテストデータも良い可能性が高い。（が、過剰適合しているだけの可能性もあるので注意）\n",
    "\n",
    "4の場合\n",
    "\n",
    "> PublicとPrivateのテストデータが同じ期間でランダム分割されている。このケースではpublicがよければprivateも良い可能性が高いので、PublicLBの利用が強く推奨される。\n",
    "\n",
    "#### shake up\n",
    "\n",
    "public LBに過適合してしまっていたり、public LBのテストデータのレコードが少なすぎたりすると、PublicのスコアがよくてもPrivateで一気に順位が入れ替わることがあり、これをshake upという。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjZW_raxhoHO"
   },
   "source": [
    "### 5.4.5 バリデーションやpublic LBへの過適合\n",
    "\n",
    "バリデーションデータやPublicLBを参照して、パラメータのチューニングを繰り返しすぎると、\n",
    "バリデーションデータやPublic LBに過適合してしまい、実力以上のスコアが出ることがある。\n",
    "\n",
    "各提出におけるバリデーションのスコアと、public LBのスコアをプロットして感覚的にブレの影響を掴んだり、クロスバリデーションの分割を変える事が考えられる。\n",
    "\n",
    "#### クロスバリデーションの分割を変える\n",
    "\n",
    "パラメータチューニングのためのバリデーションの分割と、\n",
    "モデルの評価のためのバリデーションの分割を変えるという方法が考えられる。\n",
    "\n",
    "分割を変えることは、乱数のseedを変えれば良い。\n",
    "データの全体が変わっていないが、public leaderboradのデータをバリデーションに用いていないhold-out相当なので、この方法で十分な場合が多い。\n",
    "\n",
    "より保守的には、hold-outデータを取り分けておき、残りのデータでクロスバリデーションによりパラメータチューニングを行い、hold-outデータで評価を行う方法もある。\n",
    "データが少なくなるので分析コンペではあまり使われない。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKI02XFrhv_d"
   },
   "source": [
    "### 5.4.6 クロスバリデーションのfoldごとに特徴量を作り直す\n",
    "\n",
    "#### 時系列データでない場合\n",
    "\n",
    "foldごとに特徴量を作り直す典型的な例は、target Encoding（データ全体の平均を利用するので）\n",
    "学習データのencodingを行うときにはテストデータの目的変数は使えないが、この制約をバリデーションにおいても再現するために、foldごとにその時の学習データの目的変数のみを使ってtarget encodingし直す必要がある。\n",
    "\n",
    "#### 時系列データの場合\n",
    "\n",
    "図５．１１のように\n",
    "テストデータとバリデーションデータで使うデータの期間を整合的にすることで、評価の整合性を保つ。\n",
    "\n",
    "図の右側のように評価対象より先の時点のログデータを使って特徴量を作ってはいけない。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QIzDFULvhwL4"
   },
   "source": [
    "### 5.4.7 使える学習データを増やす\n",
    "\n",
    "与えられたデータから新たなデータを生成して学習データを増やすことができる。\n",
    "（data argumentation)\n",
    "画像データを扱うタスクで、画像を回転・反転させたり歪ませることで学習データを増やすことはよく行われている。\n",
    "\n",
    "テーブルデータではこのようなことは難しいが可能な例もある\n",
    "\n",
    "#### instacart market basket analysis\n",
    "\n",
    "オンラインの食料品配達サービスで、前回に引き続き注文される商品を予測するタスク。\n",
    "\n",
    "各ユーザーの最新の注文のみがtrainとtestに分割され、それ以外はprior扱い。\n",
    "priorを学習データとして使うことができる。\n",
    "（これって水増しの例になっている。。？？？？）\n",
    "\n",
    "\n",
    "#### Recruit restaurant visitor forecasting\n",
    "\n",
    "ランダムに一分のデータを削ったあとに特徴量作成を行うことで、新たに学習データを作り学習データを増やす方法が使われた。\n",
    "\n",
    "各店舗の最初のデータは開店日ではなく、サービスへの登録日であると予測できた。\n",
    "この場合各店舗のサービス登録日が異なった場合のデータを、図５．１３のように各店舗の先頭のデータを削ることで作ることができる。\n",
    "\n",
    "このような処理の後にtarget encodingなどの特徴量作成を行うと、データを削らない場合と比べて特徴量が少し異なる学習データを新たに生成できる。\n",
    "\n",
    "この例では、この増やした特徴量を元のデータに加えるのではなく、別のモデルの学習に使い、モデルの予測のアンサンブルを用いていた。\n",
    "\n",
    "このプロセスはテストデータに対しても行われていた。(test time argumentationと類似の手法）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZ0XBSpmqLne"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMDyg9ilRNqrxFHY6mMa4Xg",
   "collapsed_sections": [],
   "mount_file_id": "1Od4N8ZgxjUFxe08279ltCLk8y_S2K90T",
   "name": "kaggle5.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
