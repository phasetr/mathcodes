{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 モデルのチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 パラメータチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 ハイパーパラメータの探索方法\n",
    "\n",
    "- 手動\n",
    "- グリッドサーチ\n",
    "- ランダムサーチ\n",
    "- ベイズ最適化\n",
    "\n",
    "----\n",
    "\n",
    "- 手動\n",
    "    - 手動で頑張る。\n",
    "\n",
    "\n",
    "- グリッドサーチ\n",
    "    - ハイパーパラメータの候補を決めて網羅的に探索する手法。計算コストが高い\n",
    "    - scikit-learnのmodel_selectionモジュールのGridSearchCVという実装がある\n",
    "\n",
    "\n",
    "- ランダムサーチ\n",
    "    - 候補点を適当に見繕ってランダムに組み合わせる。設定した計算回数まで行ったら終わり\n",
    "    - RandomizedSearchCVという実装がある。\n",
    "    \n",
    "    \n",
    "- ベイズ最適化\n",
    "    - 以前に計算したハイパーパラメータの履歴に基づいて次にt探索すべきハイパーパラメータをベイズ確率に基づいて選択する手法。\n",
    "    - ライブラリ hyperopt, gpyoptm spearmint, scikit-optimize, optunaが挙げられる\n",
    "    - トースターのおすすめはoptuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチ、 ランダムサーチのコード\n",
    "import numpy as np\n",
    "\n",
    "param1_list = [3, 5, 7, 9]\n",
    "param2_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "# grid serach\n",
    "grid_search_params = []\n",
    "for p1 in param1_list:\n",
    "    for p2 in param2_list:\n",
    "        grid_search_params.append((p1, p2))\n",
    "\n",
    "#こっちの方が速い(grid search)\n",
    "grid_search_params2 = [(p1, p2) for p1 in param1_list for p2 in param2_list]\n",
    "\n",
    "#ランダムサーチ\n",
    "random_search_param = []\n",
    "trials = 15\n",
    "for i in range(trials):\n",
    "    p1 = np.random.choice(param1_list)\n",
    "    p2 = np.random.choice(param2_list)\n",
    "    random_search_param.append((p1, p2))\n",
    "\n",
    "random_search_params2 = [(np.random.choice(p1), np.random.choice(p2)) for p1 in param1_list for p2 in param2_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bergesta and Bengio によるとグリッドサーチよりもランダムサーチのほうが効率が良いとのこと。\n",
    "\n",
    "詳しくは308ページの図6.1\n",
    "\n",
    "著者の見解：top Kagglerは手動でやっている。著者の手法は308ページ\n",
    "\n",
    "トースターの意見：おそらく、特徴量+ハイパーパラメータに造詣が深い。自分でベイズ最適化できる脳を持っている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 パラメータチューニングで設定すること\n",
    "\n",
    "1. ベースラインとなるハイパーパラメータ\n",
    "2. 探索する対象となるハイパーパラメータとその範囲\n",
    "3. 手動でやるか自動でやるか\n",
    "4. 評価の枠組み(クロスバリデーション(CV) などのfoldの分け方)\n",
    "\n",
    "ベースラインとなるハイパーパラメータを設定する。それがわからないのが普通なので適当なリンクを探しておく\n",
    "\n",
    "とりあえず設定したら学習させてみる。過去のコンペ等も参考にして学習率等を決める。\n",
    "\n",
    "次に探索する範囲を決める。これも適当なリンクを探しておく\n",
    "\n",
    "よほど時間があるとき以外は探索範囲決めて寝よう(ベイズ最適化しよう)\n",
    "\n",
    "あとはCVを行う。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 パラメータチューニングのポイント\n",
    "\n",
    "- 重要なハイパーパラメータを見つけてそこからチューニング\n",
    "- ハイパーパラメータの理解が大事。増減させるとモデルが複雑になるのかそれとも単純になるのか\n",
    "- ハイパーパラメータのある範囲を探索したときにその上下限の付近に良いスコアが出ているときは探索範囲を広くするほうがいい\n",
    "- 乱数の種を固定して結果が再現されるようにする(作業性の確保)\n",
    "- 乱数の種やfoldの分割乱数の種を変えたときのスコアをみるとハイパーパラメータを変えたときのスコアの変化がただのばらつきなのかハイパーパラメータの変更による改善なのか推測できる\n",
    "\n",
    "著者の意見\n",
    "\n",
    "モデルがGBDTなら良い特徴量を与えたほうがハイパーパラメータより効く。(トースターも同意する)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4 ベイズ最適化でのパラメータ探索\n",
    "\n",
    "- hyperopt\n",
    "    - 著者のお気に入り？\n",
    "- optuna\n",
    "    - トースターのお気に入り\n",
    "    - ナウなヤングに流行り。Pytorhエコシステムには採用される。\n",
    "    - 探索アルゴリズムはTPE、CMA−ES、グリッドサーチがあるはず。デフォルトはTPE\n",
    "    - 折角なのでoptunaで例を実装し直してみる。\n",
    "    - Define-by-RunスタイルのAPI\n",
    "    - 学習曲線を用いた試行の枝刈り\n",
    "    - 並列分散最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-24 19:54:07,824] Finished trial#0 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.716314968017777, 'lambda_l2': 1.9502397013639836e-05, 'num_leaves': 24, 'feature_fraction': 0.9240148395827148, 'bagging_fraction': 0.7913416154445566, 'bagging_freq': 6, 'min_child_samples': 46}. Best is trial#0 with value: 0.958041958041958.\n",
      "[I 2020-04-24 19:54:07,961] Finished trial#1 with value: 0.972027972027972 with parameters: {'lambda_l1': 0.1061032486664129, 'lambda_l2': 1.1995875386927504e-08, 'num_leaves': 126, 'feature_fraction': 0.5952718615728272, 'bagging_fraction': 0.894098966336744, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial#1 with value: 0.972027972027972.\n",
      "[I 2020-04-24 19:54:08,080] Finished trial#2 with value: 0.965034965034965 with parameters: {'lambda_l1': 1.4461167784147193e-07, 'lambda_l2': 7.79345692117948, 'num_leaves': 52, 'feature_fraction': 0.5691302301221803, 'bagging_fraction': 0.4551346441541247, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial#1 with value: 0.972027972027972.\n",
      "[I 2020-04-24 19:54:08,205] Finished trial#3 with value: 0.951048951048951 with parameters: {'lambda_l1': 0.0006061232666175017, 'lambda_l2': 5.466314757322031e-07, 'num_leaves': 181, 'feature_fraction': 0.44833756065772457, 'bagging_fraction': 0.6092115527112392, 'bagging_freq': 3, 'min_child_samples': 72}. Best is trial#1 with value: 0.972027972027972.\n",
      "[I 2020-04-24 19:54:08,324] Finished trial#4 with value: 0.951048951048951 with parameters: {'lambda_l1': 0.0014408795235106163, 'lambda_l2': 3.941849477507472, 'num_leaves': 7, 'feature_fraction': 0.7133437922266765, 'bagging_fraction': 0.643249331812608, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial#1 with value: 0.972027972027972.\n",
      "[I 2020-04-24 19:54:08,453] Finished trial#5 with value: 0.9790209790209791 with parameters: {'lambda_l1': 0.0022565945902105746, 'lambda_l2': 0.00012333771648926936, 'num_leaves': 165, 'feature_fraction': 0.5456886196808799, 'bagging_fraction': 0.6321207275950911, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:08,574] Finished trial#6 with value: 0.9790209790209791 with parameters: {'lambda_l1': 2.592998230136422, 'lambda_l2': 7.63275563309378e-07, 'num_leaves': 22, 'feature_fraction': 0.798483992979943, 'bagging_fraction': 0.9388731547483743, 'bagging_freq': 1, 'min_child_samples': 84}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:08,698] Finished trial#7 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.0025639575297373247, 'lambda_l2': 2.3027451809052547e-07, 'num_leaves': 101, 'feature_fraction': 0.5614631922623283, 'bagging_fraction': 0.9104379698784588, 'bagging_freq': 7, 'min_child_samples': 60}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:08,825] Finished trial#8 with value: 0.9370629370629371 with parameters: {'lambda_l1': 5.959672702899483, 'lambda_l2': 0.002996076281192596, 'num_leaves': 191, 'feature_fraction': 0.6362300969028641, 'bagging_fraction': 0.9626676461337901, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:08,950] Finished trial#9 with value: 0.965034965034965 with parameters: {'lambda_l1': 0.015976240961050655, 'lambda_l2': 0.891688805379183, 'num_leaves': 12, 'feature_fraction': 0.9813094929473458, 'bagging_fraction': 0.8071284271987917, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:09,089] Finished trial#10 with value: 0.9790209790209791 with parameters: {'lambda_l1': 3.019200253495415e-06, 'lambda_l2': 0.0031705470184120923, 'num_leaves': 240, 'feature_fraction': 0.40250980917210644, 'bagging_fraction': 0.4855872242276609, 'bagging_freq': 5, 'min_child_samples': 98}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:09,224] Finished trial#11 with value: 0.958041958041958 with parameters: {'lambda_l1': 1.3723420281356769e-05, 'lambda_l2': 3.416818460295844e-05, 'num_leaves': 178, 'feature_fraction': 0.7938604692845402, 'bagging_fraction': 0.563048791717198, 'bagging_freq': 1, 'min_child_samples': 91}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:09,352] Finished trial#12 with value: 0.972027972027972 with parameters: {'lambda_l1': 4.172590888054789, 'lambda_l2': 2.2540453673536874e-06, 'num_leaves': 75, 'feature_fraction': 0.8271212013330639, 'bagging_fraction': 0.7551076644890026, 'bagging_freq': 2, 'min_child_samples': 74}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:09,487] Finished trial#13 with value: 0.972027972027972 with parameters: {'lambda_l1': 3.384377493681918e-05, 'lambda_l2': 1.0535200067738175e-08, 'num_leaves': 235, 'feature_fraction': 0.5026571612205344, 'bagging_fraction': 0.7100978269111067, 'bagging_freq': 4, 'min_child_samples': 79}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:09,625] Finished trial#14 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.0652679489312571, 'lambda_l2': 0.00060299406546626, 'num_leaves': 150, 'feature_fraction': 0.7182277446942895, 'bagging_fraction': 0.5481176572796307, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:09,761] Finished trial#15 with value: 0.958041958041958 with parameters: {'lambda_l1': 2.1518935811509108e-08, 'lambda_l2': 0.05880924264228292, 'num_leaves': 126, 'feature_fraction': 0.8473120907076016, 'bagging_fraction': 0.6962158041434332, 'bagging_freq': 5, 'min_child_samples': 60}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:09,914] Finished trial#16 with value: 0.965034965034965 with parameters: {'lambda_l1': 0.5172065786203744, 'lambda_l2': 2.7972927889023194e-05, 'num_leaves': 203, 'feature_fraction': 0.662129772638898, 'bagging_fraction': 0.994265875233697, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial#5 with value: 0.9790209790209791.\n",
      "[I 2020-04-24 19:54:10,050] Finished trial#17 with value: 0.993006993006993 with parameters: {'lambda_l1': 0.00010644546543696687, 'lambda_l2': 8.060164358035812e-08, 'num_leaves': 155, 'feature_fraction': 0.738197309672961, 'bagging_fraction': 0.8605153674117506, 'bagging_freq': 7, 'min_child_samples': 85}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:10,188] Finished trial#18 with value: 0.972027972027972 with parameters: {'lambda_l1': 9.785741813563236e-05, 'lambda_l2': 3.1104840153904995e-08, 'num_leaves': 157, 'feature_fraction': 0.49169145322780367, 'bagging_fraction': 0.8318134869401513, 'bagging_freq': 7, 'min_child_samples': 63}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:10,321] Finished trial#19 with value: 0.972027972027972 with parameters: {'lambda_l1': 1.2951464367211539e-06, 'lambda_l2': 0.05906616318909937, 'num_leaves': 219, 'feature_fraction': 0.7580452689040972, 'bagging_fraction': 0.6663467807879934, 'bagging_freq': 6, 'min_child_samples': 99}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:10,471] Finished trial#20 with value: 0.965034965034965 with parameters: {'lambda_l1': 0.006262987395414582, 'lambda_l2': 7.091028499274142e-08, 'num_leaves': 97, 'feature_fraction': 0.9000656603228276, 'bagging_fraction': 0.881360391406167, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:10,596] Finished trial#21 with value: 0.6363636363636364 with parameters: {'lambda_l1': 3.0769530248763142e-06, 'lambda_l2': 0.004782761830962974, 'num_leaves': 157, 'feature_fraction': 0.422110194653221, 'bagging_fraction': 0.4271014010671317, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:10,731] Finished trial#22 with value: 0.951048951048951 with parameters: {'lambda_l1': 0.00012127166680347796, 'lambda_l2': 0.00021599651274517258, 'num_leaves': 240, 'feature_fraction': 0.4102222342652705, 'bagging_fraction': 0.4929122182018571, 'bagging_freq': 4, 'min_child_samples': 94}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:10,868] Finished trial#23 with value: 0.972027972027972 with parameters: {'lambda_l1': 0.0005704193356128301, 'lambda_l2': 1.8904154344159828e-06, 'num_leaves': 142, 'feature_fraction': 0.7566484482323472, 'bagging_fraction': 0.9377279203522081, 'bagging_freq': 1, 'min_child_samples': 85}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:11,004] Finished trial#24 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.015376511561455738, 'lambda_l2': 3.848451182550311e-06, 'num_leaves': 101, 'feature_fraction': 0.870585455456607, 'bagging_fraction': 0.9693631022828639, 'bagging_freq': 7, 'min_child_samples': 84}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:11,149] Finished trial#25 with value: 0.986013986013986 with parameters: {'lambda_l1': 2.487955733530041e-05, 'lambda_l2': 2.5817394963494365e-07, 'num_leaves': 167, 'feature_fraction': 0.645345245333521, 'bagging_fraction': 0.8626594088322077, 'bagging_freq': 3, 'min_child_samples': 67}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:11,299] Finished trial#26 with value: 0.9790209790209791 with parameters: {'lambda_l1': 3.759212859456411e-05, 'lambda_l2': 8.546479062913326e-08, 'num_leaves': 167, 'feature_fraction': 0.6573086638125156, 'bagging_fraction': 0.8416649883960996, 'bagging_freq': 3, 'min_child_samples': 69}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:11,443] Finished trial#27 with value: 0.951048951048951 with parameters: {'lambda_l1': 3.1293348463798725e-07, 'lambda_l2': 1.1317388459501617e-07, 'num_leaves': 206, 'feature_fraction': 0.6642907140425887, 'bagging_fraction': 0.8329632531237448, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:11,582] Finished trial#28 with value: 0.965034965034965 with parameters: {'lambda_l1': 1.718860181092579e-05, 'lambda_l2': 3.17161121348148e-08, 'num_leaves': 134, 'feature_fraction': 0.6337203700874401, 'bagging_fraction': 0.7616124712987167, 'bagging_freq': 2, 'min_child_samples': 68}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:11,722] Finished trial#29 with value: 0.951048951048951 with parameters: {'lambda_l1': 0.0001291831141354467, 'lambda_l2': 9.375044746763933e-06, 'num_leaves': 174, 'feature_fraction': 0.6726504570141322, 'bagging_fraction': 0.8543103370833222, 'bagging_freq': 3, 'min_child_samples': 76}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:11,867] Finished trial#30 with value: 0.958041958041958 with parameters: {'lambda_l1': 6.351118073145923e-06, 'lambda_l2': 2.9153419657261544e-07, 'num_leaves': 195, 'feature_fraction': 0.6158855548194191, 'bagging_fraction': 0.7871022802967155, 'bagging_freq': 2, 'min_child_samples': 54}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:12,017] Finished trial#31 with value: 0.951048951048951 with parameters: {'lambda_l1': 3.7526856292079614e-05, 'lambda_l2': 4.479860097797778e-08, 'num_leaves': 166, 'feature_fraction': 0.5143040209705615, 'bagging_fraction': 0.7385328950597273, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:12,161] Finished trial#32 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.0002571654480552951, 'lambda_l2': 1.0500373599021973e-08, 'num_leaves': 125, 'feature_fraction': 0.5688258432491158, 'bagging_fraction': 0.8734086000568184, 'bagging_freq': 3, 'min_child_samples': 54}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:12,298] Finished trial#33 with value: 0.972027972027972 with parameters: {'lambda_l1': 0.5815112288874381, 'lambda_l2': 9.13132776576316e-07, 'num_leaves': 114, 'feature_fraction': 0.7742757973741312, 'bagging_fraction': 0.9259360822978229, 'bagging_freq': 6, 'min_child_samples': 85}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:12,450] Finished trial#34 with value: 0.972027972027972 with parameters: {'lambda_l1': 5.845783826505336e-07, 'lambda_l2': 0.00014002905867003135, 'num_leaves': 221, 'feature_fraction': 0.5981183941332698, 'bagging_fraction': 0.811285301007979, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:12,593] Finished trial#35 with value: 0.965034965034965 with parameters: {'lambda_l1': 0.0014081592164047973, 'lambda_l2': 5.679559308443369e-06, 'num_leaves': 166, 'feature_fraction': 0.5394669770689354, 'bagging_fraction': 0.6096570189119583, 'bagging_freq': 3, 'min_child_samples': 66}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:12,740] Finished trial#36 with value: 0.965034965034965 with parameters: {'lambda_l1': 4.98265278377217e-08, 'lambda_l2': 1.4945542802008932e-07, 'num_leaves': 187, 'feature_fraction': 0.7055706868555089, 'bagging_fraction': 0.7098959198016336, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:12,882] Finished trial#37 with value: 0.972027972027972 with parameters: {'lambda_l1': 0.14080648042695904, 'lambda_l2': 4.601396325263398e-07, 'num_leaves': 38, 'feature_fraction': 0.7372514571882559, 'bagging_fraction': 0.991669714729509, 'bagging_freq': 1, 'min_child_samples': 79}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:13,027] Finished trial#38 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.00043817801037707876, 'lambda_l2': 2.0476672092701645e-08, 'num_leaves': 145, 'feature_fraction': 0.6787199966805698, 'bagging_fraction': 0.8592127345668321, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:13,185] Finished trial#39 with value: 0.965034965034965 with parameters: {'lambda_l1': 0.00280829145859516, 'lambda_l2': 6.20702161526419e-05, 'num_leaves': 166, 'feature_fraction': 0.6000987234079046, 'bagging_fraction': 0.8916404659622815, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:13,323] Finished trial#40 with value: 0.965034965034965 with parameters: {'lambda_l1': 2.5729429741971064, 'lambda_l2': 9.621061967089447e-07, 'num_leaves': 70, 'feature_fraction': 0.9728689938406231, 'bagging_fraction': 0.9446058627928492, 'bagging_freq': 5, 'min_child_samples': 94}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:13,457] Finished trial#41 with value: 0.9300699300699301 with parameters: {'lambda_l1': 2.859471305678074e-06, 'lambda_l2': 0.001062785528121741, 'num_leaves': 116, 'feature_fraction': 0.8004099750233904, 'bagging_fraction': 0.49111202117274, 'bagging_freq': 5, 'min_child_samples': 91}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:13,604] Finished trial#42 with value: 0.972027972027972 with parameters: {'lambda_l1': 4.84718598794784e-05, 'lambda_l2': 2.3430355532329157e-07, 'num_leaves': 178, 'feature_fraction': 0.6442461721785984, 'bagging_fraction': 0.8998141893762979, 'bagging_freq': 2, 'min_child_samples': 81}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:13,745] Finished trial#43 with value: 0.9230769230769231 with parameters: {'lambda_l1': 9.738081686554612e-06, 'lambda_l2': 0.011192654675952048, 'num_leaves': 225, 'feature_fraction': 0.8090667526879062, 'bagging_fraction': 0.5200423679243003, 'bagging_freq': 5, 'min_child_samples': 89}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:13,889] Finished trial#44 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.0012460862484267965, 'lambda_l2': 1.186707307325726e-05, 'num_leaves': 140, 'feature_fraction': 0.7277672257528076, 'bagging_fraction': 0.6146248566757886, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:14,031] Finished trial#45 with value: 0.993006993006993 with parameters: {'lambda_l1': 0.00027383698999923706, 'lambda_l2': 1.367901941477159e-06, 'num_leaves': 156, 'feature_fraction': 0.6944065659318861, 'bagging_fraction': 0.6527637901325676, 'bagging_freq': 1, 'min_child_samples': 70}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:14,178] Finished trial#46 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.00023712094297214626, 'lambda_l2': 1.7820949553293432e-06, 'num_leaves': 158, 'feature_fraction': 0.6917938663725718, 'bagging_fraction': 0.6641019102322337, 'bagging_freq': 3, 'min_child_samples': 50}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:14,326] Finished trial#47 with value: 0.9440559440559441 with parameters: {'lambda_l1': 0.0038037349653439407, 'lambda_l2': 1.1621090777148419e-07, 'num_leaves': 200, 'feature_fraction': 0.4610763539528788, 'bagging_fraction': 0.5558399966333409, 'bagging_freq': 1, 'min_child_samples': 72}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:14,470] Finished trial#48 with value: 0.9790209790209791 with parameters: {'lambda_l1': 6.114717268432374e-05, 'lambda_l2': 1.1373378736033207e-08, 'num_leaves': 182, 'feature_fraction': 0.5422962508124101, 'bagging_fraction': 0.5896564515004317, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:14,620] Finished trial#49 with value: 0.965034965034965 with parameters: {'lambda_l1': 3.2825806020222637e-06, 'lambda_l2': 0.16516688438500288, 'num_leaves': 247, 'feature_fraction': 0.46473419224530144, 'bagging_fraction': 0.572457767554594, 'bagging_freq': 7, 'min_child_samples': 64}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:14,760] Finished trial#50 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.014832467899918498, 'lambda_l2': 6.174572295406811e-07, 'num_leaves': 85, 'feature_fraction': 0.842211984050854, 'bagging_fraction': 0.6395718967597747, 'bagging_freq': 1, 'min_child_samples': 76}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:14,904] Finished trial#51 with value: 0.958041958041958 with parameters: {'lambda_l1': 1.7518396506511358e-05, 'lambda_l2': 5.429940122103575e-08, 'num_leaves': 150, 'feature_fraction': 0.7436193654658375, 'bagging_fraction': 0.9136483867353989, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:15,050] Finished trial#52 with value: 0.9440559440559441 with parameters: {'lambda_l1': 2.380359723155958e-05, 'lambda_l2': 0.001615080522490392, 'num_leaves': 209, 'feature_fraction': 0.7825151810077859, 'bagging_fraction': 0.41192568632773224, 'bagging_freq': 2, 'min_child_samples': 69}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:15,204] Finished trial#53 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.0008847823791681668, 'lambda_l2': 3.351452900674225e-07, 'num_leaves': 168, 'feature_fraction': 0.6991830200488266, 'bagging_fraction': 0.7912384769709278, 'bagging_freq': 1, 'min_child_samples': 82}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:15,345] Finished trial#54 with value: 0.965034965034965 with parameters: {'lambda_l1': 8.157915628380221e-05, 'lambda_l2': 2.581999370247358e-06, 'num_leaves': 132, 'feature_fraction': 0.6371047821282747, 'bagging_fraction': 0.6664587065068296, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:15,485] Finished trial#55 with value: 0.965034965034965 with parameters: {'lambda_l1': 1.0077427896766463e-06, 'lambda_l2': 0.011069079155954328, 'num_leaves': 14, 'feature_fraction': 0.7668297144396806, 'bagging_fraction': 0.6890042541644625, 'bagging_freq': 6, 'min_child_samples': 86}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:15,630] Finished trial#56 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.00019184833731091547, 'lambda_l2': 1.1693729465914688e-06, 'num_leaves': 191, 'feature_fraction': 0.818282563492104, 'bagging_fraction': 0.8392808779704819, 'bagging_freq': 7, 'min_child_samples': 78}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:15,778] Finished trial#57 with value: 0.965034965034965 with parameters: {'lambda_l1': 5.72773824539752e-05, 'lambda_l2': 2.6152055107599475e-08, 'num_leaves': 183, 'feature_fraction': 0.5475584085289493, 'bagging_fraction': 0.5824850974455558, 'bagging_freq': 1, 'min_child_samples': 62}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:15,929] Finished trial#58 with value: 0.972027972027972 with parameters: {'lambda_l1': 0.07563890195489972, 'lambda_l2': 1.0203041839881563e-08, 'num_leaves': 155, 'feature_fraction': 0.5706964055742254, 'bagging_fraction': 0.5870879785451836, 'bagging_freq': 4, 'min_child_samples': 41}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:16,082] Finished trial#59 with value: 0.9790209790209791 with parameters: {'lambda_l1': 8.397780044292676e-06, 'lambda_l2': 8.041110014663316e-05, 'num_leaves': 117, 'feature_fraction': 0.7178953179660623, 'bagging_fraction': 0.7340724303203882, 'bagging_freq': 2, 'min_child_samples': 50}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:16,231] Finished trial#60 with value: 0.965034965034965 with parameters: {'lambda_l1': 6.219576554583578e-06, 'lambda_l2': 0.00041892571975019505, 'num_leaves': 60, 'feature_fraction': 0.7152891759925116, 'bagging_fraction': 0.739535548997441, 'bagging_freq': 2, 'min_child_samples': 50}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:16,373] Finished trial#61 with value: 0.972027972027972 with parameters: {'lambda_l1': 9.079655302139887, 'lambda_l2': 7.049147036486221e-05, 'num_leaves': 118, 'feature_fraction': 0.6555583462836017, 'bagging_fraction': 0.63388041655991, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:16,519] Finished trial#62 with value: 0.958041958041958 with parameters: {'lambda_l1': 0.0004973063081986967, 'lambda_l2': 6.370427235392809e-08, 'num_leaves': 173, 'feature_fraction': 0.6852514531235685, 'bagging_fraction': 0.539479394138128, 'bagging_freq': 4, 'min_child_samples': 59}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:16,680] Finished trial#63 with value: 0.9370629370629371 with parameters: {'lambda_l1': 0.00011757416407313017, 'lambda_l2': 2.8345805187053067e-05, 'num_leaves': 183, 'feature_fraction': 0.7441397736301164, 'bagging_fraction': 0.6771777544227069, 'bagging_freq': 1, 'min_child_samples': 43}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:16,829] Finished trial#64 with value: 0.9790209790209791 with parameters: {'lambda_l1': 3.217261301290168e-05, 'lambda_l2': 1.9508063583425698e-08, 'num_leaves': 159, 'feature_fraction': 0.6196726883063213, 'bagging_fraction': 0.6286196900042765, 'bagging_freq': 4, 'min_child_samples': 68}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:16,974] Finished trial#65 with value: 0.972027972027972 with parameters: {'lambda_l1': 6.48861761971745e-05, 'lambda_l2': 1.7224535441048343e-08, 'num_leaves': 140, 'feature_fraction': 0.5247761297841391, 'bagging_fraction': 0.6205569321825133, 'bagging_freq': 4, 'min_child_samples': 71}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:17,121] Finished trial#66 with value: 0.972027972027972 with parameters: {'lambda_l1': 2.78230156496406e-05, 'lambda_l2': 1.8617966302686244e-07, 'num_leaves': 151, 'feature_fraction': 0.6202888139454956, 'bagging_fraction': 0.647832281824803, 'bagging_freq': 5, 'min_child_samples': 65}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:17,274] Finished trial#67 with value: 0.965034965034965 with parameters: {'lambda_l1': 9.092231617719699e-06, 'lambda_l2': 6.504552674075309e-06, 'num_leaves': 127, 'feature_fraction': 0.5816316789397165, 'bagging_fraction': 0.9603776504869688, 'bagging_freq': 2, 'min_child_samples': 51}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:17,445] Finished trial#68 with value: 0.993006993006993 with parameters: {'lambda_l1': 0.0003512606011288169, 'lambda_l2': 7.672836182164665e-08, 'num_leaves': 163, 'feature_fraction': 0.6129712358485822, 'bagging_fraction': 0.8704863397342797, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:17,663] Finished trial#69 with value: 0.9790209790209791 with parameters: {'lambda_l1': 1.6871485337204867e-07, 'lambda_l2': 9.054019036222067e-08, 'num_leaves': 146, 'feature_fraction': 0.6577893386460137, 'bagging_fraction': 0.811964465171866, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:17,828] Finished trial#70 with value: 0.993006993006993 with parameters: {'lambda_l1': 2.645346823005229e-07, 'lambda_l2': 1.0218705452520032e-07, 'num_leaves': 147, 'feature_fraction': 0.6475836617679384, 'bagging_fraction': 0.8097933297803809, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:17,988] Finished trial#71 with value: 0.972027972027972 with parameters: {'lambda_l1': 1.1178244770410067e-08, 'lambda_l2': 4.64352782947805e-07, 'num_leaves': 144, 'feature_fraction': 0.6116119073121472, 'bagging_fraction': 0.8133049491430747, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:18,155] Finished trial#72 with value: 0.951048951048951 with parameters: {'lambda_l1': 0.1923394097097617, 'lambda_l2': 5.168703184976967e-08, 'num_leaves': 160, 'feature_fraction': 0.5838820376835983, 'bagging_fraction': 0.8833317752007535, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:18,339] Finished trial#73 with value: 0.993006993006993 with parameters: {'lambda_l1': 1.3221852210592064e-07, 'lambda_l2': 1.1858788467011337e-07, 'num_leaves': 170, 'feature_fraction': 0.5498098835118216, 'bagging_fraction': 0.7740173670893791, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:18,542] Finished trial#74 with value: 0.958041958041958 with parameters: {'lambda_l1': 9.084177344871213e-08, 'lambda_l2': 1.0071733354978814e-07, 'num_leaves': 172, 'feature_fraction': 0.4817499847658947, 'bagging_fraction': 0.8171457219500811, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:18,740] Finished trial#75 with value: 0.986013986013986 with parameters: {'lambda_l1': 3.7470141594055406e-08, 'lambda_l2': 1.8159119262313298e-07, 'num_leaves': 178, 'feature_fraction': 0.5388692226737322, 'bagging_fraction': 0.7684675871531044, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:18,927] Finished trial#76 with value: 0.986013986013986 with parameters: {'lambda_l1': 1.4488172713288868e-08, 'lambda_l2': 1.8591614008693807e-07, 'num_leaves': 195, 'feature_fraction': 0.5161137932937758, 'bagging_fraction': 0.7717829268709431, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:19,130] Finished trial#77 with value: 0.951048951048951 with parameters: {'lambda_l1': 3.638140521151868e-08, 'lambda_l2': 2.0081940452484674e-07, 'num_leaves': 198, 'feature_fraction': 0.5075389488333639, 'bagging_fraction': 0.7682669940044476, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:19,319] Finished trial#78 with value: 0.965034965034965 with parameters: {'lambda_l1': 1.2605115769906206e-08, 'lambda_l2': 3.338448155562256e-07, 'num_leaves': 214, 'feature_fraction': 0.4931176901697731, 'bagging_fraction': 0.8591980130953957, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:19,517] Finished trial#79 with value: 0.951048951048951 with parameters: {'lambda_l1': 2.7670253473550615e-07, 'lambda_l2': 4.652484242970782e-08, 'num_leaves': 191, 'feature_fraction': 0.5273547364238266, 'bagging_fraction': 0.7838251580810199, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:19,689] Finished trial#80 with value: 0.958041958041958 with parameters: {'lambda_l1': 6.906208651573705e-08, 'lambda_l2': 1.2940284212618788e-06, 'num_leaves': 136, 'feature_fraction': 0.44032581604864707, 'bagging_fraction': 0.7218784443499404, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:19,858] Finished trial#81 with value: 0.9370629370629371 with parameters: {'lambda_l1': 1.691929817503112e-08, 'lambda_l2': 1.4469565377879205e-07, 'num_leaves': 172, 'feature_fraction': 0.5573512097888066, 'bagging_fraction': 0.7748826308034492, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:20,050] Finished trial#82 with value: 0.993006993006993 with parameters: {'lambda_l1': 3.234536515634845e-08, 'lambda_l2': 6.973390080955618e-07, 'num_leaves': 177, 'feature_fraction': 0.5880852041744677, 'bagging_fraction': 0.7537295728373301, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:20,263] Finished trial#83 with value: 0.972027972027972 with parameters: {'lambda_l1': 2.5704831005815897e-08, 'lambda_l2': 4.406076812767147e-07, 'num_leaves': 178, 'feature_fraction': 0.5915964488228472, 'bagging_fraction': 0.8028627738143466, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:20,447] Finished trial#84 with value: 0.972027972027972 with parameters: {'lambda_l1': 1.5447218668802646e-07, 'lambda_l2': 7.536486573803367e-07, 'num_leaves': 163, 'feature_fraction': 0.5607326834926663, 'bagging_fraction': 0.8692453920708306, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:20,626] Finished trial#85 with value: 0.972027972027972 with parameters: {'lambda_l1': 3.2377850512113056e-07, 'lambda_l2': 2.48977654930117e-07, 'num_leaves': 152, 'feature_fraction': 0.6047154777791752, 'bagging_fraction': 0.7443262051348405, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:20,806] Finished trial#86 with value: 0.972027972027972 with parameters: {'lambda_l1': 8.616223136385499e-08, 'lambda_l2': 3.3884196848127443e-08, 'num_leaves': 186, 'feature_fraction': 0.6331332502506135, 'bagging_fraction': 0.7580965829286749, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:21,006] Finished trial#87 with value: 0.972027972027972 with parameters: {'lambda_l1': 4.442593949467799e-08, 'lambda_l2': 3.425103501125518e-06, 'num_leaves': 206, 'feature_fraction': 0.6755770843892988, 'bagging_fraction': 0.7235190549103552, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:21,187] Finished trial#88 with value: 0.9370629370629371 with parameters: {'lambda_l1': 2.7935737775496695e-08, 'lambda_l2': 1.3461083557028367e-07, 'num_leaves': 195, 'feature_fraction': 0.527235780110095, 'bagging_fraction': 0.826188123933424, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:21,350] Finished trial#89 with value: 0.972027972027972 with parameters: {'lambda_l1': 5.832985157720741e-07, 'lambda_l2': 8.657444858002741e-08, 'num_leaves': 169, 'feature_fraction': 0.5777210474009031, 'bagging_fraction': 0.7985304271653116, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:21,540] Finished trial#90 with value: 0.972027972027972 with parameters: {'lambda_l1': 0.00032000828570916655, 'lambda_l2': 5.241827111268912e-07, 'num_leaves': 174, 'feature_fraction': 0.6488582003916695, 'bagging_fraction': 0.843472055172736, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:21,729] Finished trial#91 with value: 0.951048951048951 with parameters: {'lambda_l1': 1.7485358773847354e-08, 'lambda_l2': 3.3510957494673684e-08, 'num_leaves': 164, 'feature_fraction': 0.7019445748600799, 'bagging_fraction': 0.8515140404919636, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:21,896] Finished trial#92 with value: 0.993006993006993 with parameters: {'lambda_l1': 0.000836813493309224, 'lambda_l2': 2.5529770638057853e-07, 'num_leaves': 156, 'feature_fraction': 0.6261762692949854, 'bagging_fraction': 0.7773387799717939, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:22,063] Finished trial#93 with value: 0.965034965034965 with parameters: {'lambda_l1': 0.0009479408894651464, 'lambda_l2': 2.7132445278666e-07, 'num_leaves': 155, 'feature_fraction': 0.6233346867731906, 'bagging_fraction': 0.7512695170752944, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:22,248] Finished trial#94 with value: 0.986013986013986 with parameters: {'lambda_l1': 0.005983963014159578, 'lambda_l2': 8.741409242480463e-07, 'num_leaves': 179, 'feature_fraction': 0.5938965398597681, 'bagging_fraction': 0.7948942799209165, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:22,435] Finished trial#95 with value: 0.972027972027972 with parameters: {'lambda_l1': 0.0054398280371928094, 'lambda_l2': 1.4987141542850304e-06, 'num_leaves': 188, 'feature_fraction': 0.6703716966347621, 'bagging_fraction': 0.7803022324705601, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:22,597] Finished trial#96 with value: 0.9790209790209791 with parameters: {'lambda_l1': 0.001833166081881557, 'lambda_l2': 8.447640448673666e-07, 'num_leaves': 149, 'feature_fraction': 0.6334890966606063, 'bagging_fraction': 0.7107660582585706, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:22,784] Finished trial#97 with value: 0.972027972027972 with parameters: {'lambda_l1': 0.0007319889524620576, 'lambda_l2': 1.4657499302828542e-07, 'num_leaves': 177, 'feature_fraction': 0.5508862863645626, 'bagging_fraction': 0.765566141415486, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:22,949] Finished trial#98 with value: 0.972027972027972 with parameters: {'lambda_l1': 0.0001794213065394191, 'lambda_l2': 2.3590368847525606e-06, 'num_leaves': 161, 'feature_fraction': 0.5939157067762989, 'bagging_fraction': 0.8304818839028878, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial#17 with value: 0.993006993006993.\n",
      "[I 2020-04-24 19:54:23,128] Finished trial#99 with value: 0.9370629370629371 with parameters: {'lambda_l1': 0.00037751061894489654, 'lambda_l2': 6.79293731076781e-08, 'num_leaves': 136, 'feature_fraction': 0.5685359736547373, 'bagging_fraction': 0.9174643467227206, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial#17 with value: 0.993006993006993.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.993006993006993\n",
      "  Params: \n",
      "    lambda_l1: 0.00010644546543696687\n",
      "    lambda_l2: 8.060164358035812e-08\n",
      "    num_leaves: 155\n",
      "    feature_fraction: 0.738197309672961\n",
      "    bagging_fraction: 0.8605153674117506\n",
      "    bagging_freq: 7\n",
      "    min_child_samples: 85\n"
     ]
    }
   ],
   "source": [
    "#from https://github.com/optuna/optuna/blob/master/examples/lightgbm_simple.py\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(param, dtrain)\n",
    "    preds = gbm.predict(test_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(test_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "著者の意見\n",
    "\n",
    "ベイズ最適化を行うと以下のような問題\n",
    "\n",
    "計算時間がかかりすぎる。(ニューラルネットの方がつらい）　ガウス過程時点でもO(N^3)\n",
    "\n",
    "ハイパーパラメータ間の依存性。ハイパーパラメータが精度に与える影響が独立でない事がしばしばある。\n",
    "\n",
    "評価のランダムネスによるばらつき。CVで頑張る。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.5 GBDTのパラメータのチューニング\n",
    "\n",
    "| hyper paramator (general name) | xgboost | lightGBM | 解説|\n",
    "| ---- | ---- | ---- | ---- |\n",
    "| learning rate | eta | learning_rate | 学習率 |\n",
    "| Number of Iterations | nrounds | num_iterations | 作成する決定木の本数 |\n",
    "| Maximum Depth | max_depth | max_depth | 決定木の最大深さ |\n",
    "| Hessian Regularization | min_child_weight | min_sum_hessian_in_leaf | Prune by minimum hessian requirement |\n",
    "| Loss Regularization | gamma | min_gain_to_split | 決定木を分岐させるために最低限減らさなくてはいけない目的関数の値。 |\n",
    "| Row Sampling | subsample | bagging_fraction | 決定木ごとに学習データの行をサンプリングする割合 |\n",
    "| Column Sampling by Tree | colsample_bytree | feature_fraction | 決定木ごとに特徴量の列をサンプリングする割合 |\n",
    "| L1 Regularization | alpha | lambda_l1 | 決定木の葉のウェイトに対するL1正則化の強さ |\n",
    "| L2 Regularization | lambda | lambda_l2 | 決定木の葉のウェイトに対するL2正則化の強さ |\n",
    "\n",
    "- learning rate を小さくすることで精度が下がることはまずないが計算の収束まで時間がかかる。\n",
    "    - LightGBMだと強引に学習率のスケーリングができる。\n",
    "\n",
    "- number of iterations は十分大きな値にしておきアーリーストッピングを使う。\n",
    "\n",
    "- アーリーストッピングを観察するのは50回に程度で良い。(それでも学習率とのバランスがあるとトースターは思う)\n",
    "\n",
    "- maximum Depth, Hessian Regularization, Loss Regularization\n",
    "    - 分岐の深さや分岐を行うかどうかを制御することでモデルの複雑さを制御できる\n",
    "  \n",
    "- L1 Regularization, L2 Regularization\n",
    "    - 決定木の葉のウェイトの正則化によりモデルの複雑さを調整できる\n",
    "    \n",
    "- Row Sampling, column Sampling by tree\n",
    "    - ランダム性を加えて過剰適合を抑える\n",
    "    \n",
    "    \n",
    "著者の意見\n",
    "\n",
    "maximum depthが最重要で、 row sampling, col sampling by tree, Hessian Regularizationも重要。残りは好みによる。\n",
    "\n",
    "トースターはmax depthはあまりいじらないでiter. と Hess. を重視。アーリーストッピングは200くらいで学習率は0.005とかもう1桁下でやることが多い。（データによるけど）\n",
    "\n",
    "情報\n",
    "\n",
    "LightGBM公式はクソドキュメントなので読んでもわからない。xgboostは知らない。\n",
    "\n",
    "トースターのおすすめはPARAMETERS(https://sites.google.com/view/lauraepp/parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://blog.amedama.jp/entry/2019/07/18/211731\n",
    "\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sample_scheduler_func(current_lr, eval_history, best_round, is_higher_better):\n",
    "    \"\"\"次のラウンドで用いる学習率を決定するための関数 (この中身を好きに改造する)\n",
    "\n",
    "    :param current_lr: 現在の学習率 (指定されていない場合の初期値は None)\n",
    "    :param eval_history: 検証用データに対する評価指標の履歴\n",
    "    :param best_round: 現状で最も評価指標の良かったラウンド数\n",
    "    :param is_higher_better: 高い方が性能指標として優れているか否か\n",
    "    :return: 次のラウンドで用いる学習率\n",
    "\n",
    "    NOTE: 学習を打ち切りたいときには callback.EarlyStopException を上げる\n",
    "    \"\"\"\n",
    "    # 学習率が設定されていない場合のデフォルト\n",
    "    current_lr = current_lr or 0.2\n",
    "\n",
    "    # 試しに 30 ラウンド毎に学習率を半分にしてみる\n",
    "    if len(eval_history) % 30 == 0:\n",
    "        current_lr /= 2\n",
    "\n",
    "    # 小さすぎるとほとんど学習が進まないので下限も用意する\n",
    "    min_threshold = 0.001\n",
    "    current_lr = max(min_threshold, current_lr)\n",
    "\n",
    "    return current_lr\n",
    "\n",
    "class LrSchedulingCallback(object):\n",
    "    \"\"\"ラウンドごとの学習率を動的に制御するためのコールバック\"\"\"\n",
    "\n",
    "    def __init__(self, strategy_func):\n",
    "        # 学習率を決定するための関数\n",
    "        self.scheduler_func = strategy_func\n",
    "        # 検証用データに対する評価指標の履歴\n",
    "        self.eval_metric_history = []\n",
    "\n",
    "    def __call__(self, env):\n",
    "        # 現在の学習率を取得する\n",
    "        current_lr = env.params.get('learning_rate')\n",
    "\n",
    "        # 検証用データに対する評価結果を取り出す (先頭の評価指標)\n",
    "        first_eval_result = env.evaluation_result_list[0]\n",
    "        # スコア\n",
    "        metric_score = first_eval_result[2]\n",
    "        # 評価指標は大きい方が優れているか否か\n",
    "        is_higher_better = first_eval_result[3]\n",
    "\n",
    "        # 評価指標の履歴を更新する\n",
    "        self.eval_metric_history.append(metric_score)\n",
    "        # 現状で最も優れたラウンド数を計算する\n",
    "        best_round_find_func = np.argmax if is_higher_better else np.argmin\n",
    "        best_round = best_round_find_func(self.eval_metric_history)\n",
    "\n",
    "        # 新しい学習率を計算する\n",
    "        new_lr = self.scheduler_func(current_lr=current_lr,\n",
    "                                     eval_history=self.eval_metric_history,\n",
    "                                     best_round=best_round,\n",
    "                                     is_higher_better=is_higher_better)\n",
    "\n",
    "        # 次のラウンドで使う学習率を更新する\n",
    "        update_params = {\n",
    "            'learning_rate': new_lr,\n",
    "        }\n",
    "        env.model.reset_parameter(update_params)\n",
    "        env.params.update(update_params)\n",
    "\n",
    "    @property\n",
    "    def before_iteration(self):\n",
    "        # コールバックは各イテレーションの後に実行する\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.25)\n",
    "dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "\n",
    "\n",
    "param = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"lambda_l1\" : 0.00010644546543696687,\n",
    "    \"lambda_l2\" : 8.060164358035812e-08,\n",
    "    \"num_leaves\" : 155,\n",
    "    \"feature_fraction\" : 0.738197309672961,\n",
    "    \"bagging_fraction\" : 0.8605153674117506,\n",
    "    \"bagging_freq\" : 7,\n",
    "    \"min_child_samples\" : 85,\n",
    "}\n",
    "\n",
    "# コールバックを用意する\n",
    "lr_scheduler_cb = LrSchedulingCallback(strategy_func=sample_scheduler_func)\n",
    "callbacks = [lr_scheduler_cb]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,\n",
    "                      shuffle=True,\n",
    "                      random_state=42)\n",
    "\n",
    "# 動的に学習率を制御した場合\n",
    "cv_results_d = lgb.cv(param, dtrain,\n",
    "                        num_boost_round=500,\n",
    "                        verbose_eval=0,\n",
    "                        folds=skf, seed=42,\n",
    "                        callbacks=callbacks,\n",
    "                        )\n",
    "dynamic_lr = cv_results_d['binary_logloss-mean']\n",
    "\n",
    "# 学習率を 0.1 に固定した場合\n",
    "param.update({'learning_rate': 0.1})\n",
    "cv_results_s = lgb.cv(param, dtrain,\n",
    "                    num_boost_round=500,\n",
    "                    verbose_eval=0,\n",
    "                    folds=skf, seed=42,\n",
    "                    )\n",
    "static_lr_0_1 = cv_results_s['binary_logloss-mean']\n",
    "\n",
    "# グラフにプロットする\n",
    "sns.lineplot(np.arange(len(dynamic_lr)),\n",
    "             dynamic_lr,\n",
    "             label='LR=dynamic')\n",
    "sns.lineplot(np.arange(len(static_lr_0_1)),\n",
    "             static_lr_0_1,\n",
    "             label='LR=0.1')\n",
    "plt.title('learning rate control comparison')\n",
    "plt.xlabel('rounds')\n",
    "plt.ylabel('logloss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コラム\n",
    "\n",
    "hyperoptを使わずにベイズ最適化(optunaを使用)\n",
    "\n",
    "- ライブラリに任せる\n",
    "- 決定木の本数は多くしてアーリーストッピングを使う\n",
    "- 学習率は0.1にしておく。提出時は小さくする。(トースターは変動派)\n",
    "- チューニング時間を短縮するためCVは1foldのみ。実際に提出モデルを作成、検証、予測するときは異なる乱数の種で分割したfoldで行う。\n",
    "\n",
    "| hyper paramater | base line | 探索範囲と事前分布 |\n",
    "| ---- | ---- | ---- |\n",
    "| learning rate | 0.1 | 固定 |\n",
    "| number of iterations | 固定 | 大きな値をとりあえず入れる |\n",
    "| maximum depth | 5 | 3~9、一様分布(1刻み) |\n",
    "| Hessian regularization | 1.0 | 0.1~10.0 対数が一様分布になるように |\n",
    "| Loss Regularization | 0.0 | 1e-8~ 1.0 対数が一様分布 |\n",
    "| column sampling by tree | 0.8 | 0.60~0.95、一様分布 |\n",
    "| row sampling | 0.8 | 0.60 ~ 0.95 一様分布 |\n",
    "| L1 regularization | 0.0 | デフォルト値 |\n",
    "| L2 regularization | 1.0 | デフォルト値 |\n",
    "\n",
    "\n",
    "\n",
    "筆者のチューニング\n",
    "\n",
    "1. ハイパーパラメータの初期値を設定する。\n",
    "    - learning rate : 0.1 or 0.05\n",
    "    - maximum depth : 決め打ち\n",
    "    - column sampling by tree : 1.0\n",
    "    - column sampling by level : 0.3(Percentage of columns used per split selection)\n",
    "    - row sampling : 0.9\n",
    "    - loss regularization : 0\n",
    "    - Hessian regularization : 1\n",
    "    - L1 regularization : 0\n",
    "    - L2 regularization : 1\n",
    "   \n",
    "2. maximum depthの最適化\n",
    "    - 5~8くらいを味見してから深くするか浅くする\n",
    "    \n",
    "3. column sampling by level\n",
    "    - 0.1きざみで0.5~0.1\n",
    "\n",
    "4. loss regularization\n",
    "    - 1,2,4,8...\n",
    "\n",
    "5. L1, L2\n",
    "    - バランスを見て適当に\n",
    "\n",
    "アーリーストッピングは10/学習率くらいにしている\n",
    "    \n",
    "    \n",
    "Analytics Vidhyaの記事で紹介されている手動チューニング\n",
    "\n",
    "1. ハイパーパラメータの初期値を設定する。\n",
    "    - learning rate : 0.1\n",
    "    - maximum depth : 5\n",
    "    - column sampling by tree : 0.8\n",
    "    - row sampling : 0.8\n",
    "    - loss regularization : 0\n",
    "    - Hessian regularization : 1\n",
    "    - L1 regularization : 0\n",
    "    - L2 regularization : 1\n",
    "    \n",
    "2. maximum depth, Hessian regularization\n",
    "    - maximum depthを3～9まで2刻み、Hessian regularization を1～5まで1刻み\n",
    "\n",
    "3. Loss Regularization \n",
    "    - 0.0~0.4ｍで\n",
    "    \n",
    "4. row sampling, column sampling by tree\n",
    "    - 0.6~1.0まで0.1刻み\n",
    "    \n",
    "5. L1 regularization\n",
    "    - 1e-5, 1e-2, 0.1, 1, 100\n",
    "\n",
    "6. learning rateの減少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.6 ニューラルネットのパラメータ及びそのチューニング\n",
    "\n",
    "- ネットワークの構成 多層パーセプトロンが前提\n",
    "    - 中間層の活性化関数　RELU、LeakyRELU、PRELU(これはLeakyReLUの改良版)\n",
    "    - 中間層の数\n",
    "    - 角層のユニット数、ドロップアウト率\n",
    "    - Batch Normalization (BN)を入れるか\n",
    "\n",
    "-　オプティマイザの選択\n",
    "    - SGDとAdam\n",
    "    - トースターの意見としては、多分SGDだと局所解に落ちるからモーメンタム入れるほうがいい気がする(更にやるならcosineアニーリング付きで)。Adamはだいたいいい感じになるが、押しに欠ける。RAdamとかAdamWの方が好き。\n",
    "    - いずれにしても学習率は重要\n",
    "    \n",
    "- その他\n",
    "    - バッチサイズ(ミニバッチ内のデータ数)\n",
    "    - Weight Decayなどの正則化項の導入、オプティマイザの学習率以外のパラメータの調整\n",
    "    \n",
    "まず学習率を調整してある程度進むようなら他のパラメータ調整をすると良いと書かれている。\n",
    "\n",
    "トースターの意見としては3～5層くらいのパーセプトロンでも学習進まないことがあるので、早期にBatch Normalizationすることをおすすめする。あとはDropout併用(5割くらい)するか若干(2割位)入れてみるか。\n",
    "\n",
    "スコアの図があるので322ページ参照\n",
    "\n",
    "コラム\n",
    "\n",
    "多層パーセプトロンのチューニング例\n",
    "\n",
    "| hyper paramater | base line | 探索範囲と事前分布 |\n",
    "| ---- | ---- | ---- |\n",
    "| 入力層のドロップアウト | 0.0 | 0.0～0.2、一様分布、0.05刻み |\n",
    "| 中間層の数 | 3 | 2～4 1刻み |\n",
    "| 中間層のユニット数 | 96 | 32～256 一様分布、32刻み |\n",
    "| 中間層のドロップアウト | 0.2 | 0.0~0.3 一様分布、0.05刻み |\n",
    "| Batch Normalization | 活性化関数の前 | もしくは設定しない |\n",
    "| オプティマイザ | Adam | AdamもしくはSGD、学習率は1e-5～0.01、対数が一様分布 |\n",
    "| バッチサイズ | 32 | 32～128、一様分布32刻み |\n",
    "| エポック数 | 指定しない | アーリーストッピングを使う |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-29 15:25:21,508] Finished trial#0 with value: 0.925 with parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.46906359740965725, 'optimizer': 'RMSprop', 'lr': 0.001080683809572086}. Best is trial#0 with value: 0.925.\n",
      "[I 2020-04-29 15:25:27,927] Finished trial#1 with value: 0.9078125 with parameters: {'n_layers': 2, 'n_units_l0': 29, 'dropout_l0': 0.3335785549383267, 'n_units_l1': 49, 'dropout_l1': 0.4908082355006125, 'optimizer': 'Adam', 'lr': 0.007516669504675806}. Best is trial#0 with value: 0.925.\n",
      "[I 2020-04-29 15:25:33,555] Finished trial#2 with value: 0.8984375 with parameters: {'n_layers': 1, 'n_units_l0': 62, 'dropout_l0': 0.2071881644382113, 'optimizer': 'SGD', 'lr': 0.08289574223936326}. Best is trial#0 with value: 0.925.\n",
      "[I 2020-04-29 15:25:39,864] Finished trial#3 with value: 0.49921875 with parameters: {'n_layers': 2, 'n_units_l0': 126, 'dropout_l0': 0.2540609247212493, 'n_units_l1': 93, 'dropout_l1': 0.2101883159540476, 'optimizer': 'RMSprop', 'lr': 0.03935160053881418}. Best is trial#0 with value: 0.925.\n",
      "[I 2020-04-29 15:25:46,308] Finished trial#4 with value: 0.43046875 with parameters: {'n_layers': 2, 'n_units_l0': 90, 'dropout_l0': 0.490722690736943, 'n_units_l1': 82, 'dropout_l1': 0.3479351378139375, 'optimizer': 'Adam', 'lr': 2.7985298449110034e-05}. Best is trial#0 with value: 0.925.\n",
      "[I 2020-04-29 15:25:51,943] Finished trial#5 with value: 0.39375 with parameters: {'n_layers': 1, 'n_units_l0': 35, 'dropout_l0': 0.40135708644261603, 'optimizer': 'SGD', 'lr': 0.0021138311240760654}. Best is trial#0 with value: 0.925.\n",
      "[I 2020-04-29 15:25:58,877] Finished trial#6 with value: 0.93125 with parameters: {'n_layers': 3, 'n_units_l0': 125, 'dropout_l0': 0.2843475116065575, 'n_units_l1': 64, 'dropout_l1': 0.37430453453781753, 'n_units_l2': 58, 'dropout_l2': 0.3748383776975528, 'optimizer': 'Adam', 'lr': 0.0031695215225102076}. Best is trial#6 with value: 0.93125.\n",
      "[I 2020-04-29 15:26:05,171] Finished trial#7 with value: 0.10078125 with parameters: {'n_layers': 2, 'n_units_l0': 128, 'dropout_l0': 0.2121641889626353, 'n_units_l1': 50, 'dropout_l1': 0.2052267178589663, 'optimizer': 'RMSprop', 'lr': 0.08053108677513598}. Best is trial#6 with value: 0.93125.\n",
      "[I 2020-04-29 15:26:11,137] Finished trial#8 with value: 0.3890625 with parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_l0': 0.373971252974684, 'n_units_l1': 78, 'dropout_l1': 0.31503340526746015, 'optimizer': 'SGD', 'lr': 0.011763539861168942}. Best is trial#6 with value: 0.93125.\n",
      "[I 2020-04-29 15:26:17,258] Finished trial#9 with value: 0.1375 with parameters: {'n_layers': 3, 'n_units_l0': 34, 'dropout_l0': 0.3123742549385871, 'n_units_l1': 5, 'dropout_l1': 0.445697455818457, 'n_units_l2': 27, 'dropout_l2': 0.2713189883531641, 'optimizer': 'SGD', 'lr': 0.004772172692902197}. Best is trial#6 with value: 0.93125.\n",
      "[I 2020-04-29 15:26:24,121] Finished trial#10 with value: 0.765625 with parameters: {'n_layers': 3, 'n_units_l0': 87, 'dropout_l0': 0.27610892740327825, 'n_units_l1': 23, 'dropout_l1': 0.32403952969401506, 'n_units_l2': 118, 'dropout_l2': 0.32259436570097333, 'optimizer': 'Adam', 'lr': 0.0001342869695247473}. Best is trial#6 with value: 0.93125.\n",
      "[I 2020-04-29 15:26:29,953] Finished trial#11 with value: 0.8984375 with parameters: {'n_layers': 1, 'n_units_l0': 109, 'dropout_l0': 0.4843996228248244, 'optimizer': 'RMSprop', 'lr': 0.0003169147228046283}. Best is trial#6 with value: 0.93125.\n",
      "[I 2020-04-29 15:26:36,899] Finished trial#12 with value: 0.84609375 with parameters: {'n_layers': 3, 'n_units_l0': 107, 'dropout_l0': 0.43283109366215505, 'n_units_l1': 46, 'dropout_l1': 0.39839154189617754, 'n_units_l2': 20, 'dropout_l2': 0.47458081438377026, 'optimizer': 'Adam', 'lr': 0.0006760660432278654}. Best is trial#6 with value: 0.93125.\n",
      "[I 2020-04-29 15:26:42,716] Finished trial#13 with value: 0.92265625 with parameters: {'n_layers': 1, 'n_units_l0': 111, 'dropout_l0': 0.2978667963109243, 'optimizer': 'RMSprop', 'lr': 0.001475274213581958}. Best is trial#6 with value: 0.93125.\n",
      "[I 2020-04-29 15:26:49,308] Finished trial#14 with value: 0.7484375 with parameters: {'n_layers': 3, 'n_units_l0': 78, 'dropout_l0': 0.44607877191228607, 'n_units_l1': 105, 'dropout_l1': 0.380691457953207, 'n_units_l2': 66, 'dropout_l2': 0.2543216207633065, 'optimizer': 'RMSprop', 'lr': 0.00010813335190171628}. Best is trial#6 with value: 0.93125.\n",
      "[I 2020-04-29 15:26:55,320] Finished trial#15 with value: 0.95078125 with parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.24661959571895817, 'optimizer': 'Adam', 'lr': 0.01624627487564842}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:27:02,196] Finished trial#16 with value: 0.76015625 with parameters: {'n_layers': 3, 'n_units_l0': 124, 'dropout_l0': 0.2508419810584588, 'n_units_l1': 124, 'dropout_l1': 0.2650207853689608, 'n_units_l2': 10, 'dropout_l2': 0.4914616412270936, 'optimizer': 'Adam', 'lr': 0.02149334808240863}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:27:08,608] Finished trial#17 with value: 0.93515625 with parameters: {'n_layers': 2, 'n_units_l0': 58, 'dropout_l0': 0.2328961871295181, 'n_units_l1': 53, 'dropout_l1': 0.4944368525322957, 'optimizer': 'Adam', 'lr': 0.0037139985145260854}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:27:15,003] Finished trial#18 with value: 0.9015625 with parameters: {'n_layers': 2, 'n_units_l0': 49, 'dropout_l0': 0.2290068252547793, 'n_units_l1': 63, 'dropout_l1': 0.4920840616806598, 'optimizer': 'Adam', 'lr': 0.021349914867773687}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:27:21,049] Finished trial#19 with value: 0.94375 with parameters: {'n_layers': 1, 'n_units_l0': 63, 'dropout_l0': 0.2457336730167737, 'optimizer': 'Adam', 'lr': 0.009329880928222949}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:27:27,077] Finished trial#20 with value: 0.9109375 with parameters: {'n_layers': 1, 'n_units_l0': 75, 'dropout_l0': 0.3564420386160068, 'optimizer': 'Adam', 'lr': 0.039495296369692866}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:27:33,082] Finished trial#21 with value: 0.93671875 with parameters: {'n_layers': 1, 'n_units_l0': 57, 'dropout_l0': 0.24584689789454772, 'optimizer': 'Adam', 'lr': 0.007146082950331337}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:27:39,097] Finished trial#22 with value: 0.93828125 with parameters: {'n_layers': 1, 'n_units_l0': 48, 'dropout_l0': 0.2660414283113902, 'optimizer': 'Adam', 'lr': 0.014617816426276832}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:27:45,161] Finished trial#23 with value: 0.9375 with parameters: {'n_layers': 1, 'n_units_l0': 45, 'dropout_l0': 0.20139063695864678, 'optimizer': 'Adam', 'lr': 0.015235956891334211}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:27:51,223] Finished trial#24 with value: 0.90625 with parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.2680975418851122, 'optimizer': 'Adam', 'lr': 0.0419169085507499}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:27:57,258] Finished trial#25 with value: 0.93515625 with parameters: {'n_layers': 1, 'n_units_l0': 71, 'dropout_l0': 0.31793905006046624, 'optimizer': 'Adam', 'lr': 0.009056032751918148}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:28:03,258] Finished trial#26 with value: 0.815625 with parameters: {'n_layers': 1, 'n_units_l0': 48, 'dropout_l0': 0.22359265990791116, 'optimizer': 'Adam', 'lr': 0.09366739710776105}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:28:09,260] Finished trial#27 with value: 0.878125 with parameters: {'n_layers': 1, 'n_units_l0': 16, 'dropout_l0': 0.26838072501514826, 'optimizer': 'Adam', 'lr': 0.030724889481442}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:28:15,281] Finished trial#28 with value: 0.9140625 with parameters: {'n_layers': 1, 'n_units_l0': 84, 'dropout_l0': 0.29277874263225473, 'optimizer': 'Adam', 'lr': 0.0006193524073248635}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:28:21,450] Finished trial#29 with value: 0.9171875 with parameters: {'n_layers': 1, 'n_units_l0': 93, 'dropout_l0': 0.24423260075190037, 'optimizer': 'Adam', 'lr': 0.001959021443281437}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:28:27,472] Finished trial#30 with value: 0.9359375 with parameters: {'n_layers': 1, 'n_units_l0': 67, 'dropout_l0': 0.30888068050215917, 'optimizer': 'Adam', 'lr': 0.0050027676911416205}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:28:33,480] Finished trial#31 with value: 0.93359375 with parameters: {'n_layers': 1, 'n_units_l0': 42, 'dropout_l0': 0.20017121986870923, 'optimizer': 'Adam', 'lr': 0.016898552397127238}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:28:39,494] Finished trial#32 with value: 0.9453125 with parameters: {'n_layers': 1, 'n_units_l0': 48, 'dropout_l0': 0.20029541330644612, 'optimizer': 'Adam', 'lr': 0.011940652877938112}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:28:45,519] Finished trial#33 with value: 0.93671875 with parameters: {'n_layers': 1, 'n_units_l0': 54, 'dropout_l0': 0.21206315660293185, 'optimizer': 'Adam', 'lr': 0.00897673897605}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:28:51,558] Finished trial#34 with value: 0.8828125 with parameters: {'n_layers': 1, 'n_units_l0': 64, 'dropout_l0': 0.26100464454521594, 'optimizer': 'Adam', 'lr': 0.05765141425679705}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:28:57,640] Finished trial#35 with value: 0.9015625 with parameters: {'n_layers': 1, 'n_units_l0': 21, 'dropout_l0': 0.23270530024511812, 'optimizer': 'Adam', 'lr': 0.028087917005225265}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:29:03,588] Finished trial#36 with value: 0.28828125 with parameters: {'n_layers': 2, 'n_units_l0': 30, 'dropout_l0': 0.3363037732047681, 'n_units_l1': 29, 'dropout_l1': 0.44109329585524826, 'optimizer': 'SGD', 'lr': 0.006259192231485831}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:29:09,656] Finished trial#37 with value: 0.93125 with parameters: {'n_layers': 1, 'n_units_l0': 40, 'dropout_l0': 0.2125409264788228, 'optimizer': 'Adam', 'lr': 0.003044846354391536}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:29:16,083] Finished trial#38 with value: 0.65625 with parameters: {'n_layers': 2, 'n_units_l0': 54, 'dropout_l0': 0.2821812107261933, 'n_units_l1': 64, 'dropout_l1': 0.4456717238615378, 'optimizer': 'Adam', 'lr': 0.062713920533793}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:29:22,111] Finished trial#39 with value: 0.9375 with parameters: {'n_layers': 1, 'n_units_l0': 62, 'dropout_l0': 0.2522757885403137, 'optimizer': 'Adam', 'lr': 0.01371607785564738}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:29:28,041] Finished trial#40 with value: 0.475 with parameters: {'n_layers': 2, 'n_units_l0': 95, 'dropout_l0': 0.2250504728907183, 'n_units_l1': 31, 'dropout_l1': 0.25294952533938314, 'optimizer': 'SGD', 'lr': 0.010555766312596965}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:29:34,069] Finished trial#41 with value: 0.946875 with parameters: {'n_layers': 1, 'n_units_l0': 47, 'dropout_l0': 0.20293170457115456, 'optimizer': 'Adam', 'lr': 0.017594295755892508}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:29:40,071] Finished trial#42 with value: 0.93125 with parameters: {'n_layers': 1, 'n_units_l0': 39, 'dropout_l0': 0.20335739627132426, 'optimizer': 'Adam', 'lr': 0.02555663101048762}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:29:46,050] Finished trial#43 with value: 0.89375 with parameters: {'n_layers': 1, 'n_units_l0': 29, 'dropout_l0': 0.23876428681065653, 'optimizer': 'Adam', 'lr': 0.04984697445980986}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:29:52,066] Finished trial#44 with value: 0.9359375 with parameters: {'n_layers': 1, 'n_units_l0': 53, 'dropout_l0': 0.21755101712526084, 'optimizer': 'Adam', 'lr': 0.01431352678151167}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:29:58,115] Finished trial#45 with value: 0.9328125 with parameters: {'n_layers': 1, 'n_units_l0': 70, 'dropout_l0': 0.20028136016685122, 'optimizer': 'Adam', 'lr': 0.002635377191297388}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:30:03,971] Finished trial#46 with value: 0.925 with parameters: {'n_layers': 1, 'n_units_l0': 34, 'dropout_l0': 0.2590791645086077, 'optimizer': 'RMSprop', 'lr': 0.005633764611214253}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:30:09,951] Finished trial#47 with value: 0.91796875 with parameters: {'n_layers': 1, 'n_units_l0': 47, 'dropout_l0': 0.28190765733297707, 'optimizer': 'Adam', 'lr': 0.0011106133919706266}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:30:15,566] Finished trial#48 with value: 0.8140625 with parameters: {'n_layers': 1, 'n_units_l0': 61, 'dropout_l0': 0.24006314616080457, 'optimizer': 'SGD', 'lr': 0.019243005640583018}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:30:21,623] Finished trial#49 with value: 0.70546875 with parameters: {'n_layers': 1, 'n_units_l0': 79, 'dropout_l0': 0.38005930156263856, 'optimizer': 'Adam', 'lr': 0.09601686616939649}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:30:27,959] Finished trial#50 with value: 0.8640625 with parameters: {'n_layers': 2, 'n_units_l0': 52, 'dropout_l0': 0.2989501366696382, 'n_units_l1': 5, 'dropout_l1': 0.4066757339588822, 'optimizer': 'RMSprop', 'lr': 0.003678073642879492}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:30:33,973] Finished trial#51 with value: 0.94375 with parameters: {'n_layers': 1, 'n_units_l0': 45, 'dropout_l0': 0.201252784206905, 'optimizer': 'Adam', 'lr': 0.012575357289243907}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:30:39,955] Finished trial#52 with value: 0.9484375 with parameters: {'n_layers': 1, 'n_units_l0': 43, 'dropout_l0': 0.2186466227353371, 'optimizer': 'Adam', 'lr': 0.01056369993270361}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:30:45,968] Finished trial#53 with value: 0.91875 with parameters: {'n_layers': 1, 'n_units_l0': 24, 'dropout_l0': 0.2178805433297826, 'optimizer': 'Adam', 'lr': 0.007683189713813481}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:30:52,000] Finished trial#54 with value: 0.92421875 with parameters: {'n_layers': 1, 'n_units_l0': 34, 'dropout_l0': 0.2065968819119186, 'optimizer': 'Adam', 'lr': 0.03148549248736064}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:30:58,022] Finished trial#55 with value: 0.32265625 with parameters: {'n_layers': 1, 'n_units_l0': 40, 'dropout_l0': 0.2284602692693124, 'optimizer': 'Adam', 'lr': 1.1264895172115878e-05}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:31:04,051] Finished trial#56 with value: 0.940625 with parameters: {'n_layers': 1, 'n_units_l0': 44, 'dropout_l0': 0.21903537489042088, 'optimizer': 'Adam', 'lr': 0.011870789945842725}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:31:10,062] Finished trial#57 with value: 0.94140625 with parameters: {'n_layers': 1, 'n_units_l0': 60, 'dropout_l0': 0.2516698498493494, 'optimizer': 'Adam', 'lr': 0.004535726188276144}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:31:16,094] Finished trial#58 with value: 0.9390625 with parameters: {'n_layers': 1, 'n_units_l0': 116, 'dropout_l0': 0.23597931573195302, 'optimizer': 'Adam', 'lr': 0.020680022408427336}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:31:22,137] Finished trial#59 with value: 0.9234375 with parameters: {'n_layers': 1, 'n_units_l0': 37, 'dropout_l0': 0.2009162139059398, 'optimizer': 'Adam', 'lr': 0.009951232209681799}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:31:28,164] Finished trial#60 with value: 0.934375 with parameters: {'n_layers': 1, 'n_units_l0': 57, 'dropout_l0': 0.2136509715159188, 'optimizer': 'Adam', 'lr': 0.036054415272083584}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:31:34,196] Finished trial#61 with value: 0.9375 with parameters: {'n_layers': 1, 'n_units_l0': 68, 'dropout_l0': 0.25264924140826295, 'optimizer': 'Adam', 'lr': 0.004896599376733581}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:31:40,206] Finished trial#62 with value: 0.940625 with parameters: {'n_layers': 1, 'n_units_l0': 49, 'dropout_l0': 0.246072997374162, 'optimizer': 'Adam', 'lr': 0.00706743582366839}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:31:46,217] Finished trial#63 with value: 0.9265625 with parameters: {'n_layers': 1, 'n_units_l0': 58, 'dropout_l0': 0.2743167384738057, 'optimizer': 'Adam', 'lr': 0.00199926759891293}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:31:52,240] Finished trial#64 with value: 0.9484375 with parameters: {'n_layers': 1, 'n_units_l0': 73, 'dropout_l0': 0.22672772398057897, 'optimizer': 'Adam', 'lr': 0.004092058358957364}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:31:58,271] Finished trial#65 with value: 0.9 with parameters: {'n_layers': 1, 'n_units_l0': 13, 'dropout_l0': 0.22958850688767946, 'optimizer': 'Adam', 'lr': 0.011226296288358495}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:32:04,322] Finished trial#66 with value: 0.90625 with parameters: {'n_layers': 1, 'n_units_l0': 29, 'dropout_l0': 0.20831169184279713, 'optimizer': 'Adam', 'lr': 0.023362024317902658}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:32:10,178] Finished trial#67 with value: 0.934375 with parameters: {'n_layers': 1, 'n_units_l0': 98, 'dropout_l0': 0.2218504541048088, 'optimizer': 'RMSprop', 'lr': 0.016300681124495685}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:32:16,220] Finished trial#68 with value: 0.934375 with parameters: {'n_layers': 1, 'n_units_l0': 44, 'dropout_l0': 0.20125699981358547, 'optimizer': 'Adam', 'lr': 0.008160705561859586}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:32:22,257] Finished trial#69 with value: 0.93984375 with parameters: {'n_layers': 1, 'n_units_l0': 75, 'dropout_l0': 0.2361688914742425, 'optimizer': 'Adam', 'lr': 0.006598168099850753}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:32:27,898] Finished trial#70 with value: 0.4375 with parameters: {'n_layers': 1, 'n_units_l0': 50, 'dropout_l0': 0.4158356060113393, 'optimizer': 'SGD', 'lr': 0.003898079232002699}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:32:33,940] Finished trial#71 with value: 0.9359375 with parameters: {'n_layers': 1, 'n_units_l0': 60, 'dropout_l0': 0.26224714969982127, 'optimizer': 'Adam', 'lr': 0.004614017154791409}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:32:39,955] Finished trial#72 with value: 0.94921875 with parameters: {'n_layers': 1, 'n_units_l0': 65, 'dropout_l0': 0.24655905262156916, 'optimizer': 'Adam', 'lr': 0.011899292699176792}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:32:45,979] Finished trial#73 with value: 0.9421875 with parameters: {'n_layers': 1, 'n_units_l0': 83, 'dropout_l0': 0.2433390829467908, 'optimizer': 'Adam', 'lr': 0.01232358803663682}. Best is trial#15 with value: 0.95078125.\n",
      "[I 2020-04-29 15:32:52,027] Finished trial#74 with value: 0.953125 with parameters: {'n_layers': 1, 'n_units_l0': 74, 'dropout_l0': 0.2252273729995417, 'optimizer': 'Adam', 'lr': 0.01714994461289793}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:32:58,083] Finished trial#75 with value: 0.93984375 with parameters: {'n_layers': 1, 'n_units_l0': 73, 'dropout_l0': 0.21103207702974777, 'optimizer': 'Adam', 'lr': 0.018140906766645308}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:33:04,156] Finished trial#76 with value: 0.9140625 with parameters: {'n_layers': 1, 'n_units_l0': 65, 'dropout_l0': 0.22604898054478742, 'optimizer': 'Adam', 'lr': 0.04499389098921218}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:33:10,221] Finished trial#77 with value: 0.9375 with parameters: {'n_layers': 1, 'n_units_l0': 78, 'dropout_l0': 0.21983382535224044, 'optimizer': 'Adam', 'lr': 0.023924269126447264}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:33:16,284] Finished trial#78 with value: 0.934375 with parameters: {'n_layers': 1, 'n_units_l0': 89, 'dropout_l0': 0.47368584584087026, 'optimizer': 'Adam', 'lr': 0.028479053860070783}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:33:22,356] Finished trial#79 with value: 0.94140625 with parameters: {'n_layers': 1, 'n_units_l0': 67, 'dropout_l0': 0.26907185850630383, 'optimizer': 'Adam', 'lr': 0.008500365029780544}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:33:28,767] Finished trial#80 with value: 0.94453125 with parameters: {'n_layers': 2, 'n_units_l0': 84, 'dropout_l0': 0.23160286318536252, 'n_units_l1': 73, 'dropout_l1': 0.2884359497588933, 'optimizer': 'Adam', 'lr': 0.0026822993984459502}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:33:35,205] Finished trial#81 with value: 0.91796875 with parameters: {'n_layers': 2, 'n_units_l0': 81, 'dropout_l0': 0.2346710981697671, 'n_units_l1': 109, 'dropout_l1': 0.25936896091730044, 'optimizer': 'Adam', 'lr': 0.0011343350911274645}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:33:41,223] Finished trial#82 with value: 0.9359375 with parameters: {'n_layers': 1, 'n_units_l0': 75, 'dropout_l0': 0.2555307860649837, 'optimizer': 'Adam', 'lr': 0.002725903431135379}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:33:47,672] Finished trial#83 with value: 0.93125 with parameters: {'n_layers': 2, 'n_units_l0': 119, 'dropout_l0': 0.22714353185981478, 'n_units_l1': 79, 'dropout_l1': 0.2992510162692405, 'optimizer': 'Adam', 'lr': 0.014193823841870628}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:33:54,170] Finished trial#84 with value: 0.92109375 with parameters: {'n_layers': 2, 'n_units_l0': 70, 'dropout_l0': 0.20697109180769066, 'n_units_l1': 97, 'dropout_l1': 0.2849951683420797, 'optimizer': 'Adam', 'lr': 0.0015156302907567574}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:34:00,619] Finished trial#85 with value: 0.92265625 with parameters: {'n_layers': 2, 'n_units_l0': 37, 'dropout_l0': 0.2460280042190613, 'n_units_l1': 59, 'dropout_l1': 0.3533437452680097, 'optimizer': 'Adam', 'lr': 0.005584748194390978}. Best is trial#74 with value: 0.953125.\n",
      "[I 2020-04-29 15:34:07,083] Finished trial#86 with value: 0.96015625 with parameters: {'n_layers': 2, 'n_units_l0': 101, 'dropout_l0': 0.21434185153678595, 'n_units_l1': 78, 'dropout_l1': 0.2966115331221448, 'optimizer': 'Adam', 'lr': 0.010329070791129179}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:34:13,541] Finished trial#87 with value: 0.61171875 with parameters: {'n_layers': 2, 'n_units_l0': 103, 'dropout_l0': 0.2144767900989516, 'n_units_l1': 74, 'dropout_l1': 0.23285312840586442, 'optimizer': 'Adam', 'lr': 0.06777625243198694}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:34:20,038] Finished trial#88 with value: 0.9390625 with parameters: {'n_layers': 2, 'n_units_l0': 102, 'dropout_l0': 0.23088596528300412, 'n_units_l1': 86, 'dropout_l1': 0.29504539709083977, 'optimizer': 'Adam', 'lr': 0.002373890067180276}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:34:26,373] Finished trial#89 with value: 0.95390625 with parameters: {'n_layers': 2, 'n_units_l0': 87, 'dropout_l0': 0.22223683095827065, 'n_units_l1': 89, 'dropout_l1': 0.28628867079853465, 'optimizer': 'RMSprop', 'lr': 0.0034646361964078406}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:34:32,725] Finished trial#90 with value: 0.91640625 with parameters: {'n_layers': 2, 'n_units_l0': 93, 'dropout_l0': 0.22101801420577818, 'n_units_l1': 123, 'dropout_l1': 0.23592746228925296, 'optimizer': 'RMSprop', 'lr': 0.009813203240156882}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:34:38,981] Finished trial#91 with value: 0.9390625 with parameters: {'n_layers': 2, 'n_units_l0': 87, 'dropout_l0': 0.23917322076310737, 'n_units_l1': 112, 'dropout_l1': 0.333620133799934, 'optimizer': 'RMSprop', 'lr': 0.003406315021845241}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:34:45,308] Finished trial#92 with value: 0.92109375 with parameters: {'n_layers': 2, 'n_units_l0': 85, 'dropout_l0': 0.21036791715587416, 'n_units_l1': 71, 'dropout_l1': 0.28076599660292, 'optimizer': 'RMSprop', 'lr': 0.0005835338734500047}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:34:51,609] Finished trial#93 with value: 0.9375 with parameters: {'n_layers': 2, 'n_units_l0': 81, 'dropout_l0': 0.22402687907499347, 'n_units_l1': 92, 'dropout_l1': 0.31205057354090127, 'optimizer': 'RMSprop', 'lr': 0.0015509295010892553}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:34:57,901] Finished trial#94 with value: 0.87109375 with parameters: {'n_layers': 2, 'n_units_l0': 112, 'dropout_l0': 0.21604444548667318, 'n_units_l1': 103, 'dropout_l1': 0.23238328763815336, 'optimizer': 'RMSprop', 'lr': 0.01864198962632385}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:35:03,857] Finished trial#95 with value: 0.0984375 with parameters: {'n_layers': 2, 'n_units_l0': 77, 'dropout_l0': 0.2346335847410169, 'n_units_l1': 119, 'dropout_l1': 0.34590495224663825, 'optimizer': 'SGD', 'lr': 0.0007846147614785802}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:35:10,272] Finished trial#96 with value: 0.953125 with parameters: {'n_layers': 2, 'n_units_l0': 97, 'dropout_l0': 0.2460771800913664, 'n_units_l1': 85, 'dropout_l1': 0.29419073035189874, 'optimizer': 'Adam', 'lr': 0.0063333086054106}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:35:16,783] Finished trial#97 with value: 0.95859375 with parameters: {'n_layers': 2, 'n_units_l0': 99, 'dropout_l0': 0.24797218140107016, 'n_units_l1': 89, 'dropout_l1': 0.2768054586571741, 'optimizer': 'Adam', 'lr': 0.005853376173926116}. Best is trial#86 with value: 0.96015625.\n",
      "[I 2020-04-29 15:35:23,297] Finished trial#98 with value: 0.9625 with parameters: {'n_layers': 2, 'n_units_l0': 97, 'dropout_l0': 0.2581206350138599, 'n_units_l1': 87, 'dropout_l1': 0.2743710041364531, 'optimizer': 'Adam', 'lr': 0.005974174176366611}. Best is trial#98 with value: 0.9625.\n",
      "[I 2020-04-29 15:35:29,826] Finished trial#99 with value: 0.9484375 with parameters: {'n_layers': 2, 'n_units_l0': 97, 'dropout_l0': 0.25773452327939866, 'n_units_l1': 94, 'dropout_l1': 0.27595072292494194, 'optimizer': 'Adam', 'lr': 0.004242364329345936}. Best is trial#98 with value: 0.9625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  100\n",
      "Best trial:\n",
      "  Value:  0.9625\n",
      "  Params: \n",
      "    n_layers: 2\n",
      "    n_units_l0: 97\n",
      "    dropout_l0: 0.2581206350138599\n",
      "    n_units_l1: 87\n",
      "    dropout_l1: 0.2743710041364531\n",
      "    optimizer: Adam\n",
      "    lr: 0.005974174176366611\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import optuna\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "LOG_INTERVAL = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
    "\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden untis and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_uniform(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def get_mnist():\n",
    "    # Load MNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-1)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the MNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            # Zeroing out gradient buffers.\n",
    "            optimizer.zero_grad()\n",
    "            # Performing a forward pass.\n",
    "            output = model(data)\n",
    "            # Computing negative Log Likelihood loss.\n",
    "            loss = F.nll_loss(output, target)\n",
    "            # Performing a backward pass.\n",
    "            loss.backward()\n",
    "            # Updating the weights.\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation of the model.\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "            # Limiting validation data.\n",
    "            if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                break\n",
    "            data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability.\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    accuracy = correct / N_VALID_EXAMPLES\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.7 線形モデルのパラメータ及びチューニング\n",
    "\n",
    "ハイパーパラメータ少ない、計算速いので10倍刻みで調べると良い\n",
    "\n",
    "scikit-learnのlinear_modelモジュールの各モデルの紹介\n",
    "\n",
    "- Lasso, Ridge：alphaが正則化の強さを表す。LassoではL1正則化(係数の大きさに比例して罰則を与える)、RidgeではL2正則化(係数の大きさの2乗に比例して罰則を与える)\n",
    "- ElasticNet :LassoとRidgeの半々みたいなモデル。alphaが生息家の強さを表すハイパーパラメータ。l1_ratioがL1とL2正則化の割合を表すパラメータ。\n",
    "- LogisticRegression： Cが生息家の強さの逆数を表すパラメータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 特徴選択及び特徴量の重要度\n",
    "\n",
    "与えられたデータの特徴量やそれから作成した特徴量にはモデルの精度に寄与しないばかりか悪化させる場合もある。有用な特徴量を撮ってくるのが大事。\n",
    "\n",
    "特徴選択の方法\n",
    "\n",
    "- 単変量統計を用いる方法\n",
    "    - 相関係数やカイ2乗などの統計量から求める\n",
    "- 特徴量の重要度を用いる方法\n",
    "    - 主にGBDTやランダムフォレストなどの決定木モデルで、モデルから出力される特徴量の重要度から求める方法。単純に重要度の上位を選択するだけでなく、工夫した手法も存在する。\n",
    "- 反復して探索する方法\n",
    "    - 特徴量の組を変えてモデルをを学習させることを繰り返し、その精度などを用いて探索する手法\n",
    "    \n",
    "理論的な手法の他に試行や直感に基づいて試行錯誤するのも有効な場合がある旨が書かれている。\n",
    "\n",
    "著者の意見\n",
    "\n",
    "分析コンペにおいては特徴量がそれぞれ多少なり予測に役立つ情報を持っていること。GBDTでは意味のない特徴量があっても精度が落ちづらいこと、アンサンブルで過剰適合が抑えられることからそれほど特徴選択が行われていないように感じる。与えられたものは全て使い、考えて作った特徴量はスコア見ながら取捨選択するというのが一つのやりかた。\n",
    "一方で機械的な作成から大量に特徴量を生成する手法もある。このときは計算コストが高いので特徴選択が重要。\n",
    "\n",
    "特徴選択を行う場合にはGBDTの特徴量の重要度をベースとする手法が比較的よく使われていると思う。重要度をそのまま使う、重要度のCVのfold間での変動係数が小さい順に採用するなど。ランダムな値からなる特徴量と比較して重要かどうかを判別できる手法も用いると良いでしょう。（この文どういう意味かわからんかった）\n",
    "\n",
    "トースターの意見\n",
    "\n",
    "- GBDTはたしかに無駄な特徴入れても精度はほぼ落ちない。\n",
    "- 過剰適合はめっちゃするので気をつけたほうがいい。ハイパーパラメータのチューニングでどうにかなるならいいんだけど。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 単変量統計を用いる場合\n",
    "\n",
    "各特徴量と目的変数からの何らかの統計量を計算し、その統計量の順序で特徴量選択する。単変量統計はあくまで特徴量と目的変数の1対1の関係を見るので特徴量の相互作用は考慮されない。\n",
    "\n",
    "- 相関係数\n",
    "\n",
    "いわゆる相関係数、線形の関係を前提とする。\n",
    "\n",
    "要素xと目的変数yの組がある。\n",
    "\n",
    "$(x_1, y_1), (x_2, y_2), ...(x_n, y_n)$とn対のデータが有る。$x_{\\mu}$は$ \\boldsymbol{x} $の平均、$y_{\\mu}$は$ \\boldsymbol{y} $の平均 ←ここ教科書誤植だよね。\n",
    "\n",
    "$$\n",
    "\\rho = \\frac{\\sum_i(x_i-x_{\\mu})(y_i-y_{\\mu})}{\\sqrt{\\sum_i(x_i-x_{\\mu})^2 \\sum_i(y_i-y_{\\mu})^2}}\n",
    "$$\n",
    "\n",
    "値の線形の関係性よりも値の大きさの順序関係のみに着目したい場合にはスピアマンの順位相関係数を使う。\n",
    "\n",
    "相関係数はnumpyのcorrcoef関数、pandasのcorr関数、スピアマンの順位相関係数はscipy.statsモジュールのspearmanr関数を使うと便利\n",
    "\n",
    "特徴選択はnumpyのargsort関数を使って自分で記述したほうが汎用性がある。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 0, 1, 2], dtype=int64), array([2, 1, 0, 3], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#indormation\n",
    "import numpy as np\n",
    "\n",
    "ary = np.array([10, 20, 30, 0])\n",
    "idx = ary.argsort()\n",
    "idx, idx[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 20, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#大きい方から3つ出力\n",
    "ary[idx[::-1][:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相関係数\n",
    "#pandas.DataFrame持ちっぽい\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "corrs = []\n",
    "for c in train_x.columns:\n",
    "    corr = np.corrcoef(train_x[c], train_y)[0, 1]\n",
    "    corrs.append(corr)\n",
    "corrs = np.array(corrs)\n",
    "\n",
    "# スピアマンの順位相関係数\n",
    "corrs_sp = []\n",
    "for c in train_x.columns:\n",
    "    corr_sp = st.spearmanr(train_x[c], train_y).correlation\n",
    "    corrs_sp.append(corr_sp)\n",
    "corrs_sp = np.array(corrs_sp)\n",
    "\n",
    "# 重要度の上位を出力する（上位5個まで）\n",
    "# np.argsortを使うことで、値の順序のとおりに並べたインデックスを取得できる\n",
    "idx = np.argsort(np.abs(corrs))[::-1]\n",
    "top_cols, top_importances = train_x.columns.values[idx][:5], corrs[idx][:5]\n",
    "print(top_cols, top_importances)\n",
    "\n",
    "idx2 = np.argsort(np.abs(corrs_sp))[::-1]\n",
    "top_cols2, top_importances2 = train_x.columns.values[idx][:5], corrs_sp[idx][:5]\n",
    "print(top_cols2, top_importances2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- カイ2乗統計量\n",
    "\n",
    "カイ2乗検定の統計量を計算し、統計量の大きい方から特徴量を選択する方法。この手法を用いるとき特徴量は非負での値、分類タスクである必要がある。特徴量の値のスケールに影響されるため、MinMaxScalerを使用すると良い。\n",
    "\n",
    "scikit-learnのfeature_selectionモジュールのchi2関数を使用する。\n",
    "\n",
    "- information\n",
    "\n",
    "上記chi2関数の動き\n",
    "\n",
    "1. 目的変数の各クラスごとにグルーピングして、特徴量の値の合計を観測度数とし、レコードの割合を期待確率とする集計表を作成する。（すでにわからない\n",
    "2. その集計表に対し、観測度数が期待確率に基づいてランダムに抽出されたものかどうかのカイ2乗統計量を計算する。\n",
    "\n",
    "特徴量の値が2値や頻度でない場合にそれを観測度数とすることは理論的に解釈しづらいが、それでも特徴量の値とクラスの関係性を見ることが可能らしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# カイ二乗統計量\n",
    "# ---------------------------------\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# カイ二乗統計量\n",
    "x = MinMaxScaler().fit_transform(train_x)\n",
    "c2, _ = chi2(x, train_y)\n",
    "\n",
    "# 重要度の上位を出力する（上位5個まで）\n",
    "idx = np.argsort(c2)[::-1]\n",
    "top_cols, top_importances = train_x.columns.values[idx][:5], corrs[idx][:5]\n",
    "print(top_cols, top_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 相互情報量\n",
    "\n",
    "各特徴量と目的変数との相互情報量を計算し、大きい方から選択する方法。確率変数XとYの相互情報量は以下の式\n",
    "\n",
    "$$\n",
    "I(X;Y) = \\int_Y \\int_X p(x,y) \\log \\frac{p(x,y)}{p(x)p(y)}dxdy\n",
    "$$\n",
    "\n",
    "相互情報量は、片方を知ることでもう片方をより推測できるようになる場合値が大きくなる。XとYが完全に従属のときはどちらかの変数の情報量と等しくなり、独立のときは0になる。\n",
    "\n",
    "scikit-learnのfeature_selectionモジュールから、目的変数が連続変数の場合はmutual_info_regression関数、目的変数がクラス（分類タスク）のときはmutual_info_classif関数を使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# 相互情報量\n",
    "# ---------------------------------\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# 相互情報量\n",
    "mi = mutual_info_classif(train_x, train_y)\n",
    "\n",
    "# 重要度の上位を出力する（上位5個まで）\n",
    "idx = np.argsort(mi)[::-1]\n",
    "top_cols, top_importances = train_x.columns.values[idx][:5], corrs[idx][:5]\n",
    "print(top_cols, top_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "著者の意見\n",
    "\n",
    "学習データ全体で特徴選択してはいけない旨が書かれている。特徴選択もout-of-foldでやるべき。（当たり前では…？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 特徴量の重要度を用いる方法\n",
    "\n",
    "- ランダムフォレストの特徴量の重要度\n",
    "\n",
    "ランダムフォレストは特徴量の重要度を出力できる。scikit-learnのRandomForestRegressor, RandomForestClassifierでは重要度は分岐を作成するときの基準となる値（回帰では2乗誤差、分類ではジニ不純度）の減少によって計算される。オプションで変えられたはず。\n",
    "\n",
    "重要度の上位から特徴量を選択することで特徴選択を行える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ランダムフォレスト\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=71)\n",
    "clf.fit(train_x, train_y)\n",
    "fi = clf.feature_importances_\n",
    "\n",
    "# 重要度の上位を出力する\n",
    "idx = np.argsort(fi)[::-1]\n",
    "top_cols, top_importances = train_x.columns.values[idx][:5], fi[idx][:5]\n",
    "print('random forest importance')\n",
    "print(top_cols, top_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GBDTの特徴量の重要度\n",
    "\n",
    "LightGBMで説明する。標準はゲインになってるはず。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9370629370629371\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.25)\n",
    "dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "\n",
    "param = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"lambda_l1\": 1e-8,\n",
    "    \"lambda_l2\": 1e-8,\n",
    "    \"num_leaves\": 64,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 1.0,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"min_child_samples\": 5,\n",
    "}\n",
    "\n",
    "gbm = lgb.train(param, dtrain)\n",
    "preds = gbm.predict(test_x)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(test_y, pred_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "27       27         197\n",
       "7         7         166\n",
       "21       21         127\n",
       "1         1         127\n",
       "14       14         108\n",
       "13       13         106\n",
       "22       22         100\n",
       "28       28         100\n",
       "19       19          90\n",
       "12       12          82\n",
       "23       23          81\n",
       "5         5          76\n",
       "20       20          73\n",
       "24       24          71\n",
       "4         4          69\n",
       "11       11          67\n",
       "6         6          62\n",
       "17       17          58\n",
       "18       18          58\n",
       "0         0          55\n",
       "29       29          48\n",
       "10       10          48\n",
       "26       26          47\n",
       "15       15          47\n",
       "8         8          45\n",
       "25       25          39\n",
       "9         9          38\n",
       "16       16          23\n",
       "2         2          17\n",
       "3         3          12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "f_importance = pd.DataFrame({'feature': range(len(gbm.feature_importance())), 'importance':gbm.feature_importance()}).sort_values('importance', ascending=False)\n",
    "\n",
    "f_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.subplots(figsize=(8,8))\n",
    "plt.barh(np.array(range(f_importance.shape[0])),\n",
    "        np.array(f_importance.importance.T),\n",
    "        tick_label=list(f_importance.feature))\n",
    "plt.title(\"feature importance\")\n",
    "plt.xlabel(\"importance value\")\n",
    "plt.ylabel(\"features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- permutation importance\n",
    "\n",
    "モデルを学習させたあとに、通常どおりに予測させたときのバリデーションデータのスコアと、ある特徴量の列をシャッフルして予測させたときのバリデーションデータのスコアを比較してシャッフルしたときどの程度予測精度が落ちるかということからその特徴量の重要度を計算する手法。\n",
    "モデルの種類に関わらず適用可能な点が大きい。\n",
    "\n",
    "eli5がおすすめされているがscikit-learn内に収まるなら0.22からpermutation importanceはかるモジュールが入ってるのでそちらがおすすめ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.25)\n",
    "\n",
    "RFC = RandomForestClassifier(criterion = 'entropy')\n",
    "RFC.fit(train_x, train_y)\n",
    "\n",
    "result = permutation_importance(RFC, test_x, test_y, scoring='neg_log_loss', n_repeats=30, random_state=3, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.138662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.124339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>-0.097871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.095837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.091947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.085530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.081957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.077771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.077655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.073312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>-0.063617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.057732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.031711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.030855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.011822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.006611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.001205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.001245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.001662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.002117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.004484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.011636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.015065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "12       12   -0.138662\n",
       "26       26   -0.124339\n",
       "27       27   -0.097871\n",
       "6         6   -0.095837\n",
       "20       20   -0.091947\n",
       "2         2   -0.085530\n",
       "0         0   -0.081957\n",
       "7         7   -0.077771\n",
       "23       23   -0.077655\n",
       "3         3   -0.073312\n",
       "22       22   -0.063617\n",
       "25       25   -0.057732\n",
       "24       24   -0.052800\n",
       "5         5   -0.031711\n",
       "28       28   -0.030855\n",
       "16       16   -0.011822\n",
       "19       19   -0.006611\n",
       "17       17    0.000035\n",
       "10       10    0.000303\n",
       "11       11    0.000431\n",
       "8         8    0.000779\n",
       "14       14    0.001205\n",
       "18       18    0.001245\n",
       "15       15    0.001284\n",
       "9         9    0.001662\n",
       "4         4    0.002117\n",
       "29       29    0.004484\n",
       "13       13    0.011636\n",
       "1         1    0.012292\n",
       "21       21    0.015065"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_importance = pd.DataFrame({'feature': range(len(result.importances_mean)), 'importance':result.importances_mean}).sort_values('importance', ascending=True)\n",
    "p_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "          vert=False, labels=p_importance.feature)\n",
    "ax.set_title(\"permutation importance of each features for validation dataset\")\n",
    "ax.set_ylabel(\"Features\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- null importance\n",
    "\n",
    "目的変数をシャッフルして学習させたときの重要度をnull importanceとして基準として、目的変数をシャッフルしていない通常の重要度をactual importanceとしてこの違いを重要度とする。\n",
    "\n",
    "両者ともに複数回行うのが普通のやり方。（並べ替え具合によってスコアが変わるので）\n",
    "\n",
    "- boruta\n",
    "\n",
    "上記2つとはまた違う方法でシャッフルして特徴選択を行う方法。それぞれの特徴量をシャッフルしたデータを作成し、これをshadow featureと呼ぶ。shadow featureを元のデータの列方向に加えてランダムフォレストで学習を行い特徴量の重要度計算する。このときそれぞれの特徴量の重要度がshadow featureのうち最も高い重要度よりも高いかどうかを判定して記録する。これを繰り返し行いshadow featureより重要と言えない特徴量を除外し残った特徴量によって再び学習を行い、十分に高い重要度を保つ特徴量を選別する。BorutaPyというライブラリが公開されている。\n",
    "\n",
    "- 特徴量を大量生成してからの特徴選択\n",
    "\n",
    "特徴量を考察及び機械的な組み合わせを数千～数万作り特徴選択する。\n",
    "\n",
    "- xgbfir\n",
    "\n",
    "xgboost使い用\n",
    "\n",
    "- Greedy Forward Selection\n",
    "\n",
    "1. 使用する特徴量の集合を空集合から始める（この集合をMとする）\n",
    "2. 候補となる特徴量それぞれについてMに加えた場合のスコアを計算する。\n",
    "3. 最もスコアを改善させた特徴量をMに加える\n",
    "4. 3.で採用された特徴量を候補から外し、2と3をスコアの改善が止まるまで続ける\n",
    "\n",
    "デメリットは計算コストがでかい。簡便版は以下\n",
    "\n",
    "1. 使用する特徴量の集合を空集合から始める（この集合をMとする）\n",
    "2. 候補となる特徴量を有望な順番もしくはランダムな順番に並べる。\n",
    "3. 次の特徴量を加えることでスコアが良くなればMに加える、そうでなければ加えない。\n",
    "4. 3.をすべての候補について繰り返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Greedy Forward Selection\n",
    "# ----------------------------------\n",
    "\n",
    "best_score = 9999.0\n",
    "selected = set([])\n",
    "\n",
    "print('start greedy forward selection')\n",
    "\n",
    "while True:\n",
    "\n",
    "    if len(selected) == len(train_x.columns):\n",
    "        # すべての特徴が選ばれて終了\n",
    "        break\n",
    "\n",
    "    scores = []\n",
    "    for feature in train_x.columns:\n",
    "        if feature not in selected:\n",
    "            # 特徴量のリストに対して精度を評価するevaluate関数があるものとする\n",
    "            fs = list(selected) + [feature]\n",
    "            score = evaluate(fs)\n",
    "            scores.append((feature, score))\n",
    "\n",
    "    # スコアは低い方が良いとする\n",
    "    b_feature, b_score = sorted(scores, key=lambda tpl: tpl[1])[0]\n",
    "    if b_score < best_score:\n",
    "        selected.add(b_feature)\n",
    "        best_score = b_score\n",
    "        print(f'selected:{b_feature}')\n",
    "        print(f'score:{b_score}')\n",
    "    else:\n",
    "        # どの特徴を追加してもスコアが上がらないので終了\n",
    "        break\n",
    "\n",
    "print(f'selected features: {selected}')\n",
    "\n",
    "# ---------------------------------\n",
    "# Greedy Forward Selectionを単純化した手法\n",
    "# ----------------------------------\n",
    "\n",
    "best_score = 9999.0\n",
    "candidates = np.random.RandomState(71).permutation(train_x.columns)\n",
    "selected = set([])\n",
    "\n",
    "print('start simple selection')\n",
    "for feature in candidates:\n",
    "    # 特徴量のリストに対して精度を評価するevaluate関数があるものとする\n",
    "    fs = list(selected) + [feature]\n",
    "    score = evaluate(fs)\n",
    "\n",
    "    # スコアは低い方が良いとする\n",
    "    if score < best_score:\n",
    "        selected.add(feature)\n",
    "        best_score = score\n",
    "        print(f'selected:{feature}')\n",
    "        print(f'score:{score}')\n",
    "\n",
    "print(f'selected features: {selected}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3クラスの分布が偏っている場合\n",
    "\n",
    "- アンダーサンプリング\n",
    "\n",
    "負例が多い場合に負例の一部のみを使用してモデルを作る。異なる負例を取り出して学習させた複数のモデルを平均する手法（バギング）も有効\n",
    "\n",
    "    - 効率麺ではメリットが多い\n",
    "    - 特徴量を作るときは負例のすべてのデータを使うほうがいい。\n",
    "    - すべてのデータで学習した場合とバリデーションで精度比較し確認したほうがいい\n",
    "    \n",
    "- 特に工夫しない\n",
    "- 重み付け\n",
    "    -正例と負例のウェイト合計がおなじになるようにする。\n",
    "- オーバーサンプリング\n",
    "    - 負例のほうが多い場合に正例を増やしてモデルを学習させる方法。単純に増やすだけでなく、SMOTEなどの人工的に正例を生成する方法がある。\n",
    "- 確率を予測する場合の注意点\n",
    "    - loglossなど適切な確率予測をする必要がある場合は注意が必要。比率を変えたときは確率の補正が必要。\n",
    "    - 筆者はGBDTまともだと言ってるが、GBDTも疑ったほうがいい。多層パーセプトロンでも深い場合は注意が必要。\n",
    "    \n",
    "コラム\n",
    "\n",
    "ベイズ最適化とTPEのアルゴリズム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
