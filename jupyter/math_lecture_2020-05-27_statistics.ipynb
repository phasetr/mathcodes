{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"math_lecture_2020-05-27_statistics.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNArtJA1a19La2M/pIKxzIG"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8B7VE7_e__RP","colab_type":"text"},"source":["# 第 7 章 アンサンブル"]},{"cell_type":"markdown","metadata":{"id":"NM0g4vYYAOpu","colab_type":"text"},"source":["## 7.1 アンサンブルとは\n","- 複数のモデルを組み合わせてモデルを作ること・予測すること\n","- 分析コンペだとふつうモデルのアンサンブルによる予測値を提出する。\n","    - 数百のモデルを組み合わせることさえある\n","- 実務では少し精度を上げる程度の目的でモデルを複数作るのは許されないこともあるかもしれない\n","    - 検討・計算に膨大な時間がかかる\n","    - コンペはまた別\n","    - チームを組むときにそれぞれの成果を混ぜ合わせることもある\n","- 2 つの主な手法\n","    - 平均を取るようなシンプルなアンサンブル\n","    - 効率的にモデルを混ぜ合わせる手法：**スタッキング**"]},{"cell_type":"markdown","metadata":{"id":"SK1t4rn4AR5j","colab_type":"text"},"source":["## 7.2 シンプルなアンサンブル手法"]},{"cell_type":"markdown","metadata":{"id":"tj77_XWHBo-t","colab_type":"text"},"source":["### 7.2.1 平均・加重平均"]},{"cell_type":"markdown","metadata":{"id":"jVG5TOYeBuFg","colab_type":"text"},"source":["- 回帰タスク：単に複数のモデルの予測値の平均を取る\n","    - これで十分精度が出ることもある\n","- タスクやモデルによって考えるべき要素は次の通り\n","    - ハイパーパラメータや特徴量が同じでも、乱数シードを変えて平均を取るだけで精度が上がることもある\n","    - ニューラルネットワークは特に学習の精度がぶれやすく、効果が出やすい"]},{"cell_type":"markdown","metadata":{"id":"M01vwPqiCH5H","colab_type":"text"},"source":["#### たくさん作ったモデルの精度にばらつきがある場合\n","- 精度の高いモデルには大きめの重みをかけた加重平均をしたくなる\n","- どうやって重みを決めるか？\n","    - モデルの精度を見ながら**適当に決める**\n","    - スコアがもっとも高くなるように最適化する\n","        - 最適化には `scipy.optimize` モジュールが使える"]},{"cell_type":"markdown","metadata":{"id":"k3FzbzqnCiVN","colab_type":"text"},"source":["#### 注意点\n","- 「2.5.3 閾値の最適化を out-of-fold で行うべきか」も参照\n","- 学習データ全体の予測値を使い、学習データ全体のスコアが最適になるように調整したとき、目的変数を知っている状態での調整になる\n","    - 少し過大評価になってしまう\n","    - 避けたければクロスバリデーションして out-of-fold\n","    - スタッキングで 2 層目に線型モデルを使うのと類似"]},{"cell_type":"markdown","metadata":{"id":"2C6i5CJyDO5U","colab_type":"text"},"source":["#### 復習：out-of-fold\n","- cf. P94\n","- データをいくつかに分割し、そのうち 1 つを予測対象にし、残りを予測用の学習データにする手法\n","- 場面の設定\n","    - 分析コンペである変数を予測し、その予測した結果を使いたい・予測が正しいか評価したい\n","    - 各レコードについて自身の変数の値をつかってしまうと答えを見ているようなもので予測の意味をなさない\n","    - 自身の変数の値を使わずに予測したい\n","- よく使われるのはクロスバリデーション：cf 5.2.2"]},{"cell_type":"markdown","metadata":{"id":"mqA5WtUjD7xY","colab_type":"text"},"source":["### 7.2.2 多数決・重みづけ多数決\n","- 分類タスクの場合\n","    - 一番シンプルなのは予測値のクラスの多数決\n","    - モデルごとに重みをつけて多数決を取ることもある\n","- ふつうは予測確率をもとに予測値のクラスを決めているはず\n","    - 予測値のクラスよりも情報の多い予測確率が使える\n","    - 予測確率の平均・重みづけ平均を取った後に分類する方法もある"]},{"cell_type":"markdown","metadata":{"id":"dahCLUHKD_KP","colab_type":"text"},"source":["### 7.2.3 注意点とその他のテクニック"]},{"cell_type":"markdown","metadata":{"id":"kG17xUlsaieT","colab_type":"text"},"source":["#### 評価指標の最適化\n","- cf. 「2.5 評価指標の最適化」\n","- 評価指標によってはモデルの予測値をそのまま提出するのではなく、評価指標に合わせるために最適化する必要がある。\n","- アンサンブルの前に個別のモデルの予測値に対して最適化するかどうかは状況次第\n","    - アンサンブルの後に最適化する必要があるケースは多い"]},{"cell_type":"markdown","metadata":{"id":"X8sHjMjSbgO2","colab_type":"text"},"source":["#### 不思議な調整\n","- 「理屈」のない調整もありうる\n","- 「試行錯誤する中でたまたまスコアがよくなったから採用」というケース"]},{"cell_type":"markdown","metadata":{"id":"rE4dXUjEbtXs","colab_type":"text"},"source":["#### 順位の平均をとる\n","- AUC のような予測値の大小関係だけが影響する評価指標を考える\n","- 確率の平均値ではなく確率を順位に変換して順位の平均値をとる\n","    - モデルが予測する確率がゆがんでいてもその影響を除いてアンサンブルできる。\n","    - cf. P95、確率の歪み"]},{"cell_type":"markdown","metadata":{"id":"ktOkE8f_cIK2","colab_type":"text"},"source":["#### 幾何平均や調和平均などの利用\n","- 算術平均（標本平均）以外の平均を使う\n","- 幾何平均・調和平均・p次平均\n","- cf. P359 図7.1：平均とその等高線の図"]},{"cell_type":"markdown","metadata":{"id":"5NsY0phjcdw9","colab_type":"text"},"source":["#### 過学習気味のモデルのアンサンブル\n","- 「複雑でやや過学習気味のモデルを選ぶ方がいい」という意見もある\n","    - 言葉の定義\n","        - バイアス：モデルの平均的な予測値と真の値の乖離\n","        - バリアンス：予測値の不安定性\n","    - モデルが複雑：バイアス小、バリアンス大\n","    - モデルが単純：バイアス大、バリアンス小\n","    - アンサンブルで複数の予測値を組み合わせるとバリアンスは小さくなる。\n","    - 「少し複雑なモデルにしておけばトータルのバイアスを抑えられるのでは？」"]},{"cell_type":"markdown","metadata":{"id":"1jjQdFswAUnE","colab_type":"text"},"source":["## 7.3 スタッキング\n"]},{"cell_type":"markdown","metadata":{"id":"wJC2xCytEHHE","colab_type":"text"},"source":["### 7.3.1 スタッキングの概要\n","- cf. P.361 図7.2-7.4\n","- 効率的・効果的に 2 つ以上のモデルを組み合わせて予測する方法\n","- 次の手順で進める\n","    - 学習データをクロスバリデーションの fold にわける\n","        - fold を 1-4 とする\n","    - モデルを out-of-fold で学習させ、バリデーションデータへの予測値を作る\n","        - fold2-fold4 で学習したモデルで fold1 の予測値を作る\n","            - これを fold 分繰り返してから予測値をもとの順番に並べ直す\n","        - 学習データに特徴量として「そのモデルでの予測値」を作る\n","    - 各 fold で学習したモデルでテストデータを予測し、平均などを取ってテストデータの特徴量とする\n","    - 直上の 2 ステップをスタッキングしたいモデルの数だけくり返す：図 7.3\n","    - 直上の 3 ステップで作った特徴量でモデルの学習・予測をする。\n","        - このモデルを 2 層目のモデルという"]},{"cell_type":"markdown","metadata":{"id":"48Pma5gPg5BS","colab_type":"text"},"source":["#### コメント\n","- ポイント：こうして作った特徴量は予測対象のレコードの目的変数を知らない状況で学習したモデルによる予測値であること\n","- 問題があるパターン\n","    1. 学習データをクロスバリデーションの fold にわけず、 fold1-fold4 まですべてを学習データにしたモデルで学習データをそのまま予測する\n","    2. 上記モデルでテストデータを予測する\n","    3. 上記 2 ステップをスタッキングしたいモデルの数だけくり返す\n","    4. 2 層目のモデルでは 1-2 で作った予測値を特徴量としてモデルの学習・予測をする\n","- この方法の問題\n","    - 学習データは「目的変数を知っている」予測値\n","    - テストデータについて「目的変数を知らない」予測値\n","    - 学習データとテストデータで意味が違う特徴量になっている\n","    - 2 層目のモデルでテストデータを予測すると精度が悪くなる\n","        - cf. P362, 図 7.5"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_zZTs4NVEQFR"},"source":["### 7.3.2 特徴量作成の方法としてのスタッキング\n","- スタッキングはアンサンブル手法\n","- 特徴量を作る手法ととらえることもできる\n","- スタッキングで作った値は「あるモデルによる予測値」という特徴量ともみなせる：**メタ特徴量**\n","- 特徴量とみなすとき\n","    - 同質性が重要: 「あるモデルの予測値」という特徴量が学習データに対してもテストデータに対しても同じ意味の特徴量であること\n","    - cf. 先程の問題のケース\n","- 他の問題があるとき: 一部のモデルで作られた予測値が「目的変数を少し知っている」\n","    - target encoding の適用に間違いがあったとき\n","        - target encoding の復習：目的変数を使ってカテゴリ変数を数値に変換すること\n","    - パラメータチューニングしすぎたとき\n","- 「あるモデルによる予測値」とみなすと工夫の幅が広がる\n","    - 普通のアプローチ：目的変数を予測するモデルを作る\n","    - 次のようなアプローチが取れるようになる\n","        - モデルのとらえ直し\n","            - 欠損が多い変数の値を予測するモデル\n","            - 回帰問題を目的変数の値が 0 か否かの 2 値分類問題とみなす\n","        - それらの予測値を特徴量にする\n","    - 2 層目のモデルにスタッキングで作った特徴量と一緒に元のデータの特徴量や t-SNE などの教師なし学習による特徴量を与えることなどもある"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XGxxQcWxEQIt"},"source":["### 7.3.3 スタッキングの実装\n"]},{"cell_type":"code","metadata":{"id":"D8JMW8FbksYX","colab_type":"code","colab":{}},"source":["from sklearn.metrics import log_loss\n","from sklearn.model_selection import KFold\n","\n","# models.pyにModel1Xgb, Model1NN, Model2Linearを定義しているものとする\n","# 各クラスは、fitで学習し、predictで予測値の確率を出力する\n","\n","from models import Model1Xgb, Model1NN, Model2Linear\n","\n","\n","# 学習データに対する「目的変数を知らない」予測値と、テストデータに対する予測値を返す関数\n","def predict_cv(model, train_x, train_y, test_x):\n","    preds = []\n","    preds_test = []\n","    va_idxes = []\n","\n","    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n","\n","    # クロスバリデーションで学習・予測を行い、予測値とインデックスを保存する\n","    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n","        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n","        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n","        model.fit(tr_x, tr_y, va_x, va_y)\n","        pred = model.predict(va_x)\n","        preds.append(pred)\n","        pred_test = model.predict(test_x)\n","        preds_test.append(pred_test)\n","        va_idxes.append(va_idx)\n","\n","    # バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n","    va_idxes = np.concatenate(va_idxes)\n","    preds = np.concatenate(preds, axis=0)\n","    order = np.argsort(va_idxes)\n","    pred_train = preds[order]\n","\n","    # テストデータに対する予測値の平均をとる\n","    preds_test = np.mean(preds_test, axis=0)\n","\n","    return pred_train, preds_test\n","\n","\n","# 1層目のモデル\n","# pred_train_1a, pred_train_1bは、学習データのクロスバリデーションでの予測値\n","# pred_test_1a, pred_test_1bは、テストデータの予測値\n","model_1a = Model1Xgb()\n","pred_train_1a, pred_test_1a = predict_cv(model_1a, train_x, train_y, test_x)\n","\n","model_1b = Model1NN()\n","pred_train_1b, pred_test_1b = predict_cv(model_1b, train_x_nn, train_y, test_x_nn)\n","\n","# 1層目のモデルの評価\n","print(f'logloss: {log_loss(train_y, pred_train_1a, eps=1e-7):.4f}')\n","print(f'logloss: {log_loss(train_y, pred_train_1b, eps=1e-7):.4f}')\n","\n","# 予測値を特徴量としてデータフレームを作成\n","train_x_2 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b})\n","test_x_2 = pd.DataFrame({'pred_1a': pred_test_1a, 'pred_1b': pred_test_1b})\n","\n","# 2層目のモデル\n","# pred_train_2は、2層目のモデルの学習データのクロスバリデーションでの予測値\n","# pred_test_2は、2層目のモデルのテストデータの予測値\n","model_2 = Model2Linear()\n","pred_train_2, pred_test_2 = predict_cv(model_2, train_x_2, train_y, test_x_2)\n","print(f'logloss: {log_loss(train_y, pred_train_2, eps=1e-7):.4f}')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"juBDAf7REQMW"},"source":["### 7.3.4 スタッキングのポイント"]},{"cell_type":"markdown","metadata":{"id":"GN_M8khwkvbs","colab_type":"text"},"source":["#### スタッキングが効く場合・効かない場合\n","- コンペの性質によってスタッキングの効果も違う\n","- スタッキングは学習データを使い尽くそうとする性質がある\n","    - 学習データとテストデータが同じ分布でデータ量が多いと有効\n","    - 時系列データのような分布が違うデータは学習データに適合しすぎる\n","        - スタッキングよりもモデルの加重平均によるアンサンブルを使う方が多い\n","- 特徴量作成で差がつきにくい場合は相対的に有効\n","- 評価指標の違い\n","    - logloss を使うときスタッキングが有効\n","        - accuracy よりも logloss の方が細かく予測値をチューニングすることによるスコアの向上がある\n","    - 多クラス分類で評価指標が multi-class logloss の場合\n","        - GBDT とニューラルネットをスタッキングすると大きなスコア向上がありうる"]},{"cell_type":"markdown","metadata":{"id":"Y93cccohvllD","colab_type":"text"},"source":["#### テストデータの特徴量の作成方法\n","- スタッキングでテストデータの特徴量を作るときはテストデータへの予測が必要\n","- 予測の方法について\n","    - ここまでは P.366 図 7.6 のような各 fold のモデル平均として説明した\n","    - 図 7.7 のように学習データ全体に対して学習し直したモデルで予測する方法もある\n","- クロスバリデーション後にテストデータをどう予測するかはいつでも問題\n","    - cf. P218, 4.1.2 モデル作成の流れ"]},{"cell_type":"markdown","metadata":{"id":"I5Rd3SFr7oRQ","colab_type":"text"},"source":["#### 2 層目のモデルに元の特徴量を加えるか?\n","- 1 層目のモデルの予測値だけを特徴量にするか, 1 層目のモデルの元の特徴量も付加するか?\n","    - cf. P367, 図 7.8\n","    - 前者 (予測値だけ): 学習時間が少なく過学習も起きにくい\n","    - 後者: 元の特徴量とモデルの予測値の関係性が見える\n","        - t-SNE, UMAP やクラスタリングなどの教師なし学習による特徴量を 2 層目のモデルの特徴量に与えることもある"]},{"cell_type":"markdown","metadata":{"id":"3JS2Ac1x7qD6","colab_type":"text"},"source":["#### 多層のスタッキング\n","- イメージ図：P.367, 図 7.9\n","- スタッキングをくり返すと精度の上がり方は弱くなる\n","    - それでも多少の効果はある\n","- スタッキングの選択肢があるとき\n","    - 2 層目で両方試して 3 層目で組み合わせるとか\n"]},{"cell_type":"markdown","metadata":{"id":"lm7fuXcu9Axl","colab_type":"text"},"source":["#### ハイパーパラメータ調整やアーリーストッピングでの注意点\n","- 調整しすぎるとバリデーションデータへの過剰適合が起きる\n","- アーリーストッピングではバリデーションデータに対して学習の進行が最適なところで止まる\n","- スタッキング: 特徴量として予測値を使う\n","    - バリデーションに対しては「少しだけ目的変数を知っている」\n","    - テストデータに対してはそうではない\n","- ハイパーパラメータ調整, アーリーストッピングでのパラメータ・決定木の本数決定のあとに\n","  fold の切り方を変えて学習・予測した方がいい?\n","    - cf. 5.4.5 バリデーションデータや Public Leaderboard への過剰な適合\n"]},{"cell_type":"markdown","metadata":{"id":"ouu_HNg58EDA","colab_type":"text"},"source":["#### 最終的に出力すべき予測値でなくても良い\n","- 1 層目のモデルで出力する値は予測に役に立てばいい\n","    - 最終出力する予測値である必要はない\n","- いろいろな工夫がありうる"]},{"cell_type":"markdown","metadata":{"id":"k9_Rlq-j9qMa","colab_type":"text"},"source":["#### モデルの予測値のさらなるメタ特徴量\n","- 2 層目のモデルに与える特徴量を考える\n","    - 1 層目のモデルの予測値\n","- メタ特徴量を考えてもいい\n","    - 1 層目のあるモデルと別のモデルによる予測値の差\n","    - 1 層目の複数のモデルの予測値の平均や分散"]},{"cell_type":"markdown","metadata":{"id":"BsqgguI4-POG","colab_type":"text"},"source":["#### 分析への利用\n","- スタッキングでモデルの予測値という特徴量が手に入る\n","- 目的変数と組み合せるとレコードごとにどの程度正しく予測できているかわかる\n","    - これを分析に応用する\n","- 例: 次のような量で精度を見て予測が難しいレコードの条件を推察する\n","    - 混同行列 (分析タスクで真の値のクラスと予測値のクラスの行列) 作成\n","    - あるカテゴリ変数の値"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"v4BwhRGrEPcB"},"source":["### 7.3.5 hold-out データへの予測値を用いたアンサンブル\n","- Blending というテクニック\n","    - 予測値の加重平均によるアンサンブル\n","    - ここでは特に「hold-out データへの予測値によるアンサンブル」とする\n","    - 復習（hold-out 法）\n","        - 一部のデータをバリデーションデータとして取り分けておく\n","        - 欠点：モデルの学習・評価に使えるデータが減る\n","        - 欠点克服のためにふつうクロスバリデーションをよく使う\n","- モデルの予測値を次の層の特徴量として使う\n","- 相違点: まず hold--out データを分ける\n","    - スタッキング: クロスバリデーションの分割ごとに学習させる\n","- 2 層目では hold-out データで学習し, テストデータを予測する\n","- 手順：cf. P.370, 図 7.11\n","    - 学習データを train データと hold-out データにわける\n","    - モデルを train データで学習させ, hold-out データ・テストデータの予測値を作る\n","        - cf. P.370, 図 7.10\n","    - 上記プロセスをアンサンブルしたいモデルの数だけくり返す\n","    - 2 層目のモデルとして直上 2 ステップで作った特徴量でモデルを学習・予測する\n","- メリット\n","    - 1 層目のモデルをクロスバリデーションしないので計算時間が短い\n","    - 1 層目のモデルの学習時に hold-out データの目的変数を見ないためリークのリスクが (少し) 小さい\n","- デメリット\n","    - 使えるデータ数が少なくなる: かなり強い否定的な材料\n","- データ数が多く, クロスバリデーションするための計算量が厳しいときに検討する\n"]},{"cell_type":"markdown","metadata":{"id":"tco-GHpWAXPd","colab_type":"text"},"source":["## 7.4 どんなモデルをアンサンブルにすると良いか？\n","- アンサンブルで高い効果を出すためには多様性に富んだモデルを組み合わせる\n","    - 得意な部分が違うモデルを組み合わせる\n","    - 例: それぞれ晴れの日の販売量と雨の日の販売量をよく予測できるモデル\n","    - 例: 線型関係をよく捉えるモデルと変数間の相互作用を良く捉えるモデル\n","- 精度が低いモデルでも, 性質が違うならアンサンブルとしては精度の改善につながることがある\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ahAi1SOkEfi5"},"source":["### 7.4.1 多様なモデルを使う\n","- 予測値の境界が違うため, 互いの弱いところを補完する\n","    - まずは単体で精度が高い GBDT とニューラルネットでのアンサンブルを試してみよう\n","    - GBDT\n","    - ニューラルネット\n","    - 線型モデル\n","    - k 近傍法\n","    - Extremely Randomized Trees (ERT) またはランダムフォレスト\n","    - Regularized Greedy Forest (RGF)\n","    - Field-aware Factorization Machines (FFM)\n"]},{"cell_type":"markdown","metadata":{"id":"nD11PaPHJ8aN","colab_type":"text"},"source":["#### Infomation\n","- 良いスタッキングのソリューションの特徴\n","    - 2-3 つの GBDT: 決定木の深さの大中小\n","    - 1-2 つのランダムフォレスト: 決定木の深さの大小\n","    - 1-2 つのニューラルネット: 層の数の大小\n","    - 1 つの線型モデル"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zq9YUzulEf2C"},"source":["### 7.4.2 ハイパーパラメータを変える\n","- モデルが同じでもハイパーパラメータを変えてみるのも一手\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"r9NJqE10Ef61"},"source":["### 7.4.3 特徴量を変える\n","- 使う特徴量とその組み合わせを変える\n","    - ある特徴量の組を使うか使わないか\n","    - 特徴量のスケーリングをするかしないか\n","    - 特徴選択を強くするかしないか\n","    - 外れ値を除くか除かないか\n","    - データの前処理や変換の方法を変える"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uwfXKCkHEf-n"},"source":["### 7.4.4 問題のとらえ方を変える\n","- 問題の捉え方を変えたり, 問題を解く助けになる何らかの値を予測するモデルを作り,\n","  その予測値を特徴量にする\n","    - 回帰タスクである値以上・以下の二値分類タスクのモデルを作る\n","    - 0 以上の値を取る販売額のタスクで販売されたかどうかの二値分類タスクのモデルを作る\n","    - 多クラス分類で一部のクラスだけを予測するモデルを作り,\n","      そのモデルではその一部のクラスに特化した手法を使う\n","    - 重要だが欠損が多い特徴量を予測するモデルを作る\n","    - あるモデルによる予測値の残差 (= 目的変数-予測値) を予測するモデルを作る\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"L-GnAKd-EgCe"},"source":["### 7.4.5 スタッキングに含めるモデルの選択\n","- スタッキングに含めるモデルの選択について確立した方法はない\n","- 単純な手法\n","    - モデルを作るごとにスタッキングのモデルに含める\n","        - 精度がよくなれば残し, そうでなければ対象外\n","        - これをくり返す\n","    - 自動化手法としては「6.2.3 反復して探索する手法」での Greedy Forward Selection\n","    - 計算量によってはこれも難しい\n","- 他の方法\n","    - 相関係数が 0.95 以下, コルモゴロフ-スミルノフ検定統計量が 0.05 以上のモデルを精度が高い順に選ぶ\n","    - 単に精度が高いモデルを選ぶだけだと同じようなモデルばかりで多様性がなくなることに配慮\n","- モデル選択の上での補助的な分析手法\n","    - バリデーションの結果をログに出し, 各モデルのスコアを把握する\n","    - 多様性評価\n","        - 予測値の相関係数を計算する\n","        - 異なるモデルの予測値同士の散布図をプロットする\n","    - バリデーションスコアとモデルの予測値を単独で提出したときの Public Leaderboard のスコアをプロットする\n","\n"]},{"cell_type":"markdown","metadata":{"id":"H8T5_eqTNGee","colab_type":"text"},"source":["#### AUTHOR'S OPINION\n","- アンサンブルによるソリューションの意義の議論\n","    - 数百個のモデルをアンサンブルしたモデルで少し精度が上がったとして, 何か意味があるか?\n","- 例えば次のような意義がある\n","    - スタッキングの手法は複数のモデルを混ぜ合わせる効果的かつシンプルな方法\n","    - 実務的には, タスクによっては少しの精度向上が本質的に重要で多くの利益をもたらすことがある\n","    - アンサンブルで達成した精度とシンプルなアプローチでの精度を比較できることにも意義がある\n"]},{"cell_type":"markdown","metadata":{"id":"JHYadYiEAbo4","colab_type":"text"},"source":["## 7.5 分析コンペにおけるアンサンブルの例"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"n3ywJWsLEgl8"},"source":["### 7.5.1 Kaggle の「Otto Group Product Classification Challenge\n","- 匿名化された特徴量をもとに商品を 9 クラスの商品カテゴリに分類する多クラス分類タスク\n","- 評価指標が multi-class logloss\n","- モデルについては P.375 参照\n","    - GBDT・ニューラルネット・k 近傍法をはじめおいた多数のモデルのアンサンブル\n","- 2 位も P.377 図 7.12 のようなスタッキングを使っている"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CerkvFX6EgpW"},"source":["### 7.5.2 Kaggle の「Home Depot Product Search Relevance」\n","- Home Depot のサイトで検索された語句と商品の関連度を予測する\n","- 評価指標は RMSE (平均 2 乗誤差)\n","- 検索された語句や商品のタイトル・説明がテキストで提供\n","    - 自然言語処理の技術が問われる\n","- 3 位のソリューション\n","    - テキストに対する前処理・さまざまな特徴量作成が前提\n","    - GBDT・ニューラルネット・線型モデルによるスタッキング: P.378, 図 7.13\n","    - コードとドキュメントも公開されている"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kbHkcVYTEgtA"},"source":["### 7.5.3 Kaggle の「Home Credit Default Risk」\n","- 消費者金融での顧客の貸し倒れ率の予測\n","- 評価指標は AUC\n","- 学習データとテストデータは時系列とプロジェクトで分割\n","    - プロジェクトはサービス開始地域や商品性のこと\n","- 分割特性による問題\n","    - クロスバリデーションによる学習データの評価値と Public Leaderboard でのスコアの整合性を取るのが難しい\n","    - スタッキングすると過学習する傾向にあった\n","- 2 位のソリューション\n","    - 独自手法を使っている\n","    - 「5.4.3 学習データとテストデータの分布が違う場合」で出てきた adversarial validation を利用した手法\n","    - 加重平均を取ってアンサンブル\n","    - 学習データではなくテストデータにあうように各モデルの重みを調整する\n","        - テストデータに近い学習データをサンプリングして使う\n","    - 手順\n","        - 学習データとテストデータに対して adversarial validation する\n","            - 学習データに対する「テストデータらしさ」を予測するモデルを作る\n","        - 各モデルでの予測値を out-of-fold で求める\n","        - 「テストデータらしさ」をもとに学習データの中から一定の割合でデータをサンプリング\n","        - サンプリングしたデータに対して加重平均の各モデルの重みを最適化\n","        - 重みの平均値が収束するまでくり返す"]},{"cell_type":"code","metadata":{"id":"6M0STVEyP_Np","colab_type":"code","colab":{}},"source":["# モデルの予測値を加重平均する重みの値をadversarial validationで求める\n","# train_x: 各モデルによる確率の予測値（実際には順位に変換したものを使用）\n","# train_y: 目的変数\n","# adv_train: 学習データのテストデータらしさを確率で表した値\n","\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score\n","\n","n_sampling = 50  # サンプリングの回数\n","frac_sampling = 0.5  # サンプリングで学習データから取り出す割合\n","\n","\n","def score(x, data_x, data_y):\n","    # 評価指標はAUCとする\n","    y_prob = data_x['model1'] * x + data_x['model2'] * (1 - x)\n","    return -roc_auc_score(data_y, y_prob)\n","\n","\n","# サンプリングにより加重平均の重みの値を求めることを繰り返す\n","results = []\n","for i in range(n_sampling):\n","    # サンプリングを行う\n","    seed = i\n","    idx = pd.Series(np.arange(len(train_y))).sample(frac=frac_sampling, replace=False,\n","                                                    random_state=seed, weights=adv_train)\n","    x_sample = train_x.iloc[idx]\n","    y_sample = train_y.iloc[idx]\n","\n","    # サンプリングしたデータに対して、加重平均の重みの値を最適化により求める\n","    # 制約式を持たせるようにしたため、アルゴリズムはCOBYLAを選択\n","    init_x = np.array(0.5)\n","    constraints = (\n","        {'type': 'ineq', 'fun': lambda x: x},\n","        {'type': 'ineq', 'fun': lambda x: 1.0 - x},\n","    )\n","    result = minimize(score, x0=init_x,\n","                      args=(x_sample, y_sample),\n","                      constraints=constraints,\n","                      method='COBYLA')\n","    results.append((result.x, 1.0 - result.x))\n","\n","# model1, model2の加重平均の重み\n","results = np.array(results)\n","w_model1, w_model2 = results.mean(axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DzxgYf-yQg-d","colab_type":"text"},"source":["#### 手法に対する注意\n","- 学習データとテストデータの性質が大きく違う場合の手法\n","    - このケースでは adversarial validation での AUC は 0.9 以上\n","- スコアへの寄与は特徴量の改善ほど大きくない\n","    - コンペ終盤でのスコアの最後の一押し程度"]}]}